diff -ruN /hadoop-2.8.5-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
--- /hadoop-2.8.5-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java	2018-09-09 08:35:07.000000000 +0000
+++ ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java	2020-06-04 03:11:47.000000000 +0000
@@ -104,6 +104,10 @@
 import com.google.common.base.Preconditions;
 import com.google.common.base.Strings;
 
+// msx
+import java.io.BufferedReader;
+import java.io.FileReader;
+
 /**
  * Provides access to configuration parameters.
  *
@@ -182,7 +186,7 @@
  */
 @InterfaceAudience.Public
 @InterfaceStability.Stable
-public class Configuration implements Iterable<Map.Entry<String,String>>,
+public class Configuration extends ReconfAgent implements Iterable<Map.Entry<String,String>>,
                                       Writable {
   private static final Log LOG =
     LogFactory.getLog(Configuration.class);
@@ -709,7 +713,10 @@
       handleDeprecation(deprecations, (String)item);
     }
   }
- 
+
+  // msx
+  private static boolean msxConfEnable = false;
+
   static{
     //print deprecation warning if hadoop-site.xml is found in classpath
     ClassLoader cL = Thread.currentThread().getContextClassLoader();
@@ -725,6 +732,18 @@
     }
     addDefaultResource("core-default.xml");
     addDefaultResource("core-site.xml");
+    // msx
+    try {
+        BufferedReader reader = new BufferedReader(new FileReader("/root/reconf_test_gen/lib/enable"));
+        String buffer = reader.readLine();
+        reader.close();
+        if (buffer.equals("true"))
+            msxConfEnable = true;
+        else
+            msxConfEnable = false;
+    } catch(Exception e) {
+        e.printStackTrace();
+    }
   }
   
   private Properties properties;
@@ -1071,7 +1090,17 @@
     throw new IllegalStateException("Variable substitution depth too large: " 
                                     + MAX_SUBST + " " + expr);
   }
-  
+ 
+  // msx
+  private void whoInvokesMe(String parameter, String returnValue) {
+      if (msxConfEnable == false)
+          return;
+      String getMethodName = Thread.currentThread().getStackTrace()[2].getMethodName();
+      System.out.println("msx-conf parameter " + parameter + " getMethod " + getMethodName + " conf-hashcode "
+          + this.hashCode() + " returnValue " + returnValue);
+      return;
+  }
+
   /**
    * Get the value of the <code>name</code> property, <code>null</code> if
    * no such property exists. If the key is deprecated, it returns the value of
diff -ruN /hadoop-2.8.5-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configured.java ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configured.java
--- /hadoop-2.8.5-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configured.java	2018-05-05 10:34:35.000000000 +0000
+++ ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configured.java	2020-06-03 22:32:41.000000000 +0000
@@ -24,7 +24,7 @@
 /** Base class for things that may be configured with a {@link Configuration}. */
 @InterfaceAudience.Public
 @InterfaceStability.Stable
-public class Configured implements Configurable {
+public class Configured extends ReconfAgent implements Configurable {
 
   private Configuration conf;
 
diff -ruN /hadoop-2.8.5-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java
--- /hadoop-2.8.5-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java	1970-01-01 00:00:00.000000000 +0000
+++ ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java	2020-06-07 03:04:01.132965287 +0000
@@ -0,0 +1,196 @@
+package org.apache.hadoop.conf;
+
+import java.io.*;
+import java.util.List;
+import java.util.ArrayList;
+import java.util.Map;
+import java.util.HashMap;
+import org.apache.hadoop.conf.Configuration;
+
+public class ReconfAgent {
+    private static final String reconf_systemRootDir = "/root/parameter_test_controller/";
+
+    private static String reconf_vvmode = "";
+    private static String reconf_parameter = "";
+    public static String getReconfParameter() {
+        return ReconfAgent.reconf_parameter;
+    }
+    private static String reconf_component = "";
+    private static String reconf_v1 = "";
+    private static String reconf_v2 = "";
+    private static String reconf_point = "";
+    private static int reconf_point_int = 0; 
+    
+    private static int reconf_init_point_index = 0;
+    private static Map<Configuration, String> confComponentMap = new HashMap<Configuration, String>();
+    private static List<Object> componentList = new ArrayList<Object>();
+
+    // load just once
+    static {
+	loadSharedVariables();
+    }
+
+    private static void loadSharedVariables() {
+        try {
+            BufferedReader reader;
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_vvmode")));
+            reconf_vvmode = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_parameter")));
+            reconf_parameter = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_component")));
+            reconf_component = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_v1")));
+            reconf_v1 = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_v2")));
+            reconf_v2 = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_point")));
+            reconf_point = reader.readLine();
+            reader.close();
+            reconf_point_int = Integer.valueOf(reconf_point);
+
+            if (!reconf_vvmode.equals("v1v1") && !reconf_vvmode.equals("v2v2") && !reconf_vvmode.equals("v1v2") && !reconf_vvmode.equals("none")) {
+                myPrint("ERROR : wrong value of reconf_vvmode " + reconf_vvmode);
+                System.exit(1);
+            }
+      
+	    myPrint("reconf_vvmode=" + reconf_vvmode + ", reconf_parameter=" + reconf_parameter + 
+			    ", reconf_component=" + reconf_component + ", reconf_v1=" + reconf_v1 + ", reconf_v2=" + reconf_v2 +
+			    ", reconf_point=" + reconf_point);
+        } catch (Exception e) {
+            myPrint("ERROR : loadSharedVariables");
+            e.printStackTrace();
+        }
+    }
+
+    public synchronized static Configuration performReconf(Object componentObj, String component, Configuration originConf) {
+      if (originConf == null) {
+	  myPrint("ERROR : originConf is null");
+	  return null;
+      }
+      
+      myPrint("performReconf for comoponent " + component + " " + componentObj.hashCode() + " originConf " + originConf.hashCode());
+
+      /* check if component instance is already registered */
+      String componentHcStr = "";
+      if (componentObj != null) {
+          if (componentList.contains(componentObj)) {
+              myPrint("ERROR: " + component + " " + componentObj.hashCode() + 
+                  " already existed in componentList, just ignore this one.");
+	      // return the original conf
+              return originConf;
+          } else {
+              componentList.add(componentObj);
+              componentHcStr = Integer.toString(componentObj.hashCode());
+          }
+      } else {
+          componentHcStr = "static";
+      }
+      
+      /*
+       * check if originConf is being used by other component instances;
+       * if so, return copied new conf to ensure each component instance has its own conf.
+       */
+      Configuration uniqueConf = null; 
+      if (!confComponentMap.containsKey(originConf)) {
+          uniqueConf = originConf;
+	  myPrint("conf " + originConf.hashCode() + " itself is unique for " + component + " " + componentHcStr);
+      } else {
+	  uniqueConf = new Configuration(originConf); // new conf instance
+	  myPrint("WARN: conf " + originConf.hashCode() + " is shared with component " +
+              confComponentMap.get(originConf) + ", let copy and return new conf " + uniqueConf.hashCode());
+      }
+      confComponentMap.put(uniqueConf, component);
+
+      if (reconf_vvmode.equals("none")) {
+          myPrint(component + " init, vvmode is none, do nothing");
+      }
+
+      if (reconf_vvmode.equals("v1v1")) {
+          uniqueConf.set(reconf_parameter, reconf_v1);
+          myPrint(component + " init " + componentHcStr + ", vvmode is " + reconf_vvmode + 
+			  ". Set value as v1 " + reconf_v1);// + " uniqueConf is " + uniqueConf.hashCode());
+      }
+
+      if ((reconf_vvmode.equals("v2v2"))) {
+          uniqueConf.set(reconf_parameter, reconf_v2);
+          myPrint(component + " init " + componentHcStr + ", vvmode is " + reconf_vvmode + 
+			  ". Set value as v2 " + reconf_v2);//  + " uniqueConf is " + uniqueConf.hashCode());
+      }
+
+      if (reconf_vvmode.equals("v1v2")) { // reconfiguration injection
+          try {
+              //synchronized(this) {
+                  if (reconf_component.equals(component)) {
+                      if (reconf_point_int == -1) { //FF_ODD
+                          reconf_init_point_index ++;
+                          if ((reconf_init_point_index % 2) == 1) {
+                              uniqueConf.set(reconf_parameter, reconf_v2);
+                              myPrint(component + " init " + componentHcStr + ", PERFORM V1V2 FF_ODD RECONF " + reconf_point +
+					      ". Set value as v2 " + reconf_v2);// + " uniqueConf is " + uniqueConf.hashCode());
+                          } else {
+                              uniqueConf.set(reconf_parameter, reconf_v1);
+                              myPrint(component + " init " + componentHcStr + ", irrelevant init point " + reconf_init_point_index +
+					      ". Set value as v1 " + reconf_v1);// + " uniqueConf is " + uniqueConf.hashCode());
+                          }
+                      } else if (reconf_point_int == -2) { //FF_EVEN
+                          reconf_init_point_index ++;
+                          if ((reconf_init_point_index % 2) == 0) {
+                              uniqueConf.set(reconf_parameter, reconf_v2);
+                              myPrint(component + " init " + componentHcStr + ", PERFORM V1V2 FF_EVEN RECONF " + reconf_point +
+					      ". Set value as v2 " + reconf_v2);// + " uniqueConf is " + uniqueConf.hashCode());
+                          } else {
+                              uniqueConf.set(reconf_parameter, reconf_v1);
+                              myPrint(component + " init " + componentHcStr + ", irrelevant init point " + reconf_init_point_index +
+					      ". Set value as v1 " + reconf_v1);// + " uniqueConf is " + uniqueConf.hashCode());
+                          }
+		      } else {
+                          reconf_init_point_index ++;
+                          if (reconf_point_int == reconf_init_point_index) {
+                              uniqueConf.set(reconf_parameter, reconf_v2);
+                              myPrint(component + " init " + componentHcStr + ", PERFORM V1V2 RECONF " + reconf_point +
+					      ". Set value as v2 " + reconf_v2);// + " uniqueConf is " + uniqueConf.hashCode());
+                          } else {
+                              uniqueConf.set(reconf_parameter, reconf_v1);
+                              myPrint(component + " init " + componentHcStr + ", irrelevant init point " + reconf_init_point_index +
+					      " not " + reconf_point +
+					      ". Set value as v1 " + reconf_v1);// + " uniqueConf is " + uniqueConf.hashCode());
+                          }
+                      }
+                  } else { // for other component instances, just configure it to be v1
+                      uniqueConf.set(reconf_parameter, reconf_v1);
+                      myPrint(component + " init " + componentHcStr + ", irrelevant component." +
+				      " Set value as v1 " + reconf_v1);// + " uniqueConf is " + uniqueConf.hashCode()); 
+                  }
+             // }
+          } catch (Exception e) {
+              myPrint("ERROR happened during performReconf");
+              System.exit(1);
+          }
+      }
+      return uniqueConf;
+    }
+
+    private static void myPrint(String str) { System.out.println("msx-reconfagent " + str);}
+}
+    
+/*
+    public static void checkReconfAtShutdown(componentObject componentObj, String component, Configuration uniqueConf) {
+	if (componentObj == null || uniqueConf == null)
+	    return;
+        myPrint("" + component + " stop " + componentObj.hashCode() + ", value is " + uniqueConf.get(reconf_parameter));
+	Integer confToRemove = new Integer(uniqueConf.hashCode());
+	String v = confComponentMap.remove(confToRemove);
+	if (v == null) {
+	    myPrint("WARN : conf " + confToRemove + " not existed in confInstanceList when removing.");
+	}
+    }*/
diff -ruN /hadoop-2.8.5-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java
--- /hadoop-2.8.5-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java	2018-05-05 10:34:35.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java	2020-06-07 03:09:55.237009630 +0000
@@ -106,6 +106,8 @@
 
   @Override
   public void setConf(Configuration conf) {
+    // msx
+    conf = org.apache.hadoop.conf.Configured.performReconf(this, "hdfs:JournalNode", conf);
     this.conf = conf;
     this.localDir = new File(
         conf.get(DFSConfigKeys.DFS_JOURNALNODE_EDITS_DIR_KEY,
diff -ruN /hadoop-2.8.5-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
--- /hadoop-2.8.5-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java	2018-05-05 10:34:35.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java	2020-06-07 03:18:59.003220170 +0000
@@ -399,8 +399,11 @@
    */
   @VisibleForTesting
   @InterfaceAudience.LimitedPrivate("HDFS")
-  DataNode(final Configuration conf) {
-    super(conf);
+  DataNode(Configuration conf) {
+    // msx
+    super();
+    conf = org.apache.hadoop.conf.Configured.performReconf(this, "hdfs:DataNode", conf);
+    super.setConf(conf);
     this.blockScanner = new BlockScanner(this, conf);
     this.tracer = createTracer(conf);
     this.tracerConfigurationManager =
@@ -421,10 +424,13 @@
    * Create the DataNode given a configuration, an array of dataDirs,
    * and a namenode proxy.
    */
-  DataNode(final Configuration conf,
+  DataNode(Configuration conf,
            final List<StorageLocation> dataDirs,
            final SecureResources resources) throws IOException {
-    super(conf);
+    // msx
+    super();
+    conf = org.apache.hadoop.conf.Configured.performReconf(this, "hdfs:DataNode", conf);
+    super.setConf(conf);
     this.tracer = createTracer(conf);
     this.tracerConfigurationManager =
         new TracerConfigurationManager(DATANODE_HTRACE_PREFIX, conf);
diff -ruN /hadoop-2.8.5-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java
--- /hadoop-2.8.5-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java	2018-05-05 10:34:35.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java	2020-06-07 03:16:39.201623448 +0000
@@ -887,6 +887,14 @@
 
   protected NameNode(Configuration conf, NamenodeRole role)
       throws IOException {
+    // msx
+    super();
+    if (!(this instanceof BackupNode)) {
+        conf = org.apache.hadoop.conf.Configured.performReconf(this, "hdfs:NameNode", conf);
+    } else {
+        conf = org.apache.hadoop.conf.Configured.performReconf(this, "hdfs:BackupNode", conf);
+    }
+
     this.tracer = new Tracer.Builder("NameNode").
         conf(TraceUtils.wrapHadoopConf(NAMENODE_HTRACE_PREFIX, conf)).
         build();
@@ -1564,6 +1572,8 @@
 
     switch (startOpt) {
       case FORMAT: {
+        // msx
+        conf = org.apache.hadoop.conf.Configured.performReconf(null, "hdfs:NameNode_FORMAT", conf);
         boolean aborted = format(conf, startOpt.getForceFormat(),
             startOpt.getInteractiveFormat());
         terminate(aborted ? 1 : 0);
@@ -1583,17 +1593,23 @@
         return null; // avoid javac warning
       }
       case ROLLBACK: {
+        // msx
+        conf = org.apache.hadoop.conf.Configured.performReconf(null, "hdfs:NameNode_ROLLBACK", conf);
         boolean aborted = doRollback(conf, true);
         terminate(aborted ? 1 : 0);
         return null; // avoid warning
       }
       case BOOTSTRAPSTANDBY: {
+        // msx
+        conf = org.apache.hadoop.conf.Configured.performReconf(null, "hdfs:NameNode_BOOTSTRAPSTANDBY", conf);
         String toolArgs[] = Arrays.copyOfRange(argv, 1, argv.length);
         int rc = BootstrapStandby.run(toolArgs, conf);
         terminate(rc);
         return null; // avoid warning
       }
       case INITIALIZESHAREDEDITS: {
+        // msx
+        conf = org.apache.hadoop.conf.Configured.performReconf(null, "hdfs:NameNode_INITIALIZESHAREDEDITS", conf);
         boolean aborted = initializeSharedEdits(conf,
             startOpt.getForceFormat(),
             startOpt.getInteractiveFormat());
@@ -1604,13 +1620,18 @@
       case CHECKPOINT: {
         NamenodeRole role = startOpt.toNodeRole();
         DefaultMetricsSystem.initialize(role.toString().replace(" ", ""));
+	// msx
         return new BackupNode(conf, role);
       }
       case RECOVER: {
+        // msx
+        conf = org.apache.hadoop.conf.Configured.performReconf(null, "hdfs:NameNode_RECOVER", conf);
         NameNode.doRecovery(startOpt, conf);
         return null;
       }
       case METADATAVERSION: {
+        // msx
+        conf = org.apache.hadoop.conf.Configured.performReconf(null, "hdfs:NameNode_METADATAVERSION", conf);
         printMetadataVersion(conf);
         terminate(0);
         return null; // avoid javac warning
diff -ruN /hadoop-2.8.5-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java
--- /hadoop-2.8.5-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java	2018-05-05 10:34:35.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java	2020-06-07 03:08:31.692055435 +0000
@@ -183,6 +183,8 @@
   
   public SecondaryNameNode(Configuration conf,
       CommandLineOpts commandLineOpts) throws IOException {
+    // msx
+    conf = org.apache.hadoop.conf.Configured.performReconf(this, "hdfs:SecondaryNameNode", conf);
     try {
       String nsId = DFSUtil.getSecondaryNameServiceId(conf);
       if (HAUtil.isHAEnabled(conf, nsId)) {
