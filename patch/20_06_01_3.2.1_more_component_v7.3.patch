diff -ruN /hadoop-3.2.1-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
--- /hadoop-3.2.1-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java	2020-06-01 05:04:30.000000000 +0000
@@ -222,7 +222,7 @@
  */
 @InterfaceAudience.Public
 @InterfaceStability.Stable
-public class Configuration implements Iterable<Map.Entry<String,String>>,
+public class Configuration extends ReconfAgent implements Iterable<Map.Entry<String,String>>,
                                       Writable {
   private static final Logger LOG =
       LoggerFactory.getLogger(Configuration.class);
diff -ruN /hadoop-3.2.1-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java
--- /hadoop-3.2.1-src/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java	1970-01-01 00:00:00.000000000 +0000
+++ ./hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/ReconfAgent.java	2020-06-01 05:04:30.000000000 +0000
@@ -0,0 +1,205 @@
+package org.apache.hadoop.conf;
+
+import java.io.*;
+import java.util.List;
+import java.util.ArrayList;
+import java.util.Map;
+import java.util.HashMap;
+import org.apache.hadoop.conf.Configuration;
+
+public class ReconfAgent {
+
+    //private static final int RP_MODE_INSTANCE = -1; // set v2 to a single instance of the specified component throughout a test
+    //private static final int RP_MODE_COMPONENT = -2; // set v2 to all instances for the specified component
+    //private static final String RP_MODE_RECONF = "1"; // set v2 to a single life cycle of a single instance of the specified component
+    private static final String reconf_systemRootDir = "/root/parameter_test_controller/";
+
+    private static String reconf_vvmode = "";
+    private static String reconf_parameter = "";
+    private static String reconf_component = "";
+    private static String reconf_v1 = "";
+    private static String reconf_v2 = "";
+    private static String reconf_point = "";
+    private static int reconf_point_int = 0; 
+    
+    private static int reconf_init_point_index = 0;
+    private static Map<Integer, String> confHcComponentMap = new HashMap<Integer, String>();
+    private static List<Object> componentList = new ArrayList<Object>();
+
+    // load just once
+    static {
+	loadSharedVariables();
+    }
+
+    private static void loadSharedVariables() {
+        try {
+            BufferedReader reader;
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_vvmode")));
+            reconf_vvmode = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_parameter")));
+            reconf_parameter = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_component")));
+            reconf_component = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_v1")));
+            reconf_v1 = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_v2")));
+            reconf_v2 = reader.readLine();
+            reader.close();
+
+            reader = new BufferedReader(new FileReader(new File(reconf_systemRootDir + "shared/reconf_point")));
+            reconf_point = reader.readLine();
+            reader.close();
+            reconf_point_int = Integer.valueOf(reconf_point);
+
+            if (!reconf_vvmode.equals("v1v1") && !reconf_vvmode.equals("v2v2") && !reconf_vvmode.equals("v1v2") && !reconf_vvmode.equals("none")) {
+                myPrint("ERROR : wrong value of reconf_vvmode " + reconf_vvmode);
+                System.exit(1);
+            }
+      
+	    myPrint("reconf_vvmode=" + reconf_vvmode + ", reconf_parameter=" + reconf_parameter + 
+			    ", reconf_component=" + reconf_component + ", reconf_v1=" + reconf_v1 + ", reconf_v2=" + reconf_v2 +
+			    ", reconf_point=" + reconf_point);
+        } catch (Exception e) {
+            myPrint("ERROR : loadSharedVariables");
+            e.printStackTrace();
+        }
+    }
+
+    /*
+    public static void checkReconfAtShutdown(Object obj, String component, Configuration myConf) {
+	if (obj == null || myConf == null)
+	    return;
+        myPrint("" + component + " stop " + obj.hashCode() + ", value is " + myConf.get(reconf_parameter));
+	Integer confToRemove = new Integer(myConf.hashCode());
+	String v = confHcComponentMap.remove(confToRemove);
+	if (v == null) {
+	    myPrint("WARN : conf " + confToRemove + " not existed in confInstanceList when removing.");
+	}
+    }*/
+
+    public synchronized static void performReconf(Object obj, String component, Configuration myConf) {
+      String componentHcStr = "";
+
+      // check if component instance is already registered
+      if (obj != null) {
+          componentHcStr = Integer.toString(obj.hashCode());
+          if (componentList.contains(obj)) {
+              myPrint("WARN : component " + componentHcStr + " already existed in componentList, just ignore this one.");
+              return;
+          } else {
+              componentList.add(obj);
+          }
+      } else {
+          componentHcStr = "static";
+      }
+
+      // check if component instance's conf is shared with other component instances
+      Integer confToAdd = new Integer(myConf.hashCode());
+      if (!confHcComponentMap.containsKey(confToAdd)) {
+	  confHcComponentMap.put(confToAdd, component);
+	  myPrint("conf with hashCode " + confToAdd + " for " + component);
+      } else {
+	  myPrint("WARN : conf " + confToAdd + " existed in confInstanceList when adding.");
+	  Configuration copiedConf = new Configuration(myConf);
+	  myConf = copiedConf;
+	  confToAdd = new Integer(myConf.hashCode());
+	  if (!confHcComponentMap.containsKey(confToAdd)) {
+	      confHcComponentMap.put(confToAdd, component);
+	      myPrint("conf with hashCode " + confToAdd + " for " + component);
+	      myPrint("issue is fixed with copied configuration.");
+	  } else {
+	      myPrint("ERROR : conf " + confToAdd + " existed in confInstanceList when adding.");
+	  }
+      }
+
+      if (reconf_vvmode.equals("none")) {
+          myPrint(component + " init, vvmode is none, do nothing");
+      }
+
+      if (reconf_vvmode.equals("v1v1")) {
+          myConf.set(reconf_parameter, reconf_v1);
+          myPrint(component + " init " + componentHcStr + ", vvmode is " + reconf_vvmode + 
+			  ". Set value as v1 " + reconf_v1);// + " myConf is " + myConf.hashCode());
+      }
+
+      if ((reconf_vvmode.equals("v2v2"))) {
+          myConf.set(reconf_parameter, reconf_v2);
+          myPrint(component + " init " + componentHcStr + ", vvmode is " + reconf_vvmode + 
+			  ". Set value as v2 " + reconf_v2);//  + " myConf is " + myConf.hashCode());
+      }
+
+      if (reconf_vvmode.equals("v1v2")) { // reconfiguration injection
+          try {
+              //synchronized(this) {
+                  if (reconf_component.equals(component)) {
+                      if (reconf_point_int == -1) { //FF_ODD
+                          reconf_init_point_index ++;
+                          if ((reconf_init_point_index % 2) == 1) {
+                              myConf.set(reconf_parameter, reconf_v2);
+                              myPrint(component + " init " + componentHcStr + ", PERFORM V1V2 FF_ODD RECONF " + reconf_point +
+					      ". Set value as v2 " + reconf_v2);// + " myConf is " + myConf.hashCode());
+                          } else {
+                              myConf.set(reconf_parameter, reconf_v1);
+                              myPrint(component + " init " + componentHcStr + ", irrelevant init point " + reconf_init_point_index +
+					      ". Set value as v1 " + reconf_v1);// + " myConf is " + myConf.hashCode());
+                          }
+                      } else if (reconf_point_int == -2) { //FF_EVEN
+                          reconf_init_point_index ++;
+                          if ((reconf_init_point_index % 2) == 0) {
+                              myConf.set(reconf_parameter, reconf_v2);
+                              myPrint(component + " init " + componentHcStr + ", PERFORM V1V2 FF_EVEN RECONF " + reconf_point +
+					      ". Set value as v2 " + reconf_v2);// + " myConf is " + myConf.hashCode());
+                          } else {
+                              myConf.set(reconf_parameter, reconf_v1);
+                              myPrint(component + " init " + componentHcStr + ", irrelevant init point " + reconf_init_point_index +
+					      ". Set value as v1 " + reconf_v1);// + " myConf is " + myConf.hashCode());
+                          }
+		      } else {
+                          reconf_init_point_index ++;
+                          if (reconf_point_int == reconf_init_point_index) {
+                              myConf.set(reconf_parameter, reconf_v2);
+                              myPrint(component + " init " + componentHcStr + ", PERFORM V1V2 RECONF " + reconf_point +
+					      ". Set value as v2 " + reconf_v2);// + " myConf is " + myConf.hashCode());
+                          } else {
+                              myConf.set(reconf_parameter, reconf_v1);
+                              myPrint(component + " init " + componentHcStr + ", irrelevant init point " + reconf_init_point_index +
+					      " not " + reconf_point +
+					      ". Set value as v1 " + reconf_v1);// + " myConf is " + myConf.hashCode());
+                          }
+                      }
+                  } else { // for other component instances, just configure it to be v1
+                      myConf.set(reconf_parameter, reconf_v1);
+                      myPrint(component + " init " + componentHcStr + ", irrelevant component." +
+				      " Set value as v1 " + reconf_v1);// + " myConf is " + myConf.hashCode()); 
+                  }
+             // }
+          } catch (Exception e) {
+              myPrint("ERROR happened during performReconf");
+              System.exit(1);
+          }
+      }
+    }
+
+    private static void myPrint(String str) { System.out.println("msx-reconfagent " + str);}
+    
+    /*public ReconfAgent() {
+	String callerClassName = new Exception().getStackTrace()[1].getClassName();
+ 	myPrint("creating ReconfAgent " + this.hashCode() + " for " + callerClassName);
+    }*/
+    
+    /*public void checkReconfAtShutdown(Object obj, Configuration myConf) {
+	this.checkReconfAtShutdown(obj, obj.getClass().getSimpleName(), myConf);
+    }*/
+
+    /*public void performReconf(Object obj, Configuration myConf) {
+	this.performReconf(obj, obj.getClass().getSimpleName(), myConf);
+    }*/
+}
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java	2020-06-01 05:04:30.000000000 +0000
@@ -149,6 +149,7 @@
 
   @Override
   public void setConf(Configuration conf) {
+    Configuration.performReconf(this, "hdfs:JournalNode", conf);
     this.conf = conf;
 
     String journalNodeDir = null;
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Balancer.java	2020-06-01 05:04:30.000000000 +0000
@@ -264,6 +264,8 @@
    */
   Balancer(NameNodeConnector theblockpool, BalancerParameters p,
       Configuration conf) {
+    // msx
+    Configuration.performReconf(this, "hdfs:Balancer", conf);
     final long movedWinWidth = getLong(conf,
         DFSConfigKeys.DFS_BALANCER_MOVEDWINWIDTH_KEY,
         DFSConfigKeys.DFS_BALANCER_MOVEDWINWIDTH_DEFAULT);
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java	2020-06-01 05:04:30.000000000 +0000
@@ -419,6 +419,8 @@
   @InterfaceAudience.LimitedPrivate("HDFS")
   DataNode(final Configuration conf) throws DiskErrorException {
     super(conf);
+    // msx
+    Configuration.performReconf(this, "hdfs:DataNode", conf);
     this.tracer = createTracer(conf);
     this.tracerConfigurationManager =
         new TracerConfigurationManager(DATANODE_HTRACE_PREFIX, conf);
@@ -446,6 +448,8 @@
            final StorageLocationChecker storageLocationChecker,
            final SecureResources resources) throws IOException {
     super(conf);
+    // msx
+    Configuration.performReconf(this, "hdfs:DataNode", conf);
     this.tracer = createTracer(conf);
     this.tracerConfigurationManager =
         new TracerConfigurationManager(DATANODE_HTRACE_PREFIX, conf);
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/mover/Mover.java	2020-06-01 05:04:30.000000000 +0000
@@ -122,6 +122,8 @@
 
   Mover(NameNodeConnector nnc, Configuration conf, AtomicInteger retryCount,
       Map<Long, Set<DatanodeInfo>> excludedPinnedBlocks) {
+    // msx
+    Configuration.performReconf(this, "hdfs:Mover", conf);
     final long movedWinWidth = conf.getLong(
         DFSConfigKeys.DFS_MOVER_MOVEDWINWIDTH_KEY,
         DFSConfigKeys.DFS_MOVER_MOVEDWINWIDTH_DEFAULT);
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java	2020-06-01 05:04:30.000000000 +0000
@@ -88,6 +88,8 @@
   
   BackupNode(Configuration conf, NamenodeRole role) throws IOException {
     super(conf, role);
+    // msx
+    Configuration.performReconf(this, "hdfs:BackupNode", conf);
   }
 
   /////////////////////////////////////////////////////
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java	2020-06-01 05:04:30.000000000 +0000
@@ -929,6 +929,9 @@
   protected NameNode(Configuration conf, NamenodeRole role)
       throws IOException {
     super(conf);
+    // msx
+    Configuration.performReconf(this, "hdfs:NameNode", conf);
+
     this.tracer = new Tracer.Builder("NameNode").
         conf(TraceUtils.wrapHadoopConf(NAMENODE_HTRACE_PREFIX, conf)).
         build();
@@ -1646,6 +1649,8 @@
     boolean aborted = false;
     switch (startOpt) {
     case FORMAT:
+      // msx
+      Configuration.performReconf(null, "hdfs:NameNode_FORMAT", conf);
       aborted = format(conf, startOpt.getForceFormat(),
           startOpt.getInteractiveFormat());
       terminate(aborted ? 1 : 0);
@@ -1656,15 +1661,21 @@
       terminate(0);
       return null;
     case ROLLBACK:
+      // msx
+      Configuration.performReconf(null, "hdfs:NameNode_ROLLBACK", conf);
       aborted = doRollback(conf, true);
       terminate(aborted ? 1 : 0);
       return null; // avoid warning
     case BOOTSTRAPSTANDBY:
+      // msx
+      Configuration.performReconf(null, "hdfs:NameNode_BOOTSTRAPSTANDBY", conf);
       String[] toolArgs = Arrays.copyOfRange(argv, 1, argv.length);
       int rc = BootstrapStandby.run(toolArgs, conf);
       terminate(rc);
       return null; // avoid warning
     case INITIALIZESHAREDEDITS:
+      // msx
+      Configuration.performReconf(null, "hdfs:NameNode_INITIALIZESHAREDEDITS", conf);
       aborted = initializeSharedEdits(conf,
           startOpt.getForceFormat(),
           startOpt.getInteractiveFormat());
@@ -1676,9 +1687,13 @@
       DefaultMetricsSystem.initialize(role.toString().replace(" ", ""));
       return new BackupNode(conf, role);
     case RECOVER:
+      // msx
+      Configuration.performReconf(null, "hdfs:NameNode_RECOVER", conf);
       NameNode.doRecovery(startOpt, conf);
       return null;
     case METADATAVERSION:
+      // msx
+      Configuration.performReconf(null, "hdfs:NameNode_METADATAVERSION", conf);
       printMetadataVersion(conf);
       terminate(0);
       return null; // avoid javac warning
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/SecondaryNameNode.java	2020-06-01 05:04:30.000000000 +0000
@@ -183,6 +183,8 @@
   
   public SecondaryNameNode(Configuration conf,
       CommandLineOpts commandLineOpts) throws IOException {
+    // msx
+    Configuration.performReconf(this, "hdfs:SecondaryNameNode", conf);
     try {
       String nsId = DFSUtil.getSecondaryNameServiceId(conf);
       if (HAUtil.isHAEnabled(conf, nsId)) {
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java	2020-06-01 05:04:30.000000000 +0000
@@ -92,6 +92,8 @@
 
   public StoragePolicySatisfier(Configuration conf) {
     this.conf = conf;
+    // msx
+    Configuration.performReconf(this, "hdfs:StoragePolicySatisfier", conf);
   }
 
   /**
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java	2020-06-01 05:04:30.000000000 +0000
@@ -482,6 +482,8 @@
    */
   public DFSAdmin(Configuration conf) {
     super(conf);
+    // msx
+    Configuration.performReconf(this, "hdfs:DFSAdmin", conf);
   }
   
   protected DistributedFileSystem getDFS() throws IOException {
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSHAAdmin.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSHAAdmin.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSHAAdmin.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSHAAdmin.java	2020-06-01 05:04:30.000000000 +0000
@@ -56,6 +56,8 @@
       conf = addSecurityConfiguration(conf);
     }
     super.setConf(conf);
+    // msx
+    Configuration.performReconf(this, "hdfs:DFSHAAdmin", conf);
   }
 
   /**
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSZKFailoverController.java	2020-06-01 05:04:30.000000000 +0000
@@ -127,6 +127,8 @@
   }
   
   public static DFSZKFailoverController create(Configuration conf) {
+    // msx
+    Configuration.performReconf(null, "hdfs:DFSZKFailoverController_create", conf);
     Configuration localNNConf = DFSHAAdmin.addSecurityConfiguration(conf);
     String nsId = DFSUtil.getNamenodeNameServiceId(conf);
 
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSck.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSck.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSck.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSck.java	2020-06-01 05:04:30.000000000 +0000
@@ -130,6 +130,7 @@
 
   public DFSck(Configuration conf, PrintStream out) throws IOException {
     super(conf);
+    Configuration.performReconf(this, "hdfs:DFSck", conf);
     this.ugi = UserGroupInformation.getCurrentUser();
     this.out = out;
     this.connectionFactory = URLConnectionFactory
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DiskBalancerCLI.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DiskBalancerCLI.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DiskBalancerCLI.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DiskBalancerCLI.java	2020-06-01 05:04:30.000000000 +0000
@@ -160,6 +160,8 @@
   public DiskBalancerCLI(Configuration conf, final PrintStream printStream) {
     super(conf);
     this.printStream = printStream;
+    // msx
+    Configuration.performReconf(this, "hdfs:DiskBalancerCLI", conf);
   }
 
   /**
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetConf.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetConf.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetConf.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetConf.java	2020-06-01 05:04:30.000000000 +0000
@@ -279,6 +279,7 @@
 
   GetConf(Configuration conf, PrintStream out, PrintStream err) {
     super(conf);
+    Configuration.performReconf(this, "hdfs:GetConf", conf);
     this.out = out;
     this.err = err;
   }
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetGroups.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetGroups.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetGroups.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/GetGroups.java	2020-06-01 05:04:30.000000000 +0000
@@ -54,10 +54,14 @@
   
   public GetGroups(Configuration conf) {
     super(conf);
+    // msx
+    Configuration.performReconf(this, "hdfs:GetGroups", conf);
   }
 
   public GetGroups(Configuration conf, PrintStream out) {
     super(conf, out);
+    // msx
+    Configuration.performReconf(this, "hdfs:GetGroups", conf);
   }
   
   @Override
@@ -96,4 +100,4 @@
     int res = ToolRunner.run(new GetGroups(new HdfsConfiguration()), argv);
     System.exit(res);
   }
-}
\ No newline at end of file
+}
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/snapshot/SnapshotDiff.java ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/snapshot/SnapshotDiff.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/snapshot/SnapshotDiff.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/snapshot/SnapshotDiff.java	2020-06-01 05:04:30.000000000 +0000
@@ -55,6 +55,7 @@
    */
   public SnapshotDiff(Configuration conf) {
     super(conf);
+    Configuration.performReconf(this, "hdfs:SnapshotDiff", conf);
   }
   private static String getSnapshotName(String name) {
     if (Path.CUR_DIR.equals(name)) { // current directory
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/Router.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/Router.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/Router.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/Router.java	2020-06-01 05:04:30.000000000 +0000
@@ -143,6 +143,8 @@
   @Override
   protected void serviceInit(Configuration configuration) throws Exception {
     this.conf = configuration;
+    // msx
+    Configuration.performReconf(this, "hdfs:Router", this.conf);
     updateRouterState(RouterServiceState.INITIALIZING);
 
     if (conf.getBoolean(
diff -ruN /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/tools/federation/RouterAdmin.java ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/tools/federation/RouterAdmin.java
--- /hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/tools/federation/RouterAdmin.java	2019-09-10 14:35:49.000000000 +0000
+++ ./hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/tools/federation/RouterAdmin.java	2020-06-01 05:04:30.000000000 +0000
@@ -88,6 +88,8 @@
 
   public RouterAdmin(Configuration conf) {
     super(conf);
+    // msx
+    Configuration.performReconf(this, "hdfs:RouterAdmin", conf);
   }
 
   /**
@@ -924,4 +926,4 @@
       return mode;
     }
   }
-}
\ No newline at end of file
+}
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java	2019-09-10 14:35:50.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java	2020-06-01 05:04:30.000000000 +0000
@@ -75,6 +75,8 @@
     LOG.debug("Child starting");
 
     final JobConf job = new JobConf(MRJobConfig.JOB_CONF_FILE);
+    // msx
+    //Configuration.performReconf(null, "YarnChildMain", job);
     // Initing with our JobConf allows us to avoid loading confs twice
     Limits.init(job);
     UserGroupInformation.setConfiguration(job);
@@ -289,6 +291,9 @@
 
   private static void configureTask(JobConf job, Task task,
       Credentials credentials, Token<JobTokenIdentifier> jt) throws IOException {
+    // msx
+    job.performReconf(null, "mapreduce:YarnChild_configureTask", job);
+  
     job.setCredentials(credentials);
 
     ApplicationAttemptId appAttemptId = ContainerId.fromString(
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java	2019-09-10 14:35:50.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java	2020-06-01 05:04:30.000000000 +0000
@@ -278,6 +278,8 @@
 
   @Override
   protected void serviceInit(final Configuration conf) throws Exception {
+    // msx
+    Configuration.performReconf(this, "mapreduce:MRAppMaster", conf);
     // create the job classloader if enabled
     createJobClassLoader(conf);
 
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobClient.java ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobClient.java
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobClient.java	2019-09-10 14:35:50.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobClient.java	2020-06-01 05:04:30.000000000 +0000
@@ -471,6 +471,8 @@
    * @throws IOException
    */
   public void init(JobConf conf) throws IOException {
+    // msx
+    Configuration.performReconf(this, "mapreduce:JobClient", conf);
     setConf(conf);
     cluster = new Cluster(conf);
     clientUgi = UserGroupInformation.getCurrentUser();
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobQueueClient.java ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobQueueClient.java
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobQueueClient.java	2019-09-10 14:35:50.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobQueueClient.java	2020-06-01 18:34:00.965450794 +0000
@@ -25,6 +25,9 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 
+// msx
+import org.apache.hadoop.conf.Configuration;
+
 import org.apache.hadoop.conf.Configured;
 import org.apache.hadoop.mapreduce.JobStatus;
 import org.apache.hadoop.security.UserGroupInformation;
@@ -51,11 +54,15 @@
 
   public JobQueueClient(JobConf conf) throws IOException {
     setConf(conf);
+    // msx
+    Configuration.performReconf(this, "mapreduce:JobQueueClient", conf);
   }
 
   private void init(JobConf conf) throws IOException {
     setConf(conf);
     jc = new JobClient(conf);
+    // msx
+    Configuration.performReconf(this, "mapreduce:JobQueueClient", conf);
   }
 
   @Override
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java	2019-09-10 14:35:50.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java	2020-06-01 05:04:30.000000000 +0000
@@ -90,6 +90,7 @@
   
   public Submitter(Configuration conf) {
     setConf(conf);
+    Configuration.performReconf(this, "mapreduce:Submitter", conf);
   }
   
   /**
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/tools/CLI.java ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/tools/CLI.java
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/tools/CLI.java	2019-09-10 14:35:50.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/tools/CLI.java	2020-06-01 05:04:30.000000000 +0000
@@ -84,6 +84,8 @@
   
   public CLI(Configuration conf) {
     setConf(conf);
+    // msx
+    Configuration.performReconf(this, "mapreduce:CLI", conf);
   }
   
   public int run(String[] argv) throws Exception {
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java	2019-09-10 14:35:50.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java	2020-06-01 05:04:30.000000000 +0000
@@ -119,6 +119,8 @@
   @Override
   protected void serviceInit(Configuration conf) throws Exception {
     Configuration config = new YarnConfiguration(conf);
+    // msx
+    Configuration.performReconf(this, "mapreduce:JobHistoryServer", config);
 
     // This is required for WebApps to use https if enabled.
     MRWebAppUtil.initialize(getConfig());
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/client/HSAdmin.java ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/client/HSAdmin.java
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/client/HSAdmin.java	2019-09-10 14:35:50.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/client/HSAdmin.java	2020-06-01 05:04:30.000000000 +0000
@@ -45,6 +45,8 @@
 
   public HSAdmin(JobConf conf) {
     super(conf);
+    // msx
+    Configuration.performReconf(this, "mapreduce:HSAdmin", conf);
   }
 
   @Override
@@ -52,6 +54,8 @@
     if (conf != null) {
       conf = addSecurityConfiguration(conf);
     }
+    // msx
+    Configuration.performReconf(this, "mapreduce:HSAdmin", conf);
     super.setConf(conf);
   }
 
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/jobTokenPassword ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/jobTokenPassword
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/jobTokenPassword	1970-01-01 00:00:00.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/jobTokenPassword	2020-06-01 05:04:30.000000000 +0000
@@ -0,0 +1 @@
+password
\ No newline at end of file
diff -ruN /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/MiniMRYarnCluster.java ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/MiniMRYarnCluster.java
--- /hadoop-3.2.1-src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/MiniMRYarnCluster.java	2019-09-10 14:35:50.000000000 +0000
+++ ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/MiniMRYarnCluster.java	2020-06-01 05:04:30.000000000 +0000
@@ -233,6 +233,15 @@
     }
     private volatile boolean jhsStarted = false;
 
+    // msx
+    @Override
+    public synchronized void serviceInit(Configuration conf) throws Exception {
+        Configuration config = new YarnConfiguration(conf);
+        // msx
+        Configuration.performReconf(this, "mapreduce:JobHistoryServer", config);
+        super.serviceInit(config);
+    }
+
     @Override
     public synchronized void serviceStart() throws Exception {
       try {
