msx-listener test started org.apache.hadoop.tools.TestHadoopArchives#testRelativePathWitRepl
msx-listener unitTestCounterInClass = 0
2020-04-16 00:19:51,958 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-16 00:19:52,894 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:52,909 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:52,911 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:52,912 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:52,956 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:52,956 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:52,957 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:52,958 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:53,030 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:53,037 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-16 00:19:53,038 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:53,039 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:53,048 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:53,049 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:53
2020-04-16 00:19:53,051 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:53,053 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:53,056 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-16 00:19:53,056 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:53,080 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:53,081 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:53,105 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:53,106 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:53,106 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:53,107 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:53,108 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:53,108 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:53,109 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:53,109 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:53,109 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:53,110 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:53,110 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:53,159 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-04-16 00:19:53,159 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:53,160 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:53,160 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:53,182 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:53,182 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:53,183 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-16 00:19:53,183 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:53,189 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:53,190 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:53,190 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:53,191 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:53,200 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:53,204 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:53,213 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:53,214 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:53,215 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-16 00:19:53,215 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:53,232 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:53,233 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:53,233 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:53,240 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:53,241 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:53,244 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:53,245 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:53,246 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-16 00:19:53,246 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:53,308 INFO  [main] namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:19:53,328 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 has been successfully formatted.
2020-04-16 00:19:53,332 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 has been successfully formatted.
2020-04-16 00:19:53,378 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:53,381 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:53,543 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:53,543 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:53,574 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-16 00:19:53,579 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1635)) - createNameNode []
2020-04-16 00:19:53,664 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-04-16 00:19:54,355 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-04-16 00:19:54,355 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-16 00:19:54,362 INFO  [main] namenode.NameNode (NameNode.java:<init>(932)) - msx-hdfs NameNode init
2020-04-16 00:19:54,419 INFO  [main] namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-16 00:19:54,461 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2205a05d] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:54,479 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-16 00:19:54,507 INFO  [main] util.log (Log.java:initialized(192)) - Logging initialized @4399ms
2020-04-16 00:19:54,661 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:54,667 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-16 00:19:54,684 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:54,688 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-16 00:19:54,688 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:54,689 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:54,719 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-16 00:19:54,719 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-16 00:19:54,731 INFO  [main] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39759
2020-04-16 00:19:54,733 INFO  [main] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:54,787 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:54,789 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:55,203 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33fe57a9{/,file:///tmp/jetty-localhost-39759-hdfs-_-any-8328276877045048470.dir/webapp/,AVAILABLE}{/hdfs}
2020-04-16 00:19:55,211 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:39759}
2020-04-16 00:19:55,212 INFO  [main] server.Server (Server.java:doStart(419)) - Started @5104ms
2020-04-16 00:19:55,227 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:55,228 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:55,229 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:55,230 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:55,230 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:55,230 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:55,231 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:55,231 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:55,232 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:55,233 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:55,233 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:55,234 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:55,235 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:55
2020-04-16 00:19:55,235 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:55,236 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:55,236 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-16 00:19:55,236 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:55,240 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:55,240 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:55,241 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:55,242 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:55,242 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:55,242 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:55,243 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:55,243 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:55,243 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:55,243 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:55,243 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:55,244 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:55,244 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:55,244 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:55,245 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:55,245 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-16 00:19:55,246 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:55,248 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:55,249 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:55,249 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:55,249 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:55,250 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:55,250 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:55,250 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:55,250 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:55,251 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-16 00:19:55,251 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:55,252 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:55,252 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:55,252 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:55,253 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:55,253 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:55,253 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:55,253 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:55,254 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-16 00:19:55,254 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:55,265 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/in_use.lock acquired by nodename 6746@762b67df8ca0
2020-04-16 00:19:55,268 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/in_use.lock acquired by nodename 6746@762b67df8ca0
2020-04-16 00:19:55,272 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current
2020-04-16 00:19:55,273 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current
2020-04-16 00:19:55,274 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-04-16 00:19:55,274 INFO  [main] namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-16 00:19:55,323 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-04-16 00:19:55,338 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-04-16 00:19:55,339 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-16 00:19:55,346 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-16 00:19:55,348 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-04-16 00:19:55,403 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-16 00:19:55,404 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 148 msecs
2020-04-16 00:19:55,677 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-04-16 00:19:55,722 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:55,747 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:56,042 INFO  [Listener at localhost/36933] namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:36933 to access this namenode/service.
2020-04-16 00:19:56,046 INFO  [Listener at localhost/36933] namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-16 00:19:56,105 INFO  [Listener at localhost/36933] namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-16 00:19:56,149 INFO  [Listener at localhost/36933] blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-04-16 00:19:56,150 INFO  [Listener at localhost/36933] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-04-16 00:19:56,150 INFO  [Listener at localhost/36933] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-16 00:19:56,150 INFO  [Listener at localhost/36933] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-16 00:19:56,154 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-04-16 00:19:56,154 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-04-16 00:19:56,155 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-04-16 00:19:56,155 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-04-16 00:19:56,155 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-04-16 00:19:56,155 INFO  [Reconstruction Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-16 00:19:56,215 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:56,215 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:56,248 INFO  [Listener at localhost/36933] namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:36933
2020-04-16 00:19:56,251 INFO  [Listener at localhost/36933] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-04-16 00:19:56,251 INFO  [Listener at localhost/36933] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-04-16 00:19:56,265 INFO  [Listener at localhost/36933] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 13 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-16 00:19:56,283 INFO  [Listener at localhost/36933] namenode.NameNode (NameNode.java:<init>(969)) - msx-hdfs NameNode start
2020-04-16 00:19:56,283 INFO  [CacheReplicationMonitor(247976210)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-16 00:19:56,312 INFO  [Listener at localhost/36933] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:56,452 INFO  [Listener at localhost/36933] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:56,478 INFO  [Listener at localhost/36933] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:56,622 INFO  [Listener at localhost/36933] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:56,622 INFO  [Listener at localhost/36933] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:56,643 INFO  [Listener at localhost/36933] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:56,647 INFO  [Listener at localhost/36933] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:56,652 INFO  [Listener at localhost/36933] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:56,656 INFO  [Listener at localhost/36933] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:56,662 INFO  [Listener at localhost/36933] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:56,672 INFO  [Listener at localhost/36933] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:41407
2020-04-16 00:19:56,678 INFO  [Listener at localhost/36933] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:56,678 INFO  [Listener at localhost/36933] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:56,734 INFO  [Listener at localhost/36933] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:56,736 INFO  [Listener at localhost/36933] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:56,740 INFO  [Listener at localhost/36933] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:56,746 INFO  [Listener at localhost/36933] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:56,746 INFO  [Listener at localhost/36933] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:56,746 INFO  [Listener at localhost/36933] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:56,761 INFO  [Listener at localhost/36933] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35545
2020-04-16 00:19:56,761 INFO  [Listener at localhost/36933] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:56,766 INFO  [Listener at localhost/36933] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7726e185{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:56,767 INFO  [Listener at localhost/36933] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@282308c3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:57,030 INFO  [Listener at localhost/36933] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1af1347d{/,file:///tmp/jetty-localhost-35545-datanode-_-any-1609190566361929590.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:57,031 INFO  [Listener at localhost/36933] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:35545}
2020-04-16 00:19:57,032 INFO  [Listener at localhost/36933] server.Server (Server.java:doStart(419)) - Started @6924ms
2020-04-16 00:19:58,074 INFO  [Listener at localhost/36933] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36559
2020-04-16 00:19:58,078 INFO  [Listener at localhost/36933] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:58,079 INFO  [Listener at localhost/36933] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:58,105 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61f2c3f0] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:58,139 INFO  [Listener at localhost/36933] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:58,140 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:58,181 INFO  [Listener at localhost/38261] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:38261
2020-04-16 00:19:58,208 INFO  [Listener at localhost/38261] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:58,210 INFO  [Listener at localhost/38261] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:58,238 INFO  [Thread-58] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36933 starting to offer service
2020-04-16 00:19:58,265 INFO  [Listener at localhost/38261] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:58,282 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:58,286 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:58,355 INFO  [Listener at localhost/38261] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:58,357 INFO  [Listener at localhost/38261] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:58,361 INFO  [Listener at localhost/38261] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:58,445 INFO  [Listener at localhost/38261] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:58,445 INFO  [Listener at localhost/38261] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:58,453 INFO  [Listener at localhost/38261] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:58,453 INFO  [Listener at localhost/38261] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:58,454 INFO  [Listener at localhost/38261] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:58,454 INFO  [Listener at localhost/38261] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:58,455 INFO  [Listener at localhost/38261] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:58,456 INFO  [Listener at localhost/38261] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:33532
2020-04-16 00:19:58,456 INFO  [Listener at localhost/38261] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:58,456 INFO  [Listener at localhost/38261] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:58,481 INFO  [Listener at localhost/38261] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:58,521 INFO  [Listener at localhost/38261] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:58,526 INFO  [Listener at localhost/38261] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:58,528 INFO  [Listener at localhost/38261] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:58,528 INFO  [Listener at localhost/38261] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:58,528 INFO  [Listener at localhost/38261] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:58,533 INFO  [Listener at localhost/38261] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40887
2020-04-16 00:19:58,534 INFO  [Listener at localhost/38261] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:58,554 INFO  [Listener at localhost/38261] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30feffc{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:58,555 INFO  [Listener at localhost/38261] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@bcb09a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:58,957 INFO  [Listener at localhost/38261] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58065f0c{/,file:///tmp/jetty-localhost-40887-datanode-_-any-4024085187485488845.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:58,958 INFO  [Listener at localhost/38261] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3605c4d3{HTTP/1.1,[http/1.1]}{localhost:40887}
2020-04-16 00:19:58,958 INFO  [Listener at localhost/38261] server.Server (Server.java:doStart(419)) - Started @8850ms
2020-04-16 00:19:59,223 INFO  [Thread-58] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36933
2020-04-16 00:19:59,228 INFO  [Listener at localhost/38261] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38866
2020-04-16 00:19:59,229 INFO  [Listener at localhost/38261] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:59,229 INFO  [Listener at localhost/38261] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:59,230 INFO  [Listener at localhost/38261] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:59,231 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@187eb9a8] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:59,232 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:59,249 INFO  [Thread-58] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:59,249 INFO  [Listener at localhost/42762] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:42762
2020-04-16 00:19:59,254 INFO  [Listener at localhost/42762] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:59,254 INFO  [Listener at localhost/42762] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:59,261 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/in_use.lock acquired by nodename 6746@762b67df8ca0
2020-04-16 00:19:59,269 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 is not formatted for namespace 1945263739. Formatting...
2020-04-16 00:19:59,274 INFO  [Listener at localhost/42762] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:59,273 INFO  [Thread-81] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36933 starting to offer service
2020-04-16 00:19:59,274 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-90b72aab-26bc-4685-9dc2-072a09488728 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 
2020-04-16 00:19:59,276 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:59,277 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:59,279 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/in_use.lock acquired by nodename 6746@762b67df8ca0
2020-04-16 00:19:59,279 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 is not formatted for namespace 1945263739. Formatting...
2020-04-16 00:19:59,279 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-91b791b7-d2ef-4e6c-bf71-1bd69ab06e7d for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 
2020-04-16 00:19:59,338 INFO  [Listener at localhost/42762] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:59,341 INFO  [Listener at localhost/42762] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:59,345 INFO  [Listener at localhost/42762] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:59,348 INFO  [Listener at localhost/42762] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:59,348 INFO  [Listener at localhost/42762] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:59,348 INFO  [Listener at localhost/42762] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:59,349 INFO  [Listener at localhost/42762] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:59,350 INFO  [Listener at localhost/42762] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:59,350 INFO  [Listener at localhost/42762] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:59,350 INFO  [Listener at localhost/42762] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:59,351 INFO  [Listener at localhost/42762] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:34802
2020-04-16 00:19:59,351 INFO  [Listener at localhost/42762] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:59,351 INFO  [Listener at localhost/42762] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:59,402 INFO  [Listener at localhost/42762] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:59,413 INFO  [Listener at localhost/42762] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:59,428 INFO  [Listener at localhost/42762] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:59,430 INFO  [Listener at localhost/42762] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:59,431 INFO  [Listener at localhost/42762] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:59,431 INFO  [Listener at localhost/42762] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:59,437 INFO  [Listener at localhost/42762] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33585
2020-04-16 00:19:59,438 INFO  [Listener at localhost/42762] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:59,446 INFO  [Listener at localhost/42762] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@466d49f0{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:59,447 INFO  [Listener at localhost/42762] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d7e1102{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:59,471 INFO  [Thread-81] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36933
2020-04-16 00:19:59,472 INFO  [Thread-81] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:59,474 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/in_use.lock acquired by nodename 6746@762b67df8ca0
2020-04-16 00:19:59,474 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 is not formatted for namespace 1945263739. Formatting...
2020-04-16 00:19:59,474 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d19d1bfb-b060-41c8-9937-b040d3d54dba for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 
2020-04-16 00:19:59,490 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:19:59,490 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:19:59,491 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 and block pool id BP-1625354301-172.17.0.4-1586996393290 is not formatted. Formatting ...
2020-04-16 00:19:59,492 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1625354301-172.17.0.4-1586996393290 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1625354301-172.17.0.4-1586996393290/current
2020-04-16 00:19:59,493 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/in_use.lock acquired by nodename 6746@762b67df8ca0
2020-04-16 00:19:59,493 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 is not formatted for namespace 1945263739. Formatting...
2020-04-16 00:19:59,494 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-67b93d4b-33c1-4121-a753-b759c3d3c4be for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 
2020-04-16 00:19:59,537 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:19:59,538 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:19:59,538 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 and block pool id BP-1625354301-172.17.0.4-1586996393290 is not formatted. Formatting ...
2020-04-16 00:19:59,538 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1625354301-172.17.0.4-1586996393290 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1625354301-172.17.0.4-1586996393290/current
2020-04-16 00:19:59,564 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:19:59,565 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:19:59,565 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 and block pool id BP-1625354301-172.17.0.4-1586996393290 is not formatted. Formatting ...
2020-04-16 00:19:59,569 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1625354301-172.17.0.4-1586996393290 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1625354301-172.17.0.4-1586996393290/current
2020-04-16 00:19:59,584 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:19:59,585 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:19:59,585 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 and block pool id BP-1625354301-172.17.0.4-1586996393290 is not formatted. Formatting ...
2020-04-16 00:19:59,585 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1625354301-172.17.0.4-1586996393290 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1625354301-172.17.0.4-1586996393290/current
2020-04-16 00:19:59,586 INFO  [Thread-58] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=1945263739;bpid=BP-1625354301-172.17.0.4-1586996393290;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1945263739;c=1586996393290;bpid=BP-1625354301-172.17.0.4-1586996393290;dnuuid=null
2020-04-16 00:19:59,588 INFO  [Thread-58] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID 73911b40-4bf0-4055-899b-855a2f4b3f8b
2020-04-16 00:19:59,601 INFO  [Thread-81] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=1945263739;bpid=BP-1625354301-172.17.0.4-1586996393290;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1945263739;c=1586996393290;bpid=BP-1625354301-172.17.0.4-1586996393290;dnuuid=null
2020-04-16 00:19:59,614 INFO  [Thread-81] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID efe0c969-7bdf-48e1-a105-e13d221fef55
2020-04-16 00:19:59,786 INFO  [Listener at localhost/42762] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@17ae7628{/,file:///tmp/jetty-localhost-33585-datanode-_-any-4215984003927394846.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:59,787 INFO  [Listener at localhost/42762] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1136b469{HTTP/1.1,[http/1.1]}{localhost:33585}
2020-04-16 00:19:59,787 INFO  [Listener at localhost/42762] server.Server (Server.java:doStart(419)) - Started @9679ms
2020-04-16 00:19:59,824 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-90b72aab-26bc-4685-9dc2-072a09488728
2020-04-16 00:19:59,824 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, StorageType: DISK
2020-04-16 00:19:59,840 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d19d1bfb-b060-41c8-9937-b040d3d54dba
2020-04-16 00:19:59,868 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, StorageType: DISK
2020-04-16 00:19:59,868 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-91b791b7-d2ef-4e6c-bf71-1bd69ab06e7d
2020-04-16 00:19:59,909 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-67b93d4b-33c1-4121-a753-b759c3d3c4be
2020-04-16 00:19:59,943 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, StorageType: DISK
2020-04-16 00:19:59,945 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, StorageType: DISK
2020-04-16 00:19:59,954 INFO  [Listener at localhost/42762] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36250
2020-04-16 00:19:59,973 INFO  [Listener at localhost/42762] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:59,973 INFO  [Listener at localhost/42762] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:59,974 INFO  [Listener at localhost/42762] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:59,976 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:59,980 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:59,973 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b87581] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:59,977 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:59,991 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:59,994 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:20:00,007 INFO  [Listener at localhost/43227] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:43227
2020-04-16 00:20:00,016 INFO  [Listener at localhost/43227] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:20:00,023 INFO  [Listener at localhost/43227] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:20:00,027 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:20:00,032 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:20:00,034 INFO  [Thread-107] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36933 starting to offer service
2020-04-16 00:20:00,034 INFO  [Listener at localhost/43227] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:20:00,042 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:20:00,042 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:20:00,044 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:20:00,045 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,047 INFO  [Thread-118] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:20:00,049 INFO  [Thread-119] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:20:00,037 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:20:00,081 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:20:00,081 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:20:00,178 INFO  [Thread-107] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36933
2020-04-16 00:20:00,181 INFO  [Thread-107] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:20:00,189 INFO  [Thread-107] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/in_use.lock acquired by nodename 6746@762b67df8ca0
2020-04-16 00:20:00,189 INFO  [Thread-107] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 is not formatted for namespace 1945263739. Formatting...
2020-04-16 00:20:00,190 INFO  [Thread-107] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d35976da-fb2b-4e5b-abd2-053a6a89886d for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 
2020-04-16 00:20:00,197 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,209 INFO  [Thread-122] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:20:00,243 INFO  [Thread-123] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:20:00,251 INFO  [Thread-107] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/in_use.lock acquired by nodename 6746@762b67df8ca0
2020-04-16 00:20:00,264 INFO  [Thread-107] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 is not formatted for namespace 1945263739. Formatting...
2020-04-16 00:20:00,265 INFO  [Thread-107] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7fc4eb70-14dd-484f-bea9-af9dfed87997 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 
2020-04-16 00:20:00,282 INFO  [Thread-118] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1625354301-172.17.0.4-1586996393290 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 233ms
2020-04-16 00:20:00,357 INFO  [Thread-119] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1625354301-172.17.0.4-1586996393290 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 298ms
2020-04-16 00:20:00,361 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1625354301-172.17.0.4-1586996393290: 316ms
2020-04-16 00:20:00,365 INFO  [Thread-126] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:20:00,365 INFO  [Thread-126] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1625354301-172.17.0.4-1586996393290/current/replicas doesn't exist 
2020-04-16 00:20:00,366 INFO  [Thread-127] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:20:00,394 INFO  [Thread-126] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 29ms
2020-04-16 00:20:00,366 INFO  [Thread-127] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1625354301-172.17.0.4-1586996393290/current/replicas doesn't exist 
2020-04-16 00:20:00,398 INFO  [Thread-122] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1625354301-172.17.0.4-1586996393290 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 188ms
2020-04-16 00:20:00,405 INFO  [Thread-123] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1625354301-172.17.0.4-1586996393290 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 162ms
2020-04-16 00:20:00,406 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1625354301-172.17.0.4-1586996393290: 209ms
2020-04-16 00:20:00,407 INFO  [Thread-107] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,407 INFO  [Thread-107] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,407 INFO  [Thread-107] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 and block pool id BP-1625354301-172.17.0.4-1586996393290 is not formatted. Formatting ...
2020-04-16 00:20:00,407 INFO  [Thread-107] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1625354301-172.17.0.4-1586996393290 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1625354301-172.17.0.4-1586996393290/current
2020-04-16 00:20:00,419 INFO  [Thread-129] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:20:00,426 INFO  [Thread-129] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1625354301-172.17.0.4-1586996393290/current/replicas doesn't exist 
2020-04-16 00:20:00,418 INFO  [Thread-128] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:20:00,426 INFO  [Thread-128] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1625354301-172.17.0.4-1586996393290/current/replicas doesn't exist 
2020-04-16 00:20:00,432 INFO  [Thread-129] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 6ms
2020-04-16 00:20:00,409 INFO  [Thread-127] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 43ms
2020-04-16 00:20:00,433 INFO  [Thread-128] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 7ms
2020-04-16 00:20:00,447 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290: 41ms
2020-04-16 00:20:00,449 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290: 87ms
2020-04-16 00:20:00,454 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:20:00,455 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-90b72aab-26bc-4685-9dc2-072a09488728): finished scanning block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,460 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:20:00,523 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-91b791b7-d2ef-4e6c-bf71-1bd69ab06e7d): finished scanning block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,473 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:20:00,525 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-d19d1bfb-b060-41c8-9937-b040d3d54dba): finished scanning block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,476 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:20:00,529 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-67b93d4b-33c1-4121-a753-b759c3d3c4be): finished scanning block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,567 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-90b72aab-26bc-4685-9dc2-072a09488728): no suitable block pools found to scan.  Waiting 1814399882 ms.
2020-04-16 00:20:00,581 INFO  [Thread-58] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 3:01 AM with interval of 21600000ms
2020-04-16 00:20:00,583 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-67b93d4b-33c1-4121-a753-b759c3d3c4be): no suitable block pools found to scan.  Waiting 1814399886 ms.
2020-04-16 00:20:00,582 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-d19d1bfb-b060-41c8-9937-b040d3d54dba): no suitable block pools found to scan.  Waiting 1814399887 ms.
2020-04-16 00:20:00,582 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-91b791b7-d2ef-4e6c-bf71-1bd69ab06e7d): no suitable block pools found to scan.  Waiting 1814399867 ms.
2020-04-16 00:20:00,586 INFO  [Thread-107] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,583 INFO  [Thread-81] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 3:23 AM with interval of 21600000ms
2020-04-16 00:20:00,609 INFO  [Thread-107] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,609 INFO  [Thread-107] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 and block pool id BP-1625354301-172.17.0.4-1586996393290 is not formatted. Formatting ...
2020-04-16 00:20:00,609 INFO  [Thread-107] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1625354301-172.17.0.4-1586996393290 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1625354301-172.17.0.4-1586996393290/current
2020-04-16 00:20:00,620 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid efe0c969-7bdf-48e1-a105-e13d221fef55) service to localhost/127.0.0.1:36933 beginning handshake with NN
2020-04-16 00:20:00,622 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid 73911b40-4bf0-4055-899b-855a2f4b3f8b) service to localhost/127.0.0.1:36933 beginning handshake with NN
2020-04-16 00:20:00,624 INFO  [Thread-107] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=1945263739;bpid=BP-1625354301-172.17.0.4-1586996393290;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1945263739;c=1586996393290;bpid=BP-1625354301-172.17.0.4-1586996393290;dnuuid=null
2020-04-16 00:20:00,628 INFO  [Thread-107] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID e5510087-6ff2-4fde-8f98-ca8c189bd02a
2020-04-16 00:20:00,650 INFO  [IPC Server handler 4 on default port 36933] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41407, datanodeUuid=73911b40-4bf0-4055-899b-855a2f4b3f8b, infoPort=36559, infoSecurePort=0, ipcPort=38261, storageInfo=lv=-57;cid=testClusterID;nsid=1945263739;c=1586996393290) storage 73911b40-4bf0-4055-899b-855a2f4b3f8b
2020-04-16 00:20:00,653 INFO  [IPC Server handler 4 on default port 36933] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41407
2020-04-16 00:20:00,654 INFO  [IPC Server handler 4 on default port 36933] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 73911b40-4bf0-4055-899b-855a2f4b3f8b (127.0.0.1:41407).
2020-04-16 00:20:00,655 INFO  [Thread-107] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d35976da-fb2b-4e5b-abd2-053a6a89886d
2020-04-16 00:20:00,656 INFO  [Thread-107] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, StorageType: DISK
2020-04-16 00:20:00,657 INFO  [IPC Server handler 3 on default port 36933] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33532, datanodeUuid=efe0c969-7bdf-48e1-a105-e13d221fef55, infoPort=38866, infoSecurePort=0, ipcPort=42762, storageInfo=lv=-57;cid=testClusterID;nsid=1945263739;c=1586996393290) storage efe0c969-7bdf-48e1-a105-e13d221fef55
2020-04-16 00:20:00,657 INFO  [IPC Server handler 3 on default port 36933] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33532
2020-04-16 00:20:00,665 INFO  [Thread-107] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7fc4eb70-14dd-484f-bea9-af9dfed87997
2020-04-16 00:20:00,666 INFO  [Thread-107] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, StorageType: DISK
2020-04-16 00:20:00,666 INFO  [Thread-107] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:20:00,666 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid 73911b40-4bf0-4055-899b-855a2f4b3f8b) service to localhost/127.0.0.1:36933 successfully registered with NN
2020-04-16 00:20:00,667 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36933 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:20:00,668 INFO  [Thread-107] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:20:00,669 INFO  [Thread-107] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:20:00,669 INFO  [Thread-107] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:20:00,669 INFO  [Thread-107] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:20:00,677 INFO  [IPC Server handler 3 on default port 36933] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN efe0c969-7bdf-48e1-a105-e13d221fef55 (127.0.0.1:33532).
2020-04-16 00:20:00,681 INFO  [Thread-107] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,682 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:20:00,682 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:20:00,710 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid efe0c969-7bdf-48e1-a105-e13d221fef55) service to localhost/127.0.0.1:36933 successfully registered with NN
2020-04-16 00:20:00,711 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36933 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:20:00,782 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1625354301-172.17.0.4-1586996393290 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 100ms
2020-04-16 00:20:00,822 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1625354301-172.17.0.4-1586996393290 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 140ms
2020-04-16 00:20:00,822 INFO  [Thread-107] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1625354301-172.17.0.4-1586996393290: 140ms
2020-04-16 00:20:00,854 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:20:00,854 INFO  [Thread-142] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1625354301-172.17.0.4-1586996393290/current/replicas doesn't exist 
2020-04-16 00:20:00,854 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:20:00,855 INFO  [Thread-143] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1625354301-172.17.0.4-1586996393290/current/replicas doesn't exist 
2020-04-16 00:20:00,855 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 1ms
2020-04-16 00:20:00,855 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 1ms
2020-04-16 00:20:00,868 INFO  [Thread-107] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1625354301-172.17.0.4-1586996393290: 45ms
2020-04-16 00:20:00,869 INFO  [IPC Server handler 8 on default port 36933] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d19d1bfb-b060-41c8-9937-b040d3d54dba for DN 127.0.0.1:33532
2020-04-16 00:20:00,870 INFO  [Thread-107] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 12:36 AM with interval of 21600000ms
2020-04-16 00:20:00,870 INFO  [IPC Server handler 8 on default port 36933] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-67b93d4b-33c1-4121-a753-b759c3d3c4be for DN 127.0.0.1:33532
2020-04-16 00:20:00,873 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:20:00,873 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1625354301-172.17.0.4-1586996393290 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:20:00,873 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-d35976da-fb2b-4e5b-abd2-053a6a89886d): finished scanning block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,874 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-d35976da-fb2b-4e5b-abd2-053a6a89886d): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-16 00:20:00,876 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-7fc4eb70-14dd-484f-bea9-af9dfed87997): finished scanning block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:00,876 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-7fc4eb70-14dd-484f-bea9-af9dfed87997): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-16 00:20:00,879 INFO  [IPC Server handler 7 on default port 36933] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-90b72aab-26bc-4685-9dc2-072a09488728 for DN 127.0.0.1:41407
2020-04-16 00:20:00,898 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid e5510087-6ff2-4fde-8f98-ca8c189bd02a) service to localhost/127.0.0.1:36933 beginning handshake with NN
2020-04-16 00:20:00,929 INFO  [IPC Server handler 7 on default port 36933] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-91b791b7-d2ef-4e6c-bf71-1bd69ab06e7d for DN 127.0.0.1:41407
2020-04-16 00:20:00,933 INFO  [IPC Server handler 0 on default port 36933] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34802, datanodeUuid=e5510087-6ff2-4fde-8f98-ca8c189bd02a, infoPort=36250, infoSecurePort=0, ipcPort=43227, storageInfo=lv=-57;cid=testClusterID;nsid=1945263739;c=1586996393290) storage e5510087-6ff2-4fde-8f98-ca8c189bd02a
2020-04-16 00:20:00,934 INFO  [IPC Server handler 0 on default port 36933] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34802
2020-04-16 00:20:00,934 INFO  [IPC Server handler 0 on default port 36933] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e5510087-6ff2-4fde-8f98-ca8c189bd02a (127.0.0.1:34802).
2020-04-16 00:20:00,935 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid e5510087-6ff2-4fde-8f98-ca8c189bd02a) service to localhost/127.0.0.1:36933 successfully registered with NN
2020-04-16 00:20:00,935 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36933 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:20:00,953 INFO  [IPC Server handler 9 on default port 36933] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d35976da-fb2b-4e5b-abd2-053a6a89886d for DN 127.0.0.1:34802
2020-04-16 00:20:00,954 INFO  [IPC Server handler 9 on default port 36933] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7fc4eb70-14dd-484f-bea9-af9dfed87997 for DN 127.0.0.1:34802
2020-04-16 00:20:01,017 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1b6b2f5776ae6ee2: Processing first storage report for DS-90b72aab-26bc-4685-9dc2-072a09488728 from datanode 73911b40-4bf0-4055-899b-855a2f4b3f8b
2020-04-16 00:20:01,043 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b6b2f5776ae6ee2: from storage DS-90b72aab-26bc-4685-9dc2-072a09488728 node DatanodeRegistration(127.0.0.1:41407, datanodeUuid=73911b40-4bf0-4055-899b-855a2f4b3f8b, infoPort=36559, infoSecurePort=0, ipcPort=38261, storageInfo=lv=-57;cid=testClusterID;nsid=1945263739;c=1586996393290), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-04-16 00:20:01,058 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6d30bfe98034638e: Processing first storage report for DS-d35976da-fb2b-4e5b-abd2-053a6a89886d from datanode e5510087-6ff2-4fde-8f98-ca8c189bd02a
2020-04-16 00:20:01,058 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6d30bfe98034638e: from storage DS-d35976da-fb2b-4e5b-abd2-053a6a89886d node DatanodeRegistration(127.0.0.1:34802, datanodeUuid=e5510087-6ff2-4fde-8f98-ca8c189bd02a, infoPort=36250, infoSecurePort=0, ipcPort=43227, storageInfo=lv=-57;cid=testClusterID;nsid=1945263739;c=1586996393290), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-16 00:20:01,058 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6d30bfe98034638e: Processing first storage report for DS-7fc4eb70-14dd-484f-bea9-af9dfed87997 from datanode e5510087-6ff2-4fde-8f98-ca8c189bd02a
2020-04-16 00:20:01,058 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6d30bfe98034638e: from storage DS-7fc4eb70-14dd-484f-bea9-af9dfed87997 node DatanodeRegistration(127.0.0.1:34802, datanodeUuid=e5510087-6ff2-4fde-8f98-ca8c189bd02a, infoPort=36250, infoSecurePort=0, ipcPort=43227, storageInfo=lv=-57;cid=testClusterID;nsid=1945263739;c=1586996393290), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:20:01,059 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1b6b2f5776ae6ee2: Processing first storage report for DS-91b791b7-d2ef-4e6c-bf71-1bd69ab06e7d from datanode 73911b40-4bf0-4055-899b-855a2f4b3f8b
2020-04-16 00:20:01,059 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1b6b2f5776ae6ee2: from storage DS-91b791b7-d2ef-4e6c-bf71-1bd69ab06e7d node DatanodeRegistration(127.0.0.1:41407, datanodeUuid=73911b40-4bf0-4055-899b-855a2f4b3f8b, infoPort=36559, infoSecurePort=0, ipcPort=38261, storageInfo=lv=-57;cid=testClusterID;nsid=1945263739;c=1586996393290), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:20:01,071 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5d40b4de0d11a80: Processing first storage report for DS-d19d1bfb-b060-41c8-9937-b040d3d54dba from datanode efe0c969-7bdf-48e1-a105-e13d221fef55
2020-04-16 00:20:01,071 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5d40b4de0d11a80: from storage DS-d19d1bfb-b060-41c8-9937-b040d3d54dba node DatanodeRegistration(127.0.0.1:33532, datanodeUuid=efe0c969-7bdf-48e1-a105-e13d221fef55, infoPort=38866, infoSecurePort=0, ipcPort=42762, storageInfo=lv=-57;cid=testClusterID;nsid=1945263739;c=1586996393290), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-16 00:20:01,071 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5d40b4de0d11a80: Processing first storage report for DS-67b93d4b-33c1-4121-a753-b759c3d3c4be from datanode efe0c969-7bdf-48e1-a105-e13d221fef55
2020-04-16 00:20:01,071 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5d40b4de0d11a80: from storage DS-67b93d4b-33c1-4121-a753-b759c3d3c4be node DatanodeRegistration(127.0.0.1:33532, datanodeUuid=efe0c969-7bdf-48e1-a105-e13d221fef55, infoPort=38866, infoSecurePort=0, ipcPort=42762, storageInfo=lv=-57;cid=testClusterID;nsid=1945263739;c=1586996393290), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:20:01,117 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6d30bfe98034638e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 137 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:20:01,117 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:01,117 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1b6b2f5776ae6ee2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 139 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:20:01,118 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:01,117 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5d40b4de0d11a80,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 139 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:20:01,118 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:01,470 INFO  [IPC Server handler 1 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-16 00:20:01,499 INFO  [Listener at localhost/43227] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-04-16 00:20:01,586 INFO  [IPC Server handler 4 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive	dst=null	perm=null	proto=rpc
2020-04-16 00:20:01,594 INFO  [IPC Server handler 3 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:01,618 INFO  [IPC Server handler 0 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/input	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:20:01,705 INFO  [IPC Server handler 9 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/a	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:01,780 INFO  [IPC Server handler 8 on default port 36933] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:34802, 127.0.0.1:33532, 127.0.0.1:41407 for /user/root/input/a
2020-04-16 00:20:01,800 INFO  [Thread-150] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:01,921 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56680 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001 src: /127.0.0.1:56680 dest: /127.0.0.1:34802
2020-04-16 00:20:01,947 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56680 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:01,957 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60438 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001 src: /127.0.0.1:60438 dest: /127.0.0.1:33532
2020-04-16 00:20:01,961 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60438 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:01,965 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55658 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001 src: /127.0.0.1:55658 dest: /127.0.0.1:41407
2020-04-16 00:20:02,084 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55658, dest: /127.0.0.1:41407, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: 73911b40-4bf0-4055-899b-855a2f4b3f8b, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, duration(ns): 97395806
2020-04-16 00:20:02,085 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:02,091 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41407]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60438, dest: /127.0.0.1:33532, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: efe0c969-7bdf-48e1-a105-e13d221fef55, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, duration(ns): 90524993
2020-04-16 00:20:02,092 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41407]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41407] terminating
2020-04-16 00:20:02,129 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33532, 127.0.0.1:41407]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56680, dest: /127.0.0.1:34802, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: e5510087-6ff2-4fde-8f98-ca8c189bd02a, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, duration(ns): 122287587
2020-04-16 00:20:02,129 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33532, 127.0.0.1:41407]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33532, 127.0.0.1:41407] terminating
2020-04-16 00:20:02,147 INFO  [IPC Server handler 0 on default port 36933] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/a is closed by DFSClient_NONMAPREDUCE_1499555665_1
2020-04-16 00:20:02,165 INFO  [IPC Server handler 9 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/b	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:02,191 INFO  [IPC Server handler 8 on default port 36933] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:33532, 127.0.0.1:41407, 127.0.0.1:34802 for /user/root/input/b
2020-04-16 00:20:02,202 INFO  [Thread-159] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,218 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60460 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002 src: /127.0.0.1:60460 dest: /127.0.0.1:33532
2020-04-16 00:20:02,219 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60460 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,222 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55680 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002 src: /127.0.0.1:55680 dest: /127.0.0.1:41407
2020-04-16 00:20:02,224 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55680 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,229 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56716 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002 src: /127.0.0.1:56716 dest: /127.0.0.1:34802
2020-04-16 00:20:02,279 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56716, dest: /127.0.0.1:34802, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: e5510087-6ff2-4fde-8f98-ca8c189bd02a, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, duration(ns): 46590274
2020-04-16 00:20:02,279 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:02,289 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34802]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55680, dest: /127.0.0.1:41407, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: 73911b40-4bf0-4055-899b-855a2f4b3f8b, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, duration(ns): 55889821
2020-04-16 00:20:02,289 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34802]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34802] terminating
2020-04-16 00:20:02,303 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:34802]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60460, dest: /127.0.0.1:33532, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: efe0c969-7bdf-48e1-a105-e13d221fef55, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, duration(ns): 70466540
2020-04-16 00:20:02,304 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:34802]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:34802] terminating
2020-04-16 00:20:02,322 INFO  [IPC Server handler 5 on default port 36933] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/b is closed by DFSClient_NONMAPREDUCE_1499555665_1
2020-04-16 00:20:02,335 INFO  [IPC Server handler 1 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/c	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:02,355 INFO  [IPC Server handler 4 on default port 36933] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:34802, 127.0.0.1:41407, 127.0.0.1:33532 for /user/root/input/c
2020-04-16 00:20:02,364 INFO  [Thread-167] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,366 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56718 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003 src: /127.0.0.1:56718 dest: /127.0.0.1:34802
2020-04-16 00:20:02,367 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56718 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,383 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55686 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003 src: /127.0.0.1:55686 dest: /127.0.0.1:41407
2020-04-16 00:20:02,385 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55686 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,394 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60472 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003 src: /127.0.0.1:60472 dest: /127.0.0.1:33532
2020-04-16 00:20:02,459 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60472, dest: /127.0.0.1:33532, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: efe0c969-7bdf-48e1-a105-e13d221fef55, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, duration(ns): 62485098
2020-04-16 00:20:02,459 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:02,463 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33532]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55686, dest: /127.0.0.1:41407, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: 73911b40-4bf0-4055-899b-855a2f4b3f8b, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, duration(ns): 55467636
2020-04-16 00:20:02,472 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33532]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33532] terminating
2020-04-16 00:20:02,480 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:33532]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56718, dest: /127.0.0.1:34802, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: e5510087-6ff2-4fde-8f98-ca8c189bd02a, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, duration(ns): 59337193
2020-04-16 00:20:02,480 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:33532]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:33532] terminating
2020-04-16 00:20:02,496 INFO  [IPC Server handler 8 on default port 36933] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/c is closed by DFSClient_NONMAPREDUCE_1499555665_1
2020-04-16 00:20:02,526 INFO  [IPC Server handler 7 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/input/dir1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:20:02,539 INFO  [IPC Server handler 6 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/dir1/a	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:02,551 INFO  [IPC Server handler 2 on default port 36933] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:41407, 127.0.0.1:33532, 127.0.0.1:34802 for /user/root/input/dir1/a
2020-04-16 00:20:02,555 INFO  [Thread-175] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,565 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55696 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004 src: /127.0.0.1:55696 dest: /127.0.0.1:41407
2020-04-16 00:20:02,566 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55696 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,573 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60482 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004 src: /127.0.0.1:60482 dest: /127.0.0.1:33532
2020-04-16 00:20:02,575 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60482 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,577 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56734 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004 src: /127.0.0.1:56734 dest: /127.0.0.1:34802
2020-04-16 00:20:02,631 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56734, dest: /127.0.0.1:34802, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: e5510087-6ff2-4fde-8f98-ca8c189bd02a, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, duration(ns): 50211398
2020-04-16 00:20:02,640 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:02,643 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34802]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60482, dest: /127.0.0.1:33532, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: efe0c969-7bdf-48e1-a105-e13d221fef55, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, duration(ns): 28924322
2020-04-16 00:20:02,644 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34802]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34802] terminating
2020-04-16 00:20:02,673 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33532, 127.0.0.1:34802]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55696, dest: /127.0.0.1:41407, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: 73911b40-4bf0-4055-899b-855a2f4b3f8b, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, duration(ns): 72631497
2020-04-16 00:20:02,673 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33532, 127.0.0.1:34802]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33532, 127.0.0.1:34802] terminating
2020-04-16 00:20:02,693 INFO  [IPC Server handler 3 on default port 36933] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/dir1/a is closed by DFSClient_NONMAPREDUCE_1499555665_1
lsr root=input
2020-04-16 00:20:02,795 INFO  [IPC Server handler 0 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,806 INFO  [IPC Server handler 9 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,814 INFO  [IPC Server handler 8 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
lsr results:
lsr: DEPRECATED: Please use 'ls -R' instead.
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 input/a
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 input/b
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 input/c
drwxr-xr-x   - root supergroup          0 2020-04-16 00:20 input/dir1
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 input/dir1/a

lsr paths = [/a,
  /b,
  /c,
  /dir1,
  /dir1/a]
originalPaths: [/a, /b, /c, /dir1, /dir1/a]
inputPathStr = /user/root/input
2020-04-16 00:20:02,825 INFO  [IPC Server handler 7 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,835 INFO  [IPC Server handler 6 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,841 INFO  [IPC Server handler 2 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,849 INFO  [IPC Server handler 5 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,852 INFO  [IPC Server handler 1 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,856 INFO  [IPC Server handler 4 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,860 INFO  [IPC Server handler 3 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,875 INFO  [Listener at localhost/43227] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:02,909 INFO  [IPC Server handler 0 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,913 INFO  [IPC Server handler 9 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,921 INFO  [IPC Server handler 8 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,927 INFO  [IPC Server handler 7 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,937 INFO  [IPC Server handler 6 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,978 INFO  [Listener at localhost/43227] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:02,989 INFO  [Listener at localhost/43227] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:03,041 INFO  [Listener at localhost/43227] mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:1
2020-04-16 00:20:03,262 INFO  [Listener at localhost/43227] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1179977523_0001
2020-04-16 00:20:03,262 INFO  [Listener at localhost/43227] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2020-04-16 00:20:03,460 INFO  [Listener at localhost/43227] mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2020-04-16 00:20:03,462 INFO  [Listener at localhost/43227] mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1179977523_0001
2020-04-16 00:20:03,470 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2020-04-16 00:20:03,472 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2020-04-16 00:20:03,489 INFO  [Thread-183] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:20:03,489 INFO  [Thread-183] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:20:03,502 INFO  [IPC Server handler 2 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/archive/foo.har/_temporary/0	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:20:03,549 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2020-04-16 00:20:03,556 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1179977523_0001_m_000000_0
2020-04-16 00:20:03,629 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:20:03,632 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:20:03,702 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2020-04-16 00:20:03,704 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:updateJobWithSplit(497)) - Processing split: file:/tmp/hadoop/mapred/staging/root1994137693/.staging/har_nv3k8r/_har_src_files:0+376
2020-04-16 00:20:03,731 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:runOldMapper(451)) - numReduceTasks: 1
2020-04-16 00:20:03,965 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:setEquator(1219)) - (EQUATOR) 0 kvi 26214396(104857584)
2020-04-16 00:20:03,965 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1012)) - mapreduce.task.io.sort.mb: 100
2020-04-16 00:20:03,965 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1013)) - soft limit at 83886080
2020-04-16 00:20:03,965 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1014)) - bufstart = 0; bufvoid = 104857600
2020-04-16 00:20:03,965 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1015)) - kvstart = 26214396; length = 6553600
2020-04-16 00:20:03,968 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:createSortingCollector(409)) - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-04-16 00:20:03,973 INFO  [IPC Server handler 5 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_m_000000_0/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:03,976 INFO  [IPC Server handler 1 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_m_000000_0/part-0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:03,996 INFO  [IPC Server handler 3 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,001 INFO  [IPC Server handler 4 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,017 INFO  [IPC Server handler 6 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,070 INFO  [LocalJobRunner Map Task Executor #0] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,118 INFO  [IPC Server handler 7 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,123 INFO  [IPC Server handler 8 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,139 INFO  [IPC Server handler 9 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,141 INFO  [IPC Server handler 0 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,144 INFO  [LocalJobRunner Map Task Executor #0] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,161 INFO  [IPC Server handler 2 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,171 INFO  [IPC Server handler 5 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,174 INFO  [IPC Server handler 1 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/dir1/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,181 INFO  [IPC Server handler 3 on default port 36933] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:41407, 127.0.0.1:33532, 127.0.0.1:34802 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_m_000000_0/part-0
2020-04-16 00:20:04,187 INFO  [Thread-187] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,201 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55814 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005 src: /127.0.0.1:55814 dest: /127.0.0.1:41407
2020-04-16 00:20:04,203 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55814 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,212 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60600 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005 src: /127.0.0.1:60600 dest: /127.0.0.1:33532
2020-04-16 00:20:04,213 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60600 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,222 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56852 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005 src: /127.0.0.1:56852 dest: /127.0.0.1:34802
2020-04-16 00:20:04,287 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56852, dest: /127.0.0.1:34802, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: e5510087-6ff2-4fde-8f98-ca8c189bd02a, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, duration(ns): 57317783
2020-04-16 00:20:04,287 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:04,291 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34802]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60600, dest: /127.0.0.1:33532, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: efe0c969-7bdf-48e1-a105-e13d221fef55, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, duration(ns): 57373824
2020-04-16 00:20:04,291 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34802]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34802] terminating
2020-04-16 00:20:04,313 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33532, 127.0.0.1:34802]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55814, dest: /127.0.0.1:41407, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: 73911b40-4bf0-4055-899b-855a2f4b3f8b, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, duration(ns): 48632685
2020-04-16 00:20:04,313 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33532, 127.0.0.1:34802]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33532, 127.0.0.1:34802] terminating
2020-04-16 00:20:04,329 INFO  [IPC Server handler 8 on default port 36933] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_m_000000_0/part-0 is closed by DFSClient_NONMAPREDUCE_1499555665_1
2020-04-16 00:20:04,346 INFO  [IPC Server handler 9 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_m_000000_0/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,357 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2020-04-16 00:20:04,358 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1476)) - Starting flush of map output
2020-04-16 00:20:04,358 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1498)) - Spilling map output
2020-04-16 00:20:04,358 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1499)) - bufstart = 0; bufend = 366; bufvoid = 104857600
2020-04-16 00:20:04,358 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1501)) - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2020-04-16 00:20:04,386 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:sortAndSpill(1696)) - Finished spill 0
2020-04-16 00:20:04,408 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:done(1244)) - Task:attempt_local1179977523_0001_m_000000_0 is done. And is in the process of committing
2020-04-16 00:20:04,414 INFO  [IPC Server handler 0 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,415 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2020-04-16 00:20:04,416 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:commit(1421)) - Task attempt_local1179977523_0001_m_000000_0 is allowed to commit now
2020-04-16 00:20:04,418 INFO  [IPC Server handler 2 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,420 INFO  [IPC Server handler 5 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,426 INFO  [IPC Server handler 1 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,429 INFO  [IPC Server handler 3 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,468 INFO  [Listener at localhost/43227] mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1179977523_0001 running in uber mode : false
2020-04-16 00:20:04,468 INFO  [Listener at localhost/43227] mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 0% reduce 0%
2020-04-16 00:20:04,472 INFO  [IPC Server handler 4 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_m_000000_0/part-0	dst=/user/root/archive/foo.har/part-0	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:04,481 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:commitTask(606)) - Saved output of task 'attempt_local1179977523_0001_m_000000_0' to hdfs://localhost:36933/user/root/archive/foo.har
2020-04-16 00:20:04,487 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file hdfs://localhost:36933/user/root/input/dir1/a to archive.
2020-04-16 00:20:04,488 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1179977523_0001_m_000000_0' done.
2020-04-16 00:20:04,491 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1179977523_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=62563
		FILE: Number of bytes written=590335
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4
		HDFS: Number of bytes written=8
		HDFS: Number of read operations=30
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=13
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=366
		Map output materialized bytes=384
		Input split bytes=133
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=117
		Total committed heap usage (bytes)=1933574144
	File Input Format Counters 
		Bytes Read=388
2020-04-16 00:20:04,491 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1179977523_0001_m_000000_0
2020-04-16 00:20:04,493 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2020-04-16 00:20:04,497 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for reduce tasks
2020-04-16 00:20:04,504 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:run(330)) - Starting task: attempt_local1179977523_0001_r_000000_0
2020-04-16 00:20:04,533 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:20:04,534 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:20:04,534 INFO  [pool-49-thread-1] mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2020-04-16 00:20:04,541 INFO  [pool-49-thread-1] mapred.ReduceTask (ReduceTask.java:run(363)) - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1cd95eb
2020-04-16 00:20:04,543 INFO  [pool-49-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:04,580 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:<init>(208)) - MergerManager: memoryLimit=1353501824, maxSingleShuffleLimit=338375456, mergeThreshold=893311232, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-04-16 00:20:04,596 INFO  [EventFetcher for fetching Map Completion Events] reduce.EventFetcher (EventFetcher.java:run(61)) - attempt_local1179977523_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-04-16 00:20:04,650 INFO  [localfetcher#1] reduce.LocalFetcher (LocalFetcher.java:copyMapOutput(145)) - localfetcher#1 about to shuffle output of map attempt_local1179977523_0001_m_000000_0 decomp: 380 len: 384 to MEMORY
2020-04-16 00:20:04,653 INFO  [localfetcher#1] reduce.InMemoryMapOutput (InMemoryMapOutput.java:doShuffle(94)) - Read 380 bytes from map-output for attempt_local1179977523_0001_m_000000_0
2020-04-16 00:20:04,653 INFO  [localfetcher#1] reduce.MergeManagerImpl (MergeManagerImpl.java:closeInMemoryFile(323)) - closeInMemoryFile -> map-output of size: 380, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->380
2020-04-16 00:20:04,662 INFO  [EventFetcher for fetching Map Completion Events] reduce.EventFetcher (EventFetcher.java:run(76)) - EventFetcher is interrupted.. Returning
2020-04-16 00:20:04,664 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:20:04,664 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(695)) - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-04-16 00:20:04,674 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(606)) - Merging 1 sorted segments
2020-04-16 00:20:04,675 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(705)) - Down to the last merge-pass, with 1 segments left of total size: 374 bytes
2020-04-16 00:20:04,679 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(762)) - Merged 1 segments, 380 bytes to disk to satisfy reduce memory limit
2020-04-16 00:20:04,680 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(792)) - Merging 1 files, 384 bytes from disk
2020-04-16 00:20:04,680 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(807)) - Merging 0 segments, 0 bytes from memory into reduce
2020-04-16 00:20:04,681 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(606)) - Merging 1 sorted segments
2020-04-16 00:20:04,682 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(705)) - Down to the last merge-pass, with 1 segments left of total size: 374 bytes
2020-04-16 00:20:04,682 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:20:04,688 INFO  [IPC Server handler 6 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,694 INFO  [IPC Server handler 7 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,698 INFO  [IPC Server handler 8 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_index	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:04,702 INFO  [IPC Server handler 9 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_masterindex	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:04,723 INFO  [IPC Server handler 0 on default port 36933] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:34802, 127.0.0.1:41407, 127.0.0.1:33532 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_masterindex
2020-04-16 00:20:04,725 INFO  [Thread-204] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,733 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56862 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006 src: /127.0.0.1:56862 dest: /127.0.0.1:34802
2020-04-16 00:20:04,734 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56862 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,752 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55830 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006 src: /127.0.0.1:55830 dest: /127.0.0.1:41407
2020-04-16 00:20:04,753 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55830 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,769 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60616 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006 src: /127.0.0.1:60616 dest: /127.0.0.1:33532
2020-04-16 00:20:04,807 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60616, dest: /127.0.0.1:33532, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: efe0c969-7bdf-48e1-a105-e13d221fef55, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, duration(ns): 34587802
2020-04-16 00:20:04,807 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:04,820 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33532]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55830, dest: /127.0.0.1:41407, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: 73911b40-4bf0-4055-899b-855a2f4b3f8b, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, duration(ns): 42877929
2020-04-16 00:20:04,821 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33532]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33532] terminating
2020-04-16 00:20:04,845 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:33532]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56862, dest: /127.0.0.1:34802, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: e5510087-6ff2-4fde-8f98-ca8c189bd02a, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, duration(ns): 61079039
2020-04-16 00:20:04,846 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:33532]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:33532] terminating
2020-04-16 00:20:04,855 INFO  [IPC Server handler 1 on default port 36933] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_masterindex is closed by DFSClient_NONMAPREDUCE_1499555665_1
2020-04-16 00:20:04,882 INFO  [IPC Server handler 4 on default port 36933] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:34802, 127.0.0.1:41407, 127.0.0.1:33532 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_index
2020-04-16 00:20:04,886 INFO  [Thread-203] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,888 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56886 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007 src: /127.0.0.1:56886 dest: /127.0.0.1:34802
2020-04-16 00:20:04,892 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:56886 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,901 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55856 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007 src: /127.0.0.1:55856 dest: /127.0.0.1:41407
2020-04-16 00:20:04,903 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:55856 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,904 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_1499555665_1 at /127.0.0.1:60642 [Receiving block BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007 src: /127.0.0.1:60642 dest: /127.0.0.1:33532
2020-04-16 00:20:04,935 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60642, dest: /127.0.0.1:33532, bytes: 342, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: efe0c969-7bdf-48e1-a105-e13d221fef55, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, duration(ns): 24296399
2020-04-16 00:20:04,936 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:04,944 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33532]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55856, dest: /127.0.0.1:41407, bytes: 342, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: 73911b40-4bf0-4055-899b-855a2f4b3f8b, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, duration(ns): 27519545
2020-04-16 00:20:04,947 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33532]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33532] terminating
2020-04-16 00:20:04,952 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:33532]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56886, dest: /127.0.0.1:34802, bytes: 342, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1499555665_1, offset: 0, srvID: e5510087-6ff2-4fde-8f98-ca8c189bd02a, blockid: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, duration(ns): 42124369
2020-04-16 00:20:04,953 INFO  [PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:33532]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1625354301-172.17.0.4-1586996393290:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41407, 127.0.0.1:33532] terminating
2020-04-16 00:20:04,974 INFO  [IPC Server handler 9 on default port 36933] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_index is closed by DFSClient_NONMAPREDUCE_1499555665_1
2020-04-16 00:20:04,978 INFO  [IPC Server handler 0 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,985 INFO  [IPC Server handler 2 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,986 INFO  [pool-49-thread-1] mapred.Task (Task.java:done(1244)) - Task:attempt_local1179977523_0001_r_000000_0 is done. And is in the process of committing
2020-04-16 00:20:04,991 INFO  [IPC Server handler 5 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,995 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:20:04,996 INFO  [pool-49-thread-1] mapred.Task (Task.java:commit(1421)) - Task attempt_local1179977523_0001_r_000000_0 is allowed to commit now
2020-04-16 00:20:04,997 INFO  [IPC Server handler 3 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,999 INFO  [IPC Server handler 1 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,001 INFO  [IPC Server handler 4 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,008 INFO  [IPC Server handler 6 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,011 INFO  [IPC Server handler 7 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_index	dst=/user/root/archive/foo.har/_index	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:05,021 INFO  [IPC Server handler 8 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,029 INFO  [IPC Server handler 9 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1179977523_0001_r_000000_0/_masterindex	dst=/user/root/archive/foo.har/_masterindex	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:05,030 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:commitTask(606)) - Saved output of task 'attempt_local1179977523_0001_r_000000_0' to hdfs://localhost:36933/user/root/archive/foo.har
2020-04-16 00:20:05,032 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - reduce > reduce
2020-04-16 00:20:05,032 INFO  [pool-49-thread-1] mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1179977523_0001_r_000000_0' done.
2020-04-16 00:20:05,034 INFO  [pool-49-thread-1] mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1179977523_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=63363
		FILE: Number of bytes written=590719
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4
		HDFS: Number of bytes written=373
		HDFS: Number of read operations=36
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=21
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=384
		Reduce input records=6
		Reduce output records=0
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1933574144
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2020-04-16 00:20:05,034 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:run(353)) - Finishing task: attempt_local1179977523_0001_r_000000_0
2020-04-16 00:20:05,034 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - reduce task executor complete.
2020-04-16 00:20:05,045 INFO  [IPC Server handler 0 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,054 INFO  [IPC Server handler 2 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_SUCCESS	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:05,061 INFO  [IPC Server handler 5 on default port 36933] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1499555665_1
2020-04-16 00:20:05,471 INFO  [Listener at localhost/43227] mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 100%
2020-04-16 00:20:05,472 INFO  [Listener at localhost/43227] mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1179977523_0001 completed successfully
2020-04-16 00:20:05,490 INFO  [Listener at localhost/43227] mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 36
	File System Counters
		FILE: Number of bytes read=125926
		FILE: Number of bytes written=1181054
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=8
		HDFS: Number of bytes written=381
		HDFS: Number of read operations=66
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=34
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=366
		Map output materialized bytes=384
		Input split bytes=133
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=384
		Reduce input records=6
		Reduce output records=0
		Spilled Records=12
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=117
		Total committed heap usage (bytes)=3867148288
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=388
	File Output Format Counters 
		Bytes Written=0
2020-04-16 00:20:05,494 INFO  [IPC Server handler 3 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
lsr root=har://hdfs-localhost:36933/user/root/archive/foo.har
2020-04-16 00:20:05,506 INFO  [IPC Server handler 1 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,513 INFO  [IPC Server handler 4 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,521 INFO  [IPC Server handler 6 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,525 INFO  [IPC Server handler 7 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,533 INFO  [IPC Server handler 8 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,541 INFO  [IPC Server handler 9 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,555 INFO  [IPC Server handler 0 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,563 INFO  [IPC Server handler 2 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,570 INFO  [IPC Server handler 5 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,581 INFO  [IPC Server handler 3 on default port 36933] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
lsr results:
lsr: DEPRECATED: Please use 'ls -R' instead.
-rw-r--r--   2 root supergroup          1 2020-04-16 00:20 har://hdfs-localhost:36933/user/root/archive/foo.har/a
-rw-r--r--   2 root supergroup          1 2020-04-16 00:20 har://hdfs-localhost:36933/user/root/archive/foo.har/b
-rw-r--r--   2 root supergroup          1 2020-04-16 00:20 har://hdfs-localhost:36933/user/root/archive/foo.har/c
drwxr-xr-x   - root supergroup          0 2020-04-16 00:20 har://hdfs-localhost:36933/user/root/archive/foo.har/dir1
-rw-r--r--   2 root supergroup          1 2020-04-16 00:20 har://hdfs-localhost:36933/user/root/archive/foo.har/dir1/a

lsr paths = [/a,
  /b,
  /c,
  /dir1,
  /dir1/a]
2020-04-16 00:20:05,583 INFO  [Listener at localhost/43227] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-04-16 00:20:05,584 INFO  [Listener at localhost/43227] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-04-16 00:20:05,584 INFO  [Listener at localhost/43227] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:20:05,584 WARN  [Listener at localhost/43227] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:20:05,584 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4565a70a] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:20:05,595 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-d35976da-fb2b-4e5b-abd2-053a6a89886d) exiting.
2020-04-16 00:20:05,597 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-7fc4eb70-14dd-484f-bea9-af9dfed87997) exiting.
2020-04-16 00:20:05,685 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@17ae7628{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:20:05,715 INFO  [Listener at localhost/43227] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1136b469{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:05,752 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d7e1102{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:05,763 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@466d49f0{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:20:05,778 INFO  [Listener at localhost/43227] ipc.Server (Server.java:stop(3359)) - Stopping server on 43227
2020-04-16 00:20:05,779 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:05,780 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:05,783 WARN  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:20:05,785 WARN  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid e5510087-6ff2-4fde-8f98-ca8c189bd02a) service to localhost/127.0.0.1:36933
2020-04-16 00:20:05,786 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid e5510087-6ff2-4fde-8f98-ca8c189bd02a)
2020-04-16 00:20:05,786 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:05,805 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1625354301-172.17.0.4-1586996393290] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:05,809 INFO  [Listener at localhost/43227] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:20:05,821 INFO  [Listener at localhost/43227] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:20:05,813 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1625354301-172.17.0.4-1586996393290] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:05,835 INFO  [Listener at localhost/43227] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:20:05,837 INFO  [Listener at localhost/43227] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:20:05,859 INFO  [Listener at localhost/43227] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:20:05,860 INFO  [Listener at localhost/43227] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-04-16 00:20:05,860 INFO  [Listener at localhost/43227] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:20:05,860 WARN  [Listener at localhost/43227] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:20:05,860 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5bb8f9e2] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:20:05,862 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-67b93d4b-33c1-4121-a753-b759c3d3c4be) exiting.
2020-04-16 00:20:05,862 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-d19d1bfb-b060-41c8-9937-b040d3d54dba) exiting.
2020-04-16 00:20:05,947 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58065f0c{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:20:05,948 INFO  [Listener at localhost/43227] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3605c4d3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:05,948 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@bcb09a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:05,948 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30feffc{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:20:05,965 INFO  [Listener at localhost/43227] ipc.Server (Server.java:stop(3359)) - Stopping server on 42762
2020-04-16 00:20:05,983 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:05,984 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:05,984 WARN  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:20:05,989 WARN  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid efe0c969-7bdf-48e1-a105-e13d221fef55) service to localhost/127.0.0.1:36933
2020-04-16 00:20:05,989 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid efe0c969-7bdf-48e1-a105-e13d221fef55)
2020-04-16 00:20:05,989 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:05,990 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1625354301-172.17.0.4-1586996393290] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,017 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1625354301-172.17.0.4-1586996393290] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,043 INFO  [Listener at localhost/43227] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:20:06,043 INFO  [Listener at localhost/43227] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:20:06,045 INFO  [Listener at localhost/43227] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:20:06,045 INFO  [Listener at localhost/43227] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:20:06,055 INFO  [Listener at localhost/43227] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:20:06,055 INFO  [Listener at localhost/43227] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-04-16 00:20:06,055 INFO  [Listener at localhost/43227] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:20:06,061 WARN  [Listener at localhost/43227] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:20:06,062 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6b5f8707] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:20:06,064 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-90b72aab-26bc-4685-9dc2-072a09488728) exiting.
2020-04-16 00:20:06,065 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-91b791b7-d2ef-4e6c-bf71-1bd69ab06e7d) exiting.
2020-04-16 00:20:06,183 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1af1347d{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:20:06,221 INFO  [Listener at localhost/43227] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:06,221 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@282308c3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:06,222 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7726e185{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:20:06,225 INFO  [Listener at localhost/43227] ipc.Server (Server.java:stop(3359)) - Stopping server on 38261
2020-04-16 00:20:06,233 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:06,233 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:06,237 WARN  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:20:06,243 WARN  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid 73911b40-4bf0-4055-899b-855a2f4b3f8b) service to localhost/127.0.0.1:36933
2020-04-16 00:20:06,344 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1625354301-172.17.0.4-1586996393290 (Datanode Uuid 73911b40-4bf0-4055-899b-855a2f4b3f8b)
2020-04-16 00:20:06,344 INFO  [BP-1625354301-172.17.0.4-1586996393290 heartbeating to localhost/127.0.0.1:36933] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1625354301-172.17.0.4-1586996393290
2020-04-16 00:20:06,353 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1625354301-172.17.0.4-1586996393290] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,355 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1625354301-172.17.0.4-1586996393290] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,357 INFO  [Listener at localhost/43227] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:20:06,362 INFO  [Listener at localhost/43227] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:20:06,365 INFO  [Listener at localhost/43227] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:20:06,365 INFO  [Listener at localhost/43227] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:20:06,384 INFO  [Listener at localhost/43227] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:20:06,384 INFO  [Listener at localhost/43227] hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-04-16 00:20:06,384 INFO  [Listener at localhost/43227] namenode.NameNode (NameNode.java:stop(1013)) - msx-hdfs NameNode stop
2020-04-16 00:20:06,385 INFO  [Listener at localhost/43227] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:20:06,386 INFO  [Listener at localhost/43227] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 56
2020-04-16 00:20:06,386 INFO  [Listener at localhost/43227] namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 57 Total time for transactions(ms): 64 Number of transactions batched in Syncs: 12 Number of syncs: 46 SyncTimes(ms): 16 1 
2020-04-16 00:20:06,386 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@73393584] namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-16 00:20:06,388 INFO  [Listener at localhost/43227] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000057
2020-04-16 00:20:06,389 INFO  [Listener at localhost/43227] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000057
2020-04-16 00:20:06,389 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@70e659aa] namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-16 00:20:06,391 INFO  [FSEditLogAsync] namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-16 00:20:06,392 INFO  [Listener at localhost/43227] ipc.Server (Server.java:stop(3359)) - Stopping server on 36933
2020-04-16 00:20:06,393 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:06,394 INFO  [RedundancyMonitor] blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-04-16 00:20:06,394 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:06,401 INFO  [StorageInfoMonitor] blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-04-16 00:20:06,401 INFO  [CacheReplicationMonitor(247976210)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-16 00:20:06,450 INFO  [Listener at localhost/43227] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:20:06,451 INFO  [Listener at localhost/43227] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-04-16 00:20:06,455 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33fe57a9{/,null,UNAVAILABLE}{/hdfs}
2020-04-16 00:20:06,476 INFO  [Listener at localhost/43227] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:06,477 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:06,477 INFO  [Listener at localhost/43227] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
msx-listener testfinished org.apache.hadoop.tools.TestHadoopArchives#testRelativePathWitRepl
msx-listener writeFile testName is org.apache.hadoop.tools.TestHadoopArchives#testRelativePathWitRepl
msx-listener succeed
msx-listener all testRunFinished
