msx-listener test started org.apache.hadoop.tools.TestHadoopArchives#testOutputPathValidity
msx-listener unitTestCounterInClass = 0
2020-04-16 00:19:43,664 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-16 00:19:44,661 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:44,679 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:44,682 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:44,683 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:44,715 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:44,716 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:44,716 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:44,717 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:44,799 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:44,806 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-16 00:19:44,807 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:44,807 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:44,814 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:44,815 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:44
2020-04-16 00:19:44,818 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:44,820 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:44,822 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-16 00:19:44,823 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:44,852 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:44,853 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:44,864 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:44,865 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:44,865 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:44,865 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:44,867 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:44,867 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:44,867 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:44,868 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:44,868 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:44,868 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:44,868 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:44,916 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-04-16 00:19:44,917 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:44,917 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:44,918 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:44,941 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:44,942 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:44,943 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-16 00:19:44,943 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:44,952 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:44,952 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:44,953 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:44,953 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:44,962 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:44,966 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:44,975 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:44,975 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:44,976 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-16 00:19:44,976 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:44,992 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:44,993 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:44,993 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:45,000 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:45,001 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:45,004 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:45,005 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:45,006 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-16 00:19:45,006 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:45,069 INFO  [main] namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:45,101 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 has been successfully formatted.
2020-04-16 00:19:45,106 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 has been successfully formatted.
2020-04-16 00:19:45,161 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:45,165 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:45,364 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:45,365 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:45,394 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-16 00:19:45,401 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1635)) - createNameNode []
2020-04-16 00:19:45,485 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-04-16 00:19:46,186 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-04-16 00:19:46,186 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-16 00:19:46,194 INFO  [main] namenode.NameNode (NameNode.java:<init>(932)) - msx-hdfs NameNode init
2020-04-16 00:19:46,217 INFO  [main] namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-16 00:19:46,274 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2205a05d] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:46,293 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-16 00:19:46,335 INFO  [main] util.log (Log.java:initialized(192)) - Logging initialized @4757ms
2020-04-16 00:19:46,515 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:46,520 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-16 00:19:46,532 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:46,537 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-16 00:19:46,538 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:46,539 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:46,575 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-16 00:19:46,576 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-16 00:19:46,589 INFO  [main] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44414
2020-04-16 00:19:46,592 INFO  [main] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:46,670 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:46,671 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:47,023 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33fe57a9{/,file:///tmp/jetty-localhost-44414-hdfs-_-any-7241028343562168870.dir/webapp/,AVAILABLE}{/hdfs}
2020-04-16 00:19:47,033 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:44414}
2020-04-16 00:19:47,034 INFO  [main] server.Server (Server.java:doStart(419)) - Started @5456ms
2020-04-16 00:19:47,047 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:47,048 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:47,048 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:47,049 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:47,049 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:47,049 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:47,049 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:47,050 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:47,050 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:47,051 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:47,051 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:47,052 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:47,052 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:47
2020-04-16 00:19:47,053 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:47,053 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:47,053 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-16 00:19:47,054 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:47,072 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:47,072 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:47,073 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:47,074 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:47,074 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:47,075 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:47,075 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:47,075 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:47,075 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:47,076 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:47,076 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:47,076 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:47,076 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:47,077 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:47,077 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:47,078 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-16 00:19:47,082 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:47,090 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:47,090 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:47,091 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:47,091 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:47,091 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:47,092 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:47,092 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:47,092 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:47,092 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-16 00:19:47,093 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:47,095 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:47,095 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:47,095 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:47,096 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:47,096 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:47,096 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:47,096 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:47,097 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-16 00:19:47,097 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:47,109 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/in_use.lock acquired by nodename 7410@d082457d4d4a
2020-04-16 00:19:47,114 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/in_use.lock acquired by nodename 7410@d082457d4d4a
2020-04-16 00:19:47,118 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current
2020-04-16 00:19:47,118 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current
2020-04-16 00:19:47,119 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-04-16 00:19:47,119 INFO  [main] namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-16 00:19:47,173 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-04-16 00:19:47,184 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-04-16 00:19:47,191 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-16 00:19:47,199 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-16 00:19:47,200 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-04-16 00:19:47,247 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-16 00:19:47,247 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 148 msecs
2020-04-16 00:19:47,465 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-04-16 00:19:47,525 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:47,549 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:47,901 INFO  [Listener at localhost/34110] namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:34110 to access this namenode/service.
2020-04-16 00:19:47,905 INFO  [Listener at localhost/34110] namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-16 00:19:47,933 INFO  [Listener at localhost/34110] namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-16 00:19:47,972 INFO  [Listener at localhost/34110] blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-04-16 00:19:47,974 INFO  [Listener at localhost/34110] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-04-16 00:19:47,974 INFO  [Listener at localhost/34110] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-16 00:19:47,974 INFO  [Listener at localhost/34110] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-16 00:19:47,991 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-04-16 00:19:47,991 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-04-16 00:19:47,992 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-04-16 00:19:47,992 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-04-16 00:19:47,992 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-04-16 00:19:47,992 INFO  [Reconstruction Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2020-04-16 00:19:48,085 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:48,087 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:48,110 INFO  [Listener at localhost/34110] namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:34110
2020-04-16 00:19:48,121 INFO  [Listener at localhost/34110] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-04-16 00:19:48,122 INFO  [Listener at localhost/34110] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-04-16 00:19:48,143 INFO  [Listener at localhost/34110] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 20 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-16 00:19:48,183 INFO  [Listener at localhost/34110] namenode.NameNode (NameNode.java:<init>(969)) - msx-hdfs NameNode start
2020-04-16 00:19:48,192 INFO  [Listener at localhost/34110] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:48,210 INFO  [CacheReplicationMonitor(1590712299)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-16 00:19:48,310 INFO  [Listener at localhost/34110] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:48,336 INFO  [Listener at localhost/34110] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:48,412 INFO  [Listener at localhost/34110] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:48,412 INFO  [Listener at localhost/34110] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:48,425 INFO  [Listener at localhost/34110] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:48,431 INFO  [Listener at localhost/34110] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:48,441 INFO  [Listener at localhost/34110] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:48,454 INFO  [Listener at localhost/34110] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:48,463 INFO  [Listener at localhost/34110] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:48,475 INFO  [Listener at localhost/34110] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:41362
2020-04-16 00:19:48,479 INFO  [Listener at localhost/34110] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:48,479 INFO  [Listener at localhost/34110] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:48,531 INFO  [Listener at localhost/34110] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:48,533 INFO  [Listener at localhost/34110] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:48,537 INFO  [Listener at localhost/34110] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:48,539 INFO  [Listener at localhost/34110] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:48,539 INFO  [Listener at localhost/34110] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:48,540 INFO  [Listener at localhost/34110] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:48,545 INFO  [Listener at localhost/34110] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36456
2020-04-16 00:19:48,545 INFO  [Listener at localhost/34110] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:48,565 INFO  [Listener at localhost/34110] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7726e185{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:48,573 INFO  [Listener at localhost/34110] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@282308c3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:48,808 INFO  [Listener at localhost/34110] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1af1347d{/,file:///tmp/jetty-localhost-36456-datanode-_-any-1388908949388194408.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:48,809 INFO  [Listener at localhost/34110] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:36456}
2020-04-16 00:19:48,810 INFO  [Listener at localhost/34110] server.Server (Server.java:doStart(419)) - Started @7232ms
2020-04-16 00:19:50,030 INFO  [Listener at localhost/34110] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41392
2020-04-16 00:19:50,032 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61f2c3f0] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:50,034 INFO  [Listener at localhost/34110] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:50,034 INFO  [Listener at localhost/34110] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:50,053 INFO  [Listener at localhost/34110] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:50,056 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:50,075 INFO  [Listener at localhost/34381] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:34381
2020-04-16 00:19:50,093 INFO  [Listener at localhost/34381] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:50,094 INFO  [Listener at localhost/34381] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:50,116 INFO  [Thread-58] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34110 starting to offer service
2020-04-16 00:19:50,131 INFO  [Listener at localhost/34381] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:50,143 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:50,146 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:50,159 INFO  [Listener at localhost/34381] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:50,162 INFO  [Listener at localhost/34381] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:50,166 INFO  [Listener at localhost/34381] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:50,212 INFO  [Listener at localhost/34381] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:50,212 INFO  [Listener at localhost/34381] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:50,213 INFO  [Listener at localhost/34381] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:50,213 INFO  [Listener at localhost/34381] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:50,214 INFO  [Listener at localhost/34381] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:50,214 INFO  [Listener at localhost/34381] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:50,214 INFO  [Listener at localhost/34381] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:50,215 INFO  [Listener at localhost/34381] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:46206
2020-04-16 00:19:50,215 INFO  [Listener at localhost/34381] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:50,215 INFO  [Listener at localhost/34381] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:50,220 INFO  [Listener at localhost/34381] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:50,240 INFO  [Listener at localhost/34381] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:50,245 INFO  [Listener at localhost/34381] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:50,247 INFO  [Listener at localhost/34381] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:50,248 INFO  [Listener at localhost/34381] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:50,249 INFO  [Listener at localhost/34381] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:50,250 INFO  [Listener at localhost/34381] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33541
2020-04-16 00:19:50,250 INFO  [Listener at localhost/34381] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:50,271 INFO  [Listener at localhost/34381] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30feffc{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:50,272 INFO  [Listener at localhost/34381] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@bcb09a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:50,602 INFO  [Listener at localhost/34381] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58065f0c{/,file:///tmp/jetty-localhost-33541-datanode-_-any-7490970058217315647.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:50,603 INFO  [Listener at localhost/34381] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3605c4d3{HTTP/1.1,[http/1.1]}{localhost:33541}
2020-04-16 00:19:50,604 INFO  [Listener at localhost/34381] server.Server (Server.java:doStart(419)) - Started @9026ms
2020-04-16 00:19:50,797 INFO  [Listener at localhost/34381] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46159
2020-04-16 00:19:50,798 INFO  [Listener at localhost/34381] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:50,798 INFO  [Listener at localhost/34381] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:50,799 INFO  [Listener at localhost/34381] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:50,801 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:50,801 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@187eb9a8] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:50,821 INFO  [Listener at localhost/41826] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:41826
2020-04-16 00:19:50,826 INFO  [Listener at localhost/41826] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:50,828 INFO  [Listener at localhost/41826] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:50,829 INFO  [Thread-81] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34110 starting to offer service
2020-04-16 00:19:50,829 INFO  [Listener at localhost/41826] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:50,830 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:50,831 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:50,860 INFO  [Listener at localhost/41826] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:50,862 INFO  [Listener at localhost/41826] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:50,865 INFO  [Listener at localhost/41826] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:50,867 INFO  [Listener at localhost/41826] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:50,868 INFO  [Listener at localhost/41826] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:50,868 INFO  [Listener at localhost/41826] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:50,868 INFO  [Listener at localhost/41826] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:50,873 INFO  [Listener at localhost/41826] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:50,874 INFO  [Listener at localhost/41826] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:50,874 INFO  [Listener at localhost/41826] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:50,875 INFO  [Listener at localhost/41826] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:43686
2020-04-16 00:19:50,875 INFO  [Listener at localhost/41826] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:50,875 INFO  [Listener at localhost/41826] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:50,892 INFO  [Listener at localhost/41826] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:50,921 INFO  [Listener at localhost/41826] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:50,943 INFO  [Thread-58] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34110
2020-04-16 00:19:50,951 INFO  [Thread-58] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:50,954 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/in_use.lock acquired by nodename 7410@d082457d4d4a
2020-04-16 00:19:50,956 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 is not formatted for namespace 2127609111. Formatting...
2020-04-16 00:19:50,957 INFO  [Thread-81] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34110
2020-04-16 00:19:50,957 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1ee5e187-c63c-4f6c-aa72-e9e6dff1dc3d for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 
2020-04-16 00:19:50,958 INFO  [Thread-81] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:50,960 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/in_use.lock acquired by nodename 7410@d082457d4d4a
2020-04-16 00:19:50,960 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 is not formatted for namespace 2127609111. Formatting...
2020-04-16 00:19:50,960 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-658b3d08-d292-4cda-9307-7caca56cc69c for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 
2020-04-16 00:19:50,964 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/in_use.lock acquired by nodename 7410@d082457d4d4a
2020-04-16 00:19:50,964 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 is not formatted for namespace 2127609111. Formatting...
2020-04-16 00:19:50,965 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a384341c-ca4d-4227-bbb8-9db3b7ea8461 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 
2020-04-16 00:19:50,969 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/in_use.lock acquired by nodename 7410@d082457d4d4a
2020-04-16 00:19:50,969 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 is not formatted for namespace 2127609111. Formatting...
2020-04-16 00:19:50,970 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-faed138a-48cf-4c51-94b5-1416227165b0 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 
2020-04-16 00:19:50,999 INFO  [Listener at localhost/41826] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:51,003 INFO  [Listener at localhost/41826] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:51,003 INFO  [Listener at localhost/41826] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:51,003 INFO  [Listener at localhost/41826] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:51,005 INFO  [Listener at localhost/41826] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39021
2020-04-16 00:19:51,005 INFO  [Listener at localhost/41826] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:51,019 INFO  [Listener at localhost/41826] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@466d49f0{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:51,049 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,050 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,049 INFO  [Listener at localhost/41826] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d7e1102{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:51,066 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 and block pool id BP-69109838-172.17.0.20-1586996385043 is not formatted. Formatting ...
2020-04-16 00:19:51,082 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-69109838-172.17.0.20-1586996385043 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-69109838-172.17.0.20-1586996385043/current
2020-04-16 00:19:51,091 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,092 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,092 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 and block pool id BP-69109838-172.17.0.20-1586996385043 is not formatted. Formatting ...
2020-04-16 00:19:51,092 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-69109838-172.17.0.20-1586996385043 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-69109838-172.17.0.20-1586996385043/current
2020-04-16 00:19:51,147 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,148 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,148 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 and block pool id BP-69109838-172.17.0.20-1586996385043 is not formatted. Formatting ...
2020-04-16 00:19:51,148 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-69109838-172.17.0.20-1586996385043 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-69109838-172.17.0.20-1586996385043/current
2020-04-16 00:19:51,157 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,157 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,158 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 and block pool id BP-69109838-172.17.0.20-1586996385043 is not formatted. Formatting ...
2020-04-16 00:19:51,158 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-69109838-172.17.0.20-1586996385043 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-69109838-172.17.0.20-1586996385043/current
2020-04-16 00:19:51,161 INFO  [Thread-58] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=2127609111;bpid=BP-69109838-172.17.0.20-1586996385043;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2127609111;c=1586996385043;bpid=BP-69109838-172.17.0.20-1586996385043;dnuuid=null
2020-04-16 00:19:51,163 INFO  [Thread-58] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID a1c90093-73a6-4492-8131-24103e63cc9b
2020-04-16 00:19:51,169 INFO  [Thread-81] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=2127609111;bpid=BP-69109838-172.17.0.20-1586996385043;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2127609111;c=1586996385043;bpid=BP-69109838-172.17.0.20-1586996385043;dnuuid=null
2020-04-16 00:19:51,177 INFO  [Thread-81] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID aff595ec-11f2-4b52-8721-464bf3ebbc39
2020-04-16 00:19:51,410 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1ee5e187-c63c-4f6c-aa72-e9e6dff1dc3d
2020-04-16 00:19:51,411 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, StorageType: DISK
2020-04-16 00:19:51,410 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-658b3d08-d292-4cda-9307-7caca56cc69c
2020-04-16 00:19:51,433 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, StorageType: DISK
2020-04-16 00:19:51,441 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a384341c-ca4d-4227-bbb8-9db3b7ea8461
2020-04-16 00:19:51,441 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, StorageType: DISK
2020-04-16 00:19:51,454 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-faed138a-48cf-4c51-94b5-1416227165b0
2020-04-16 00:19:51,454 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, StorageType: DISK
2020-04-16 00:19:51,485 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:51,489 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:51,507 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:51,515 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:51,533 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:51,535 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:51,549 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:51,537 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:51,550 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:51,550 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:51,552 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,557 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,558 INFO  [Listener at localhost/41826] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@17ae7628{/,file:///tmp/jetty-localhost-39021-datanode-_-any-33021582087570787.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:51,559 INFO  [Thread-104] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:19:51,558 INFO  [Thread-101] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:19:51,562 INFO  [Thread-102] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:19:51,562 INFO  [Listener at localhost/41826] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1136b469{HTTP/1.1,[http/1.1]}{localhost:39021}
2020-04-16 00:19:51,629 INFO  [Thread-103] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:19:51,630 INFO  [Listener at localhost/41826] server.Server (Server.java:doStart(419)) - Started @10027ms
2020-04-16 00:19:51,746 INFO  [Thread-103] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-69109838-172.17.0.20-1586996385043 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 117ms
2020-04-16 00:19:51,757 INFO  [Listener at localhost/41826] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45548
2020-04-16 00:19:51,758 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b87581] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:51,758 INFO  [Listener at localhost/41826] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:51,759 INFO  [Listener at localhost/41826] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:51,759 INFO  [Listener at localhost/41826] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:51,761 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:51,773 INFO  [Listener at localhost/43706] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:43706
2020-04-16 00:19:51,791 INFO  [Listener at localhost/43706] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:51,799 INFO  [Listener at localhost/43706] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:51,808 INFO  [Listener at localhost/43706] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:51,808 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:51,809 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:51,809 INFO  [Thread-115] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34110 starting to offer service
2020-04-16 00:19:51,838 INFO  [Thread-102] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-69109838-172.17.0.20-1586996385043 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 276ms
2020-04-16 00:19:51,882 INFO  [Thread-104] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-69109838-172.17.0.20-1586996385043 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 321ms
2020-04-16 00:19:51,883 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-69109838-172.17.0.20-1586996385043: 326ms
2020-04-16 00:19:51,941 INFO  [Thread-126] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:19:51,942 INFO  [Thread-126] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-69109838-172.17.0.20-1586996385043/current/replicas doesn't exist 
2020-04-16 00:19:51,943 INFO  [Thread-127] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:19:51,951 INFO  [Thread-126] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 10ms
2020-04-16 00:19:51,943 INFO  [Thread-127] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-69109838-172.17.0.20-1586996385043/current/replicas doesn't exist 
2020-04-16 00:19:51,955 INFO  [Thread-127] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 12ms
2020-04-16 00:19:51,956 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-69109838-172.17.0.20-1586996385043: 37ms
2020-04-16 00:19:51,958 INFO  [Thread-101] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-69109838-172.17.0.20-1586996385043 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 396ms
2020-04-16 00:19:51,959 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:51,960 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-a384341c-ca4d-4227-bbb8-9db3b7ea8461): finished scanning block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:51,961 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-69109838-172.17.0.20-1586996385043: 408ms
2020-04-16 00:19:51,961 INFO  [Thread-128] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:19:51,963 INFO  [Thread-128] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-69109838-172.17.0.20-1586996385043/current/replicas doesn't exist 
2020-04-16 00:19:51,963 INFO  [Thread-128] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 2ms
2020-04-16 00:19:51,964 INFO  [Thread-129] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:19:51,964 INFO  [Thread-129] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-69109838-172.17.0.20-1586996385043/current/replicas doesn't exist 
2020-04-16 00:19:51,964 INFO  [Thread-129] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 0ms
2020-04-16 00:19:51,961 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:51,998 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-1ee5e187-c63c-4f6c-aa72-e9e6dff1dc3d): finished scanning block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,003 INFO  [Thread-115] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34110
2020-04-16 00:19:52,003 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-69109838-172.17.0.20-1586996385043: 41ms
2020-04-16 00:19:52,004 INFO  [Thread-115] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:52,004 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:52,004 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:52,005 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-658b3d08-d292-4cda-9307-7caca56cc69c): finished scanning block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,005 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-faed138a-48cf-4c51-94b5-1416227165b0): finished scanning block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,006 INFO  [Thread-115] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/in_use.lock acquired by nodename 7410@d082457d4d4a
2020-04-16 00:19:52,006 INFO  [Thread-115] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 is not formatted for namespace 2127609111. Formatting...
2020-04-16 00:19:52,006 INFO  [Thread-115] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a00d030d-2ddb-49fe-a07e-38ad1b3914cb for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 
2020-04-16 00:19:52,011 INFO  [Thread-115] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/in_use.lock acquired by nodename 7410@d082457d4d4a
2020-04-16 00:19:52,012 INFO  [Thread-115] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 is not formatted for namespace 2127609111. Formatting...
2020-04-16 00:19:52,012 INFO  [Thread-115] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ef342479-244b-4dd7-a25c-f052c414191e for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 
2020-04-16 00:19:52,040 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-a384341c-ca4d-4227-bbb8-9db3b7ea8461): no suitable block pools found to scan.  Waiting 1814399919 ms.
2020-04-16 00:19:52,048 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-658b3d08-d292-4cda-9307-7caca56cc69c): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-04-16 00:19:52,048 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-faed138a-48cf-4c51-94b5-1416227165b0): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-04-16 00:19:52,049 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-1ee5e187-c63c-4f6c-aa72-e9e6dff1dc3d): no suitable block pools found to scan.  Waiting 1814399910 ms.
2020-04-16 00:19:52,066 INFO  [Thread-58] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 1:28 AM with interval of 21600000ms
2020-04-16 00:19:52,091 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,092 INFO  [Thread-115] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,092 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 and block pool id BP-69109838-172.17.0.20-1586996385043 is not formatted. Formatting ...
2020-04-16 00:19:52,093 INFO  [Thread-81] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 12:23 AM with interval of 21600000ms
2020-04-16 00:19:52,117 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-69109838-172.17.0.20-1586996385043 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-69109838-172.17.0.20-1586996385043/current
2020-04-16 00:19:52,148 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid aff595ec-11f2-4b52-8721-464bf3ebbc39) service to localhost/127.0.0.1:34110 beginning handshake with NN
2020-04-16 00:19:52,148 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid a1c90093-73a6-4492-8131-24103e63cc9b) service to localhost/127.0.0.1:34110 beginning handshake with NN
2020-04-16 00:19:52,177 INFO  [IPC Server handler 2 on default port 34110] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46206, datanodeUuid=aff595ec-11f2-4b52-8721-464bf3ebbc39, infoPort=46159, infoSecurePort=0, ipcPort=41826, storageInfo=lv=-57;cid=testClusterID;nsid=2127609111;c=1586996385043) storage aff595ec-11f2-4b52-8721-464bf3ebbc39
2020-04-16 00:19:52,179 INFO  [IPC Server handler 2 on default port 34110] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46206
2020-04-16 00:19:52,179 INFO  [IPC Server handler 2 on default port 34110] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aff595ec-11f2-4b52-8721-464bf3ebbc39 (127.0.0.1:46206).
2020-04-16 00:19:52,202 INFO  [IPC Server handler 1 on default port 34110] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41362, datanodeUuid=a1c90093-73a6-4492-8131-24103e63cc9b, infoPort=41392, infoSecurePort=0, ipcPort=34381, storageInfo=lv=-57;cid=testClusterID;nsid=2127609111;c=1586996385043) storage a1c90093-73a6-4492-8131-24103e63cc9b
2020-04-16 00:19:52,203 INFO  [IPC Server handler 1 on default port 34110] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41362
2020-04-16 00:19:52,203 INFO  [IPC Server handler 1 on default port 34110] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a1c90093-73a6-4492-8131-24103e63cc9b (127.0.0.1:41362).
2020-04-16 00:19:52,212 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid aff595ec-11f2-4b52-8721-464bf3ebbc39) service to localhost/127.0.0.1:34110 successfully registered with NN
2020-04-16 00:19:52,212 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34110 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:19:52,217 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid a1c90093-73a6-4492-8131-24103e63cc9b) service to localhost/127.0.0.1:34110 successfully registered with NN
2020-04-16 00:19:52,217 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34110 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:19:52,221 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,221 INFO  [Thread-115] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,221 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 and block pool id BP-69109838-172.17.0.20-1586996385043 is not formatted. Formatting ...
2020-04-16 00:19:52,221 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-69109838-172.17.0.20-1586996385043 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-69109838-172.17.0.20-1586996385043/current
2020-04-16 00:19:52,245 INFO  [Thread-115] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=2127609111;bpid=BP-69109838-172.17.0.20-1586996385043;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2127609111;c=1586996385043;bpid=BP-69109838-172.17.0.20-1586996385043;dnuuid=null
2020-04-16 00:19:52,254 INFO  [Thread-115] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID c210d863-9ee8-4750-822b-002b5573d770
2020-04-16 00:19:52,277 INFO  [Thread-115] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a00d030d-2ddb-49fe-a07e-38ad1b3914cb
2020-04-16 00:19:52,278 INFO  [Thread-115] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, StorageType: DISK
2020-04-16 00:19:52,291 INFO  [IPC Server handler 0 on default port 34110] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1ee5e187-c63c-4f6c-aa72-e9e6dff1dc3d for DN 127.0.0.1:41362
2020-04-16 00:19:52,292 INFO  [IPC Server handler 0 on default port 34110] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a384341c-ca4d-4227-bbb8-9db3b7ea8461 for DN 127.0.0.1:41362
2020-04-16 00:19:52,315 INFO  [IPC Server handler 6 on default port 34110] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-658b3d08-d292-4cda-9307-7caca56cc69c for DN 127.0.0.1:46206
2020-04-16 00:19:52,316 INFO  [IPC Server handler 6 on default port 34110] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-faed138a-48cf-4c51-94b5-1416227165b0 for DN 127.0.0.1:46206
2020-04-16 00:19:52,318 INFO  [Thread-115] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ef342479-244b-4dd7-a25c-f052c414191e
2020-04-16 00:19:52,319 INFO  [Thread-115] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, StorageType: DISK
2020-04-16 00:19:52,319 INFO  [Thread-115] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:52,322 INFO  [Thread-115] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:52,343 INFO  [Thread-115] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:52,343 INFO  [Thread-115] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:52,346 INFO  [Thread-115] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:52,357 INFO  [Thread-115] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,385 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:19:52,401 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:19:52,491 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc1bcc20aa70584fe: Processing first storage report for DS-faed138a-48cf-4c51-94b5-1416227165b0 from datanode aff595ec-11f2-4b52-8721-464bf3ebbc39
2020-04-16 00:19:52,498 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1bcc20aa70584fe: from storage DS-faed138a-48cf-4c51-94b5-1416227165b0 node DatanodeRegistration(127.0.0.1:46206, datanodeUuid=aff595ec-11f2-4b52-8721-464bf3ebbc39, infoPort=46159, infoSecurePort=0, ipcPort=41826, storageInfo=lv=-57;cid=testClusterID;nsid=2127609111;c=1586996385043), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-16 00:19:52,498 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb2c25e6ba9c0ab85: Processing first storage report for DS-a384341c-ca4d-4227-bbb8-9db3b7ea8461 from datanode a1c90093-73a6-4492-8131-24103e63cc9b
2020-04-16 00:19:52,498 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb2c25e6ba9c0ab85: from storage DS-a384341c-ca4d-4227-bbb8-9db3b7ea8461 node DatanodeRegistration(127.0.0.1:41362, datanodeUuid=a1c90093-73a6-4492-8131-24103e63cc9b, infoPort=41392, infoSecurePort=0, ipcPort=34381, storageInfo=lv=-57;cid=testClusterID;nsid=2127609111;c=1586996385043), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:52,498 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc1bcc20aa70584fe: Processing first storage report for DS-658b3d08-d292-4cda-9307-7caca56cc69c from datanode aff595ec-11f2-4b52-8721-464bf3ebbc39
2020-04-16 00:19:52,498 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc1bcc20aa70584fe: from storage DS-658b3d08-d292-4cda-9307-7caca56cc69c node DatanodeRegistration(127.0.0.1:46206, datanodeUuid=aff595ec-11f2-4b52-8721-464bf3ebbc39, infoPort=46159, infoSecurePort=0, ipcPort=41826, storageInfo=lv=-57;cid=testClusterID;nsid=2127609111;c=1586996385043), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:52,499 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb2c25e6ba9c0ab85: Processing first storage report for DS-1ee5e187-c63c-4f6c-aa72-e9e6dff1dc3d from datanode a1c90093-73a6-4492-8131-24103e63cc9b
2020-04-16 00:19:52,499 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb2c25e6ba9c0ab85: from storage DS-1ee5e187-c63c-4f6c-aa72-e9e6dff1dc3d node DatanodeRegistration(127.0.0.1:41362, datanodeUuid=a1c90093-73a6-4492-8131-24103e63cc9b, infoPort=41392, infoSecurePort=0, ipcPort=34381, storageInfo=lv=-57;cid=testClusterID;nsid=2127609111;c=1586996385043), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:52,514 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-69109838-172.17.0.20-1586996385043 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 129ms
2020-04-16 00:19:52,531 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-69109838-172.17.0.20-1586996385043 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 130ms
2020-04-16 00:19:52,561 INFO  [Thread-115] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-69109838-172.17.0.20-1586996385043: 204ms
2020-04-16 00:19:52,562 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:19:52,564 INFO  [Thread-142] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-69109838-172.17.0.20-1586996385043/current/replicas doesn't exist 
2020-04-16 00:19:52,565 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 1ms
2020-04-16 00:19:52,566 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:19:52,567 INFO  [Thread-143] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-69109838-172.17.0.20-1586996385043/current/replicas doesn't exist 
2020-04-16 00:19:52,573 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 6ms
2020-04-16 00:19:52,579 INFO  [Thread-115] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-69109838-172.17.0.20-1586996385043: 17ms
2020-04-16 00:19:52,580 INFO  [Thread-115] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 5:35 AM with interval of 21600000ms
2020-04-16 00:19:52,603 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid c210d863-9ee8-4750-822b-002b5573d770) service to localhost/127.0.0.1:34110 beginning handshake with NN
2020-04-16 00:19:52,614 INFO  [IPC Server handler 4 on default port 34110] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43686, datanodeUuid=c210d863-9ee8-4750-822b-002b5573d770, infoPort=45548, infoSecurePort=0, ipcPort=43706, storageInfo=lv=-57;cid=testClusterID;nsid=2127609111;c=1586996385043) storage c210d863-9ee8-4750-822b-002b5573d770
2020-04-16 00:19:52,615 INFO  [IPC Server handler 4 on default port 34110] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43686
2020-04-16 00:19:52,615 INFO  [IPC Server handler 4 on default port 34110] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c210d863-9ee8-4750-822b-002b5573d770 (127.0.0.1:43686).
2020-04-16 00:19:52,621 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid c210d863-9ee8-4750-822b-002b5573d770) service to localhost/127.0.0.1:34110 successfully registered with NN
2020-04-16 00:19:52,621 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34110 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:19:52,625 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:52,630 INFO  [IPC Server handler 7 on default port 34110] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a00d030d-2ddb-49fe-a07e-38ad1b3914cb for DN 127.0.0.1:43686
2020-04-16 00:19:52,630 INFO  [IPC Server handler 7 on default port 34110] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ef342479-244b-4dd7-a25c-f052c414191e for DN 127.0.0.1:43686
2020-04-16 00:19:52,632 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb2c25e6ba9c0ab85,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 45 msec to generate and 240 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:19:52,649 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,641 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc1bcc20aa70584fe,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 55 msec to generate and 239 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:19:52,650 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,639 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-69109838-172.17.0.20-1586996385043 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:52,633 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-ef342479-244b-4dd7-a25c-f052c414191e): finished scanning block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,667 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-ef342479-244b-4dd7-a25c-f052c414191e): no suitable block pools found to scan.  Waiting 1814399912 ms.
2020-04-16 00:19:52,670 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3ba2a166a15bc831: Processing first storage report for DS-a00d030d-2ddb-49fe-a07e-38ad1b3914cb from datanode c210d863-9ee8-4750-822b-002b5573d770
2020-04-16 00:19:52,670 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3ba2a166a15bc831: from storage DS-a00d030d-2ddb-49fe-a07e-38ad1b3914cb node DatanodeRegistration(127.0.0.1:43686, datanodeUuid=c210d863-9ee8-4750-822b-002b5573d770, infoPort=45548, infoSecurePort=0, ipcPort=43706, storageInfo=lv=-57;cid=testClusterID;nsid=2127609111;c=1586996385043), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:52,670 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3ba2a166a15bc831: Processing first storage report for DS-ef342479-244b-4dd7-a25c-f052c414191e from datanode c210d863-9ee8-4750-822b-002b5573d770
2020-04-16 00:19:52,670 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3ba2a166a15bc831: from storage DS-ef342479-244b-4dd7-a25c-f052c414191e node DatanodeRegistration(127.0.0.1:43686, datanodeUuid=c210d863-9ee8-4750-822b-002b5573d770, infoPort=45548, infoSecurePort=0, ipcPort=43706, storageInfo=lv=-57;cid=testClusterID;nsid=2127609111;c=1586996385043), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:52,693 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3ba2a166a15bc831,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 37 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:19:52,693 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,695 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-a00d030d-2ddb-49fe-a07e-38ad1b3914cb): finished scanning block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:52,696 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-a00d030d-2ddb-49fe-a07e-38ad1b3914cb): no suitable block pools found to scan.  Waiting 1814399883 ms.
2020-04-16 00:19:53,015 INFO  [IPC Server handler 3 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,035 INFO  [Listener at localhost/43706] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-04-16 00:19:53,067 INFO  [IPC Server handler 1 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,089 INFO  [IPC Server handler 2 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,118 INFO  [IPC Server handler 6 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/input	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:19:53,232 INFO  [IPC Server handler 0 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/a	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:53,322 INFO  [IPC Server handler 9 on default port 34110] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:41362, 127.0.0.1:46206, 127.0.0.1:43686 for /user/root/input/a
2020-04-16 00:19:53,352 INFO  [Thread-150] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,499 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46624 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001 src: /127.0.0.1:46624 dest: /127.0.0.1:41362
2020-04-16 00:19:53,529 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46624 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,548 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:52918 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001 src: /127.0.0.1:52918 dest: /127.0.0.1:46206
2020-04-16 00:19:53,587 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:52918 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,594 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:57508 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001 src: /127.0.0.1:57508 dest: /127.0.0.1:43686
2020-04-16 00:19:53,712 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57508, dest: /127.0.0.1:43686, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: c210d863-9ee8-4750-822b-002b5573d770, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, duration(ns): 83429787
2020-04-16 00:19:53,714 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:53,730 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43686]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52918, dest: /127.0.0.1:46206, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: aff595ec-11f2-4b52-8721-464bf3ebbc39, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, duration(ns): 107750379
2020-04-16 00:19:53,738 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43686]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43686] terminating
2020-04-16 00:19:53,767 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46206, 127.0.0.1:43686]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46624, dest: /127.0.0.1:41362, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: a1c90093-73a6-4492-8131-24103e63cc9b, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, duration(ns): 127528840
2020-04-16 00:19:53,772 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46206, 127.0.0.1:43686]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46206, 127.0.0.1:43686] terminating
2020-04-16 00:19:53,787 INFO  [IPC Server handler 6 on default port 34110] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/a is closed by DFSClient_NONMAPREDUCE_-150464003_1
2020-04-16 00:19:53,802 INFO  [IPC Server handler 0 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/b	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:53,823 INFO  [IPC Server handler 9 on default port 34110] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:46206, 127.0.0.1:41362, 127.0.0.1:43686 for /user/root/input/b
2020-04-16 00:19:53,832 INFO  [Thread-159] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,835 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:52922 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002 src: /127.0.0.1:52922 dest: /127.0.0.1:46206
2020-04-16 00:19:53,836 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:52922 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,840 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46638 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002 src: /127.0.0.1:46638 dest: /127.0.0.1:41362
2020-04-16 00:19:53,841 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46638 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,849 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:57514 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002 src: /127.0.0.1:57514 dest: /127.0.0.1:43686
2020-04-16 00:19:53,883 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57514, dest: /127.0.0.1:43686, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: c210d863-9ee8-4750-822b-002b5573d770, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, duration(ns): 30912679
2020-04-16 00:19:53,893 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:53,908 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43686]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46638, dest: /127.0.0.1:41362, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: a1c90093-73a6-4492-8131-24103e63cc9b, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, duration(ns): 55106445
2020-04-16 00:19:53,921 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43686]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43686] terminating
2020-04-16 00:19:53,930 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41362, 127.0.0.1:43686]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52922, dest: /127.0.0.1:46206, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: aff595ec-11f2-4b52-8721-464bf3ebbc39, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, duration(ns): 77846663
2020-04-16 00:19:53,931 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41362, 127.0.0.1:43686]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41362, 127.0.0.1:43686] terminating
2020-04-16 00:19:53,950 INFO  [IPC Server handler 5 on default port 34110] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/b is closed by DFSClient_NONMAPREDUCE_-150464003_1
2020-04-16 00:19:53,971 INFO  [IPC Server handler 1 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/c	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:53,993 INFO  [IPC Server handler 2 on default port 34110] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:41362, 127.0.0.1:46206, 127.0.0.1:43686 for /user/root/input/c
2020-04-16 00:19:53,997 INFO  [Thread-167] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:54,004 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46642 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003 src: /127.0.0.1:46642 dest: /127.0.0.1:41362
2020-04-16 00:19:54,005 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46642 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:54,034 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:52930 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003 src: /127.0.0.1:52930 dest: /127.0.0.1:46206
2020-04-16 00:19:54,035 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:52930 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:54,049 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:57520 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003 src: /127.0.0.1:57520 dest: /127.0.0.1:43686
2020-04-16 00:19:54,104 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57520, dest: /127.0.0.1:43686, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: c210d863-9ee8-4750-822b-002b5573d770, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, duration(ns): 34026789
2020-04-16 00:19:54,104 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:54,132 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43686]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52930, dest: /127.0.0.1:46206, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: aff595ec-11f2-4b52-8721-464bf3ebbc39, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, duration(ns): 61091961
2020-04-16 00:19:54,132 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43686]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43686] terminating
2020-04-16 00:19:54,183 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46206, 127.0.0.1:43686]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46642, dest: /127.0.0.1:41362, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: a1c90093-73a6-4492-8131-24103e63cc9b, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, duration(ns): 91891019
2020-04-16 00:19:54,183 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46206, 127.0.0.1:43686]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46206, 127.0.0.1:43686] terminating
2020-04-16 00:19:54,197 INFO  [IPC Server handler 9 on default port 34110] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/c is closed by DFSClient_NONMAPREDUCE_-150464003_1
2020-04-16 00:19:54,232 INFO  [IPC Server handler 8 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:54,255 INFO  [IPC Server handler 4 on default port 34110] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:43686, 127.0.0.1:41362, 127.0.0.1:46206 for /user/root/archive/foo.har
2020-04-16 00:19:54,262 INFO  [Thread-175] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:54,273 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:57522 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004 src: /127.0.0.1:57522 dest: /127.0.0.1:43686
2020-04-16 00:19:54,275 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:57522 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:54,289 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46650 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004 src: /127.0.0.1:46650 dest: /127.0.0.1:41362
2020-04-16 00:19:54,290 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46650 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:54,305 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:52938 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004 src: /127.0.0.1:52938 dest: /127.0.0.1:46206
2020-04-16 00:19:54,417 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52938, dest: /127.0.0.1:46206, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: aff595ec-11f2-4b52-8721-464bf3ebbc39, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, duration(ns): 106257979
2020-04-16 00:19:54,417 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:54,429 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46206]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46650, dest: /127.0.0.1:41362, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: a1c90093-73a6-4492-8131-24103e63cc9b, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, duration(ns): 118215352
2020-04-16 00:19:54,430 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46206]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46206] terminating
2020-04-16 00:19:54,448 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41362, 127.0.0.1:46206]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57522, dest: /127.0.0.1:43686, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: c210d863-9ee8-4750-822b-002b5573d770, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, duration(ns): 116377018
2020-04-16 00:19:54,448 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41362, 127.0.0.1:46206]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41362, 127.0.0.1:46206] terminating
2020-04-16 00:19:54,475 INFO  [IPC Server handler 2 on default port 34110] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har is closed by DFSClient_NONMAPREDUCE_-150464003_1
2020-04-16 00:19:54,534 INFO  [IPC Server handler 3 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,550 INFO  [IPC Server handler 6 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,557 INFO  [IPC Server handler 0 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,564 INFO  [IPC Server handler 9 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,573 INFO  [IPC Server handler 8 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,576 INFO  [IPC Server handler 4 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/sub1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:54,587 INFO  [IPC Server handler 7 on default port 34110] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:41362, 127.0.0.1:43686, 127.0.0.1:46206 for /user/root/archive/sub1
2020-04-16 00:19:54,592 INFO  [Thread-183] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:54,597 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46664 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005 src: /127.0.0.1:46664 dest: /127.0.0.1:41362
2020-04-16 00:19:54,598 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:46664 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:54,609 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:57540 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005 src: /127.0.0.1:57540 dest: /127.0.0.1:43686
2020-04-16 00:19:54,610 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:57540 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:54,619 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-150464003_1 at /127.0.0.1:52954 [Receiving block BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005 src: /127.0.0.1:52954 dest: /127.0.0.1:46206
2020-04-16 00:19:54,680 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52954, dest: /127.0.0.1:46206, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: aff595ec-11f2-4b52-8721-464bf3ebbc39, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, duration(ns): 57995570
2020-04-16 00:19:54,680 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:54,686 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46206]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57540, dest: /127.0.0.1:43686, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: c210d863-9ee8-4750-822b-002b5573d770, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, duration(ns): 55053977
2020-04-16 00:19:54,687 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46206]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46206] terminating
2020-04-16 00:19:54,689 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43686, 127.0.0.1:46206]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46664, dest: /127.0.0.1:41362, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150464003_1, offset: 0, srvID: a1c90093-73a6-4492-8131-24103e63cc9b, blockid: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, duration(ns): 57842170
2020-04-16 00:19:54,689 INFO  [PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43686, 127.0.0.1:46206]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-69109838-172.17.0.20-1586996385043:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43686, 127.0.0.1:46206] terminating
2020-04-16 00:19:54,693 INFO  [IPC Server handler 1 on default port 34110] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/sub1 is closed by DFSClient_NONMAPREDUCE_-150464003_1
2020-04-16 00:19:54,700 INFO  [IPC Server handler 3 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,702 INFO  [IPC Server handler 6 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,705 INFO  [IPC Server handler 0 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,708 INFO  [IPC Server handler 9 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,718 INFO  [IPC Server handler 8 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/sub1/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,721 INFO  [IPC Server handler 4 on default port 34110] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/sub1	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,722 INFO  [Listener at localhost/43706] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-04-16 00:19:54,722 INFO  [Listener at localhost/43706] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-04-16 00:19:54,723 INFO  [Listener at localhost/43706] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:19:54,724 WARN  [Listener at localhost/43706] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:19:54,725 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4565a70a] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:19:54,726 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-a00d030d-2ddb-49fe-a07e-38ad1b3914cb) exiting.
2020-04-16 00:19:54,726 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-ef342479-244b-4dd7-a25c-f052c414191e) exiting.
2020-04-16 00:19:54,843 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@17ae7628{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:19:54,871 INFO  [Listener at localhost/43706] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1136b469{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:19:54,871 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d7e1102{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:19:54,872 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@466d49f0{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:19:54,945 INFO  [Listener at localhost/43706] ipc.Server (Server.java:stop(3359)) - Stopping server on 43706
2020-04-16 00:19:54,973 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:19:54,978 WARN  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:19:54,978 WARN  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid c210d863-9ee8-4750-822b-002b5573d770) service to localhost/127.0.0.1:34110
2020-04-16 00:19:54,978 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid c210d863-9ee8-4750-822b-002b5573d770)
2020-04-16 00:19:54,978 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:19:54,978 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:54,982 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-69109838-172.17.0.20-1586996385043] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:54,985 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-69109838-172.17.0.20-1586996385043] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:54,996 INFO  [Listener at localhost/43706] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:19:54,996 INFO  [Listener at localhost/43706] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:19:54,997 INFO  [Listener at localhost/43706] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:19:54,997 INFO  [Listener at localhost/43706] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:19:55,012 INFO  [Listener at localhost/43706] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:19:55,012 INFO  [Listener at localhost/43706] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-04-16 00:19:55,012 INFO  [Listener at localhost/43706] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:19:55,012 WARN  [Listener at localhost/43706] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:19:55,013 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5bb8f9e2] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:19:55,014 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-faed138a-48cf-4c51-94b5-1416227165b0) exiting.
2020-04-16 00:19:55,026 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-658b3d08-d292-4cda-9307-7caca56cc69c) exiting.
2020-04-16 00:19:55,215 WARN  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid aff595ec-11f2-4b52-8721-464bf3ebbc39) service to localhost/127.0.0.1:34110
2020-04-16 00:19:55,215 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid aff595ec-11f2-4b52-8721-464bf3ebbc39)
2020-04-16 00:19:55,215 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:55,242 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-69109838-172.17.0.20-1586996385043] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:55,377 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-69109838-172.17.0.20-1586996385043] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:55,466 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58065f0c{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:19:55,467 INFO  [Listener at localhost/43706] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3605c4d3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:19:55,468 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@bcb09a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:19:55,468 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30feffc{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:19:55,473 INFO  [Listener at localhost/43706] ipc.Server (Server.java:stop(3359)) - Stopping server on 41826
2020-04-16 00:19:55,494 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:19:55,496 INFO  [Listener at localhost/43706] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:19:55,504 INFO  [Listener at localhost/43706] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:19:55,495 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:19:55,506 INFO  [Listener at localhost/43706] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:19:55,506 INFO  [Listener at localhost/43706] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:19:55,513 INFO  [Listener at localhost/43706] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:19:55,514 INFO  [Listener at localhost/43706] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-04-16 00:19:55,514 INFO  [Listener at localhost/43706] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:19:55,514 WARN  [Listener at localhost/43706] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:19:55,517 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6b5f8707] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:19:55,529 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-1ee5e187-c63c-4f6c-aa72-e9e6dff1dc3d) exiting.
2020-04-16 00:19:55,533 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-a384341c-ca4d-4227-bbb8-9db3b7ea8461) exiting.
2020-04-16 00:19:55,646 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1af1347d{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:19:55,741 INFO  [Listener at localhost/43706] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:19:55,742 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@282308c3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:19:55,742 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7726e185{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:19:55,750 INFO  [Listener at localhost/43706] ipc.Server (Server.java:stop(3359)) - Stopping server on 34381
2020-04-16 00:19:55,769 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:19:55,769 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:19:55,770 WARN  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:19:55,771 WARN  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid a1c90093-73a6-4492-8131-24103e63cc9b) service to localhost/127.0.0.1:34110
2020-04-16 00:19:55,873 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-69109838-172.17.0.20-1586996385043 (Datanode Uuid a1c90093-73a6-4492-8131-24103e63cc9b)
2020-04-16 00:19:55,873 INFO  [BP-69109838-172.17.0.20-1586996385043 heartbeating to localhost/127.0.0.1:34110] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-69109838-172.17.0.20-1586996385043
2020-04-16 00:19:55,874 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-69109838-172.17.0.20-1586996385043] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:55,874 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-69109838-172.17.0.20-1586996385043] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:55,890 INFO  [Listener at localhost/43706] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:19:55,890 INFO  [Listener at localhost/43706] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:19:55,892 INFO  [Listener at localhost/43706] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:19:55,892 INFO  [Listener at localhost/43706] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:19:55,896 INFO  [Listener at localhost/43706] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:19:55,897 INFO  [Listener at localhost/43706] hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-04-16 00:19:55,897 INFO  [Listener at localhost/43706] namenode.NameNode (NameNode.java:stop(1013)) - msx-hdfs NameNode stop
2020-04-16 00:19:55,897 INFO  [Listener at localhost/43706] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:19:55,898 INFO  [Listener at localhost/43706] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 30
2020-04-16 00:19:55,900 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@70e659aa] namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-16 00:19:55,902 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@73393584] namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-16 00:19:55,904 INFO  [Listener at localhost/43706] namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 31 Total time for transactions(ms): 56 Number of transactions batched in Syncs: 9 Number of syncs: 23 SyncTimes(ms): 3 2 
2020-04-16 00:19:55,906 INFO  [Listener at localhost/43706] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000031
2020-04-16 00:19:55,907 INFO  [Listener at localhost/43706] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000031
2020-04-16 00:19:55,908 INFO  [FSEditLogAsync] namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-16 00:19:55,909 INFO  [CacheReplicationMonitor(1590712299)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-16 00:19:55,944 INFO  [Listener at localhost/43706] ipc.Server (Server.java:stop(3359)) - Stopping server on 34110
2020-04-16 00:19:55,948 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:19:55,962 INFO  [StorageInfoMonitor] blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-04-16 00:19:55,961 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:19:55,953 INFO  [RedundancyMonitor] blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-04-16 00:19:56,015 INFO  [Listener at localhost/43706] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:19:56,015 INFO  [Listener at localhost/43706] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-04-16 00:19:56,018 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33fe57a9{/,null,UNAVAILABLE}{/hdfs}
2020-04-16 00:19:56,034 INFO  [Listener at localhost/43706] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:19:56,036 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:19:56,042 INFO  [Listener at localhost/43706] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:19:56,059 INFO  [Listener at localhost/43706] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-16 00:19:56,089 INFO  [Listener at localhost/43706] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-16 00:19:56,091 INFO  [Listener at localhost/43706] impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-listener testfinished org.apache.hadoop.tools.TestHadoopArchives#testOutputPathValidity
msx-listener writeFile testName is org.apache.hadoop.tools.TestHadoopArchives#testOutputPathValidity
msx-listener succeed
msx-listener all testRunFinished
