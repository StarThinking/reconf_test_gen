msx-listener test started org.apache.hadoop.tools.TestHadoopArchives#testRelativePath
msx-listener unitTestCounterInClass = 0
2020-04-16 00:19:50,534 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-16 00:19:51,600 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:51,620 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:51,623 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:51,624 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:51,654 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:51,655 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:51,655 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:51,656 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:51,751 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:51,760 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-16 00:19:51,761 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:51,761 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:51,771 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:51,772 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:51
2020-04-16 00:19:51,776 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:51,778 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:51,780 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-16 00:19:51,781 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:51,807 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:51,808 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:51,819 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:51,820 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:51,820 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:51,821 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:51,822 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:51,822 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:51,823 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:51,823 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:51,823 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:51,824 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:51,824 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:51,893 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-04-16 00:19:51,894 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:51,895 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:51,895 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:51,915 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:51,916 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:51,917 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-16 00:19:51,917 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:51,925 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:51,925 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:51,926 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:51,926 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:51,936 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:51,939 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:51,948 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:51,949 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:51,950 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-16 00:19:51,950 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:51,966 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:51,967 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:51,967 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:51,978 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:51,978 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:51,981 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:51,982 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:51,986 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-16 00:19:51,987 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:52,069 INFO  [main] namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:52,085 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 has been successfully formatted.
2020-04-16 00:19:52,093 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 has been successfully formatted.
2020-04-16 00:19:52,153 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:52,153 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:52,337 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:52,337 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:52,364 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-16 00:19:52,375 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1635)) - createNameNode []
2020-04-16 00:19:52,460 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-04-16 00:19:53,181 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-04-16 00:19:53,181 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-16 00:19:53,192 INFO  [main] namenode.NameNode (NameNode.java:<init>(932)) - msx-hdfs NameNode init
2020-04-16 00:19:53,220 INFO  [main] namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-16 00:19:53,296 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2205a05d] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:53,315 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-16 00:19:53,340 INFO  [main] util.log (Log.java:initialized(192)) - Logging initialized @4576ms
2020-04-16 00:19:53,493 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:53,498 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-16 00:19:53,515 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:53,523 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-16 00:19:53,524 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:53,524 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:53,568 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-16 00:19:53,576 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-16 00:19:53,592 INFO  [main] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37490
2020-04-16 00:19:53,595 INFO  [main] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:53,708 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:53,715 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:54,164 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33fe57a9{/,file:///tmp/jetty-localhost-37490-hdfs-_-any-5809700662812828404.dir/webapp/,AVAILABLE}{/hdfs}
2020-04-16 00:19:54,177 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:37490}
2020-04-16 00:19:54,178 INFO  [main] server.Server (Server.java:doStart(419)) - Started @5414ms
2020-04-16 00:19:54,212 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:54,221 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:54,221 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:54,222 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:54,222 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:54,222 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:54,223 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:54,225 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:54,226 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:54,227 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:54,227 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:54,228 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:54,228 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:54
2020-04-16 00:19:54,228 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:54,231 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:54,233 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-16 00:19:54,233 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:54,253 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:54,253 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:54,254 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:54,254 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:54,254 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:54,255 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:54,255 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:54,255 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:54,255 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:54,256 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:54,256 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:54,256 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:54,256 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:54,259 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:54,260 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:54,260 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-16 00:19:54,260 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:54,269 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:54,270 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:54,270 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:54,271 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:54,271 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:54,271 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:54,271 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:54,272 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:54,272 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-16 00:19:54,272 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:54,274 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:54,274 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:54,275 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:54,275 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:54,275 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:54,275 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:54,275 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:54,275 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-16 00:19:54,276 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:54,287 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/in_use.lock acquired by nodename 7525@175f05d804fa
2020-04-16 00:19:54,291 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/in_use.lock acquired by nodename 7525@175f05d804fa
2020-04-16 00:19:54,295 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current
2020-04-16 00:19:54,296 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current
2020-04-16 00:19:54,297 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-04-16 00:19:54,298 INFO  [main] namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-16 00:19:54,373 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-04-16 00:19:54,390 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-04-16 00:19:54,391 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-16 00:19:54,398 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-16 00:19:54,400 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-04-16 00:19:54,431 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-16 00:19:54,431 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 153 msecs
2020-04-16 00:19:54,671 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-04-16 00:19:54,714 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:54,736 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:54,997 INFO  [Listener at localhost/38719] namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38719 to access this namenode/service.
2020-04-16 00:19:55,001 INFO  [Listener at localhost/38719] namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-16 00:19:55,023 INFO  [Listener at localhost/38719] namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-16 00:19:55,076 INFO  [Listener at localhost/38719] blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-04-16 00:19:55,089 INFO  [Listener at localhost/38719] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-04-16 00:19:55,089 INFO  [Listener at localhost/38719] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-16 00:19:55,090 INFO  [Listener at localhost/38719] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-16 00:19:55,132 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-04-16 00:19:55,132 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-04-16 00:19:55,132 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-04-16 00:19:55,132 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-04-16 00:19:55,132 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-04-16 00:19:55,132 INFO  [Reconstruction Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 25 msec
2020-04-16 00:19:55,171 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:55,213 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:55,209 INFO  [Listener at localhost/38719] namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38719
2020-04-16 00:19:55,230 INFO  [Listener at localhost/38719] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-04-16 00:19:55,230 INFO  [Listener at localhost/38719] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-04-16 00:19:55,253 INFO  [Listener at localhost/38719] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 22 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-16 00:19:55,260 INFO  [Listener at localhost/38719] namenode.NameNode (NameNode.java:<init>(969)) - msx-hdfs NameNode start
2020-04-16 00:19:55,269 INFO  [CacheReplicationMonitor(806121773)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-16 00:19:55,300 INFO  [Listener at localhost/38719] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:55,428 INFO  [Listener at localhost/38719] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:55,470 INFO  [Listener at localhost/38719] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:55,541 INFO  [Listener at localhost/38719] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:55,542 INFO  [Listener at localhost/38719] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:55,562 INFO  [Listener at localhost/38719] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:55,571 INFO  [Listener at localhost/38719] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:55,576 INFO  [Listener at localhost/38719] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:55,579 INFO  [Listener at localhost/38719] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:55,585 INFO  [Listener at localhost/38719] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:55,594 INFO  [Listener at localhost/38719] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:43534
2020-04-16 00:19:55,597 INFO  [Listener at localhost/38719] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:55,598 INFO  [Listener at localhost/38719] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:55,623 INFO  [Listener at localhost/38719] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:55,630 INFO  [Listener at localhost/38719] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:55,634 INFO  [Listener at localhost/38719] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:55,638 INFO  [Listener at localhost/38719] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:55,638 INFO  [Listener at localhost/38719] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:55,639 INFO  [Listener at localhost/38719] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:55,648 INFO  [Listener at localhost/38719] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37515
2020-04-16 00:19:55,648 INFO  [Listener at localhost/38719] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:55,659 INFO  [Listener at localhost/38719] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7726e185{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:55,660 INFO  [Listener at localhost/38719] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@282308c3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:55,926 INFO  [Listener at localhost/38719] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1af1347d{/,file:///tmp/jetty-localhost-37515-datanode-_-any-3172949471979129925.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:55,927 INFO  [Listener at localhost/38719] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:37515}
2020-04-16 00:19:55,928 INFO  [Listener at localhost/38719] server.Server (Server.java:doStart(419)) - Started @7163ms
2020-04-16 00:19:57,046 INFO  [Listener at localhost/38719] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43577
2020-04-16 00:19:57,055 INFO  [Listener at localhost/38719] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:57,056 INFO  [Listener at localhost/38719] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:57,048 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61f2c3f0] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:57,076 INFO  [Listener at localhost/38719] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:57,085 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:57,115 INFO  [Listener at localhost/44874] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:44874
2020-04-16 00:19:57,147 INFO  [Listener at localhost/44874] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:57,155 INFO  [Listener at localhost/44874] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:57,185 INFO  [Thread-58] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38719 starting to offer service
2020-04-16 00:19:57,205 INFO  [Listener at localhost/44874] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:57,206 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:57,207 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:57,221 INFO  [Listener at localhost/44874] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:57,224 INFO  [Listener at localhost/44874] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:57,225 INFO  [Listener at localhost/44874] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:57,258 INFO  [Listener at localhost/44874] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:57,259 INFO  [Listener at localhost/44874] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:57,259 INFO  [Listener at localhost/44874] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:57,259 INFO  [Listener at localhost/44874] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:57,260 INFO  [Listener at localhost/44874] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:57,260 INFO  [Listener at localhost/44874] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:57,269 INFO  [Listener at localhost/44874] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:57,287 INFO  [Listener at localhost/44874] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:44756
2020-04-16 00:19:57,287 INFO  [Listener at localhost/44874] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:57,287 INFO  [Listener at localhost/44874] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:57,293 INFO  [Listener at localhost/44874] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:57,294 INFO  [Listener at localhost/44874] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:57,309 INFO  [Listener at localhost/44874] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:57,311 INFO  [Listener at localhost/44874] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:57,312 INFO  [Listener at localhost/44874] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:57,312 INFO  [Listener at localhost/44874] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:57,313 INFO  [Listener at localhost/44874] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44032
2020-04-16 00:19:57,314 INFO  [Listener at localhost/44874] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:57,316 INFO  [Listener at localhost/44874] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30feffc{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:57,317 INFO  [Listener at localhost/44874] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@bcb09a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:57,651 INFO  [Listener at localhost/44874] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58065f0c{/,file:///tmp/jetty-localhost-44032-datanode-_-any-3952621834802465321.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:57,652 INFO  [Listener at localhost/44874] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3605c4d3{HTTP/1.1,[http/1.1]}{localhost:44032}
2020-04-16 00:19:57,652 INFO  [Listener at localhost/44874] server.Server (Server.java:doStart(419)) - Started @8888ms
2020-04-16 00:19:58,039 INFO  [Thread-58] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38719
2020-04-16 00:19:58,042 INFO  [Thread-58] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:58,043 INFO  [Listener at localhost/44874] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42599
2020-04-16 00:19:58,044 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/in_use.lock acquired by nodename 7525@175f05d804fa
2020-04-16 00:19:58,044 INFO  [Listener at localhost/44874] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:58,045 INFO  [Listener at localhost/44874] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:58,045 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 is not formatted for namespace 744571073. Formatting...
2020-04-16 00:19:58,045 INFO  [Listener at localhost/44874] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:58,046 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@187eb9a8] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:58,047 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bf3a0f32-d8b4-4f2c-b8ea-937d3aeab879 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 
2020-04-16 00:19:58,057 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:58,059 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/in_use.lock acquired by nodename 7525@175f05d804fa
2020-04-16 00:19:58,060 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 is not formatted for namespace 744571073. Formatting...
2020-04-16 00:19:58,081 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9edb8b9c-574a-4693-88c4-605727136ba3 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 
2020-04-16 00:19:58,083 INFO  [Listener at localhost/44311] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:44311
2020-04-16 00:19:58,090 INFO  [Listener at localhost/44311] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:58,091 INFO  [Listener at localhost/44311] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:58,145 INFO  [Thread-81] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38719 starting to offer service
2020-04-16 00:19:58,146 INFO  [Listener at localhost/44311] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:58,149 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:58,149 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:58,157 INFO  [Listener at localhost/44311] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:58,160 INFO  [Listener at localhost/44311] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:58,164 INFO  [Listener at localhost/44311] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:58,240 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,240 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,241 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 and block pool id BP-1147382952-172.17.0.3-1586996392031 is not formatted. Formatting ...
2020-04-16 00:19:58,241 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1147382952-172.17.0.3-1586996392031 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1147382952-172.17.0.3-1586996392031/current
2020-04-16 00:19:58,249 INFO  [Listener at localhost/44311] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:58,249 INFO  [Listener at localhost/44311] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:58,250 INFO  [Listener at localhost/44311] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:58,250 INFO  [Listener at localhost/44311] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:58,251 INFO  [Listener at localhost/44311] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:58,251 INFO  [Listener at localhost/44311] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:58,251 INFO  [Listener at localhost/44311] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:58,252 INFO  [Listener at localhost/44311] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:37273
2020-04-16 00:19:58,252 INFO  [Listener at localhost/44311] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:58,252 INFO  [Listener at localhost/44311] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:58,283 INFO  [Listener at localhost/44311] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:58,293 INFO  [Listener at localhost/44311] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:58,296 INFO  [Listener at localhost/44311] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:58,299 INFO  [Listener at localhost/44311] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:58,299 INFO  [Listener at localhost/44311] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:58,299 INFO  [Listener at localhost/44311] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:58,300 INFO  [Listener at localhost/44311] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39663
2020-04-16 00:19:58,301 INFO  [Listener at localhost/44311] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:58,321 INFO  [Thread-81] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38719
2020-04-16 00:19:58,390 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,391 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,391 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 and block pool id BP-1147382952-172.17.0.3-1586996392031 is not formatted. Formatting ...
2020-04-16 00:19:58,391 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1147382952-172.17.0.3-1586996392031 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1147382952-172.17.0.3-1586996392031/current
2020-04-16 00:19:58,387 INFO  [Listener at localhost/44311] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@466d49f0{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:58,391 INFO  [Thread-81] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:58,397 INFO  [Listener at localhost/44311] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d7e1102{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:58,399 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/in_use.lock acquired by nodename 7525@175f05d804fa
2020-04-16 00:19:58,399 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 is not formatted for namespace 744571073. Formatting...
2020-04-16 00:19:58,399 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cb483715-c48a-4bc5-9ca5-5b2d989b506e for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 
2020-04-16 00:19:58,419 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/in_use.lock acquired by nodename 7525@175f05d804fa
2020-04-16 00:19:58,419 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 is not formatted for namespace 744571073. Formatting...
2020-04-16 00:19:58,420 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-455867be-60a3-42d4-9bff-7568de67679b for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 
2020-04-16 00:19:58,421 INFO  [Thread-58] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=744571073;bpid=BP-1147382952-172.17.0.3-1586996392031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=744571073;c=1586996392031;bpid=BP-1147382952-172.17.0.3-1586996392031;dnuuid=null
2020-04-16 00:19:58,455 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,461 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,461 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 and block pool id BP-1147382952-172.17.0.3-1586996392031 is not formatted. Formatting ...
2020-04-16 00:19:58,462 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1147382952-172.17.0.3-1586996392031 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1147382952-172.17.0.3-1586996392031/current
2020-04-16 00:19:58,474 INFO  [Thread-58] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID 17a857e8-15de-4f55-a2ee-0372c16121a7
2020-04-16 00:19:58,566 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,570 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,573 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 and block pool id BP-1147382952-172.17.0.3-1586996392031 is not formatted. Formatting ...
2020-04-16 00:19:58,574 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1147382952-172.17.0.3-1586996392031 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1147382952-172.17.0.3-1586996392031/current
2020-04-16 00:19:58,577 INFO  [Thread-81] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=744571073;bpid=BP-1147382952-172.17.0.3-1586996392031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=744571073;c=1586996392031;bpid=BP-1147382952-172.17.0.3-1586996392031;dnuuid=null
2020-04-16 00:19:58,593 INFO  [Thread-81] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID ba3b0511-ce87-4e1b-b227-0d521a9c47de
2020-04-16 00:19:58,739 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bf3a0f32-d8b4-4f2c-b8ea-937d3aeab879
2020-04-16 00:19:58,740 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, StorageType: DISK
2020-04-16 00:19:58,741 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-cb483715-c48a-4bc5-9ca5-5b2d989b506e
2020-04-16 00:19:58,765 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, StorageType: DISK
2020-04-16 00:19:58,770 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9edb8b9c-574a-4693-88c4-605727136ba3
2020-04-16 00:19:58,771 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, StorageType: DISK
2020-04-16 00:19:58,789 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:58,805 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-455867be-60a3-42d4-9bff-7568de67679b
2020-04-16 00:19:58,805 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, StorageType: DISK
2020-04-16 00:19:58,806 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:58,834 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:58,824 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:58,899 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:58,901 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:58,901 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:58,902 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,903 INFO  [Thread-101] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:19:58,909 INFO  [Thread-102] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:19:58,917 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:58,933 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:58,933 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:58,953 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:58,953 INFO  [Thread-103] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:19:58,954 INFO  [Thread-104] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:19:59,011 INFO  [Thread-103] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1147382952-172.17.0.3-1586996392031 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 58ms
2020-04-16 00:19:59,093 INFO  [Thread-104] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1147382952-172.17.0.3-1586996392031 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 139ms
2020-04-16 00:19:59,097 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1147382952-172.17.0.3-1586996392031: 144ms
2020-04-16 00:19:59,102 INFO  [Thread-102] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1147382952-172.17.0.3-1586996392031 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 193ms
2020-04-16 00:19:59,103 INFO  [Thread-109] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:19:59,103 INFO  [Thread-109] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1147382952-172.17.0.3-1586996392031/current/replicas doesn't exist 
2020-04-16 00:19:59,109 INFO  [Thread-110] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:19:59,114 INFO  [Thread-101] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1147382952-172.17.0.3-1586996392031 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 211ms
2020-04-16 00:19:59,115 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1147382952-172.17.0.3-1586996392031: 212ms
2020-04-16 00:19:59,109 INFO  [Thread-110] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1147382952-172.17.0.3-1586996392031/current/replicas doesn't exist 
2020-04-16 00:19:59,115 INFO  [Thread-111] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:19:59,115 INFO  [Thread-111] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1147382952-172.17.0.3-1586996392031/current/replicas doesn't exist 
2020-04-16 00:19:59,117 INFO  [Thread-112] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:19:59,117 INFO  [Thread-112] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1147382952-172.17.0.3-1586996392031/current/replicas doesn't exist 
2020-04-16 00:19:59,122 INFO  [Thread-109] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 19ms
2020-04-16 00:19:59,123 INFO  [Thread-110] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 14ms
2020-04-16 00:19:59,133 INFO  [Thread-112] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 16ms
2020-04-16 00:19:59,134 INFO  [Thread-111] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 19ms
2020-04-16 00:19:59,141 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031: 26ms
2020-04-16 00:19:59,141 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031: 43ms
2020-04-16 00:19:59,144 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:59,146 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-455867be-60a3-42d4-9bff-7568de67679b): finished scanning block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,165 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:59,180 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-cb483715-c48a-4bc5-9ca5-5b2d989b506e): finished scanning block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,181 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:59,183 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-bf3a0f32-d8b4-4f2c-b8ea-937d3aeab879): finished scanning block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,181 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:59,183 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-9edb8b9c-574a-4693-88c4-605727136ba3): finished scanning block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,228 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-455867be-60a3-42d4-9bff-7568de67679b): no suitable block pools found to scan.  Waiting 1814399916 ms.
2020-04-16 00:19:59,228 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-bf3a0f32-d8b4-4f2c-b8ea-937d3aeab879): no suitable block pools found to scan.  Waiting 1814399951 ms.
2020-04-16 00:19:59,229 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-9edb8b9c-574a-4693-88c4-605727136ba3): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-04-16 00:19:59,229 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-cb483715-c48a-4bc5-9ca5-5b2d989b506e): no suitable block pools found to scan.  Waiting 1814399916 ms.
2020-04-16 00:19:59,238 INFO  [Thread-58] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 5:56 AM with interval of 21600000ms
2020-04-16 00:19:59,246 INFO  [Listener at localhost/44311] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@17ae7628{/,file:///tmp/jetty-localhost-39663-datanode-_-any-758700169293792919.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:59,274 INFO  [Thread-81] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 1:50 AM with interval of 21600000ms
2020-04-16 00:19:59,290 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid 17a857e8-15de-4f55-a2ee-0372c16121a7) service to localhost/127.0.0.1:38719 beginning handshake with NN
2020-04-16 00:19:59,293 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid ba3b0511-ce87-4e1b-b227-0d521a9c47de) service to localhost/127.0.0.1:38719 beginning handshake with NN
2020-04-16 00:19:59,293 INFO  [Listener at localhost/44311] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1136b469{HTTP/1.1,[http/1.1]}{localhost:39663}
2020-04-16 00:19:59,322 INFO  [Listener at localhost/44311] server.Server (Server.java:doStart(419)) - Started @10557ms
2020-04-16 00:19:59,375 INFO  [IPC Server handler 1 on default port 38719] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43534, datanodeUuid=17a857e8-15de-4f55-a2ee-0372c16121a7, infoPort=43577, infoSecurePort=0, ipcPort=44874, storageInfo=lv=-57;cid=testClusterID;nsid=744571073;c=1586996392031) storage 17a857e8-15de-4f55-a2ee-0372c16121a7
2020-04-16 00:19:59,389 INFO  [IPC Server handler 1 on default port 38719] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43534
2020-04-16 00:19:59,389 INFO  [IPC Server handler 1 on default port 38719] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 17a857e8-15de-4f55-a2ee-0372c16121a7 (127.0.0.1:43534).
2020-04-16 00:19:59,397 INFO  [IPC Server handler 2 on default port 38719] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44756, datanodeUuid=ba3b0511-ce87-4e1b-b227-0d521a9c47de, infoPort=42599, infoSecurePort=0, ipcPort=44311, storageInfo=lv=-57;cid=testClusterID;nsid=744571073;c=1586996392031) storage ba3b0511-ce87-4e1b-b227-0d521a9c47de
2020-04-16 00:19:59,397 INFO  [IPC Server handler 2 on default port 38719] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44756
2020-04-16 00:19:59,401 INFO  [Listener at localhost/44311] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33426
2020-04-16 00:19:59,402 INFO  [Listener at localhost/44311] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:59,402 INFO  [Listener at localhost/44311] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:59,402 INFO  [Listener at localhost/44311] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:59,403 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b87581] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:59,403 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:59,405 INFO  [IPC Server handler 2 on default port 38719] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ba3b0511-ce87-4e1b-b227-0d521a9c47de (127.0.0.1:44756).
2020-04-16 00:19:59,410 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid 17a857e8-15de-4f55-a2ee-0372c16121a7) service to localhost/127.0.0.1:38719 successfully registered with NN
2020-04-16 00:19:59,410 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38719 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:19:59,414 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid ba3b0511-ce87-4e1b-b227-0d521a9c47de) service to localhost/127.0.0.1:38719 successfully registered with NN
2020-04-16 00:19:59,417 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38719 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:19:59,435 INFO  [Listener at localhost/45719] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:45719
2020-04-16 00:19:59,439 INFO  [Listener at localhost/45719] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:59,440 INFO  [Listener at localhost/45719] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:59,452 INFO  [Listener at localhost/45719] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:59,461 INFO  [Thread-125] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38719 starting to offer service
2020-04-16 00:19:59,467 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:59,489 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:59,620 INFO  [IPC Server handler 6 on default port 38719] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cb483715-c48a-4bc5-9ca5-5b2d989b506e for DN 127.0.0.1:44756
2020-04-16 00:19:59,621 INFO  [IPC Server handler 6 on default port 38719] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-455867be-60a3-42d4-9bff-7568de67679b for DN 127.0.0.1:44756
2020-04-16 00:19:59,669 INFO  [Thread-125] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38719
2020-04-16 00:19:59,682 INFO  [Thread-125] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:59,675 INFO  [IPC Server handler 4 on default port 38719] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf3a0f32-d8b4-4f2c-b8ea-937d3aeab879 for DN 127.0.0.1:43534
2020-04-16 00:19:59,701 INFO  [Thread-125] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/in_use.lock acquired by nodename 7525@175f05d804fa
2020-04-16 00:19:59,702 INFO  [Thread-125] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 is not formatted for namespace 744571073. Formatting...
2020-04-16 00:19:59,702 INFO  [Thread-125] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d08c0a67-f16a-4291-a119-60c63a7531ce for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 
2020-04-16 00:19:59,705 INFO  [IPC Server handler 4 on default port 38719] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9edb8b9c-574a-4693-88c4-605727136ba3 for DN 127.0.0.1:43534
2020-04-16 00:19:59,734 INFO  [Thread-125] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/in_use.lock acquired by nodename 7525@175f05d804fa
2020-04-16 00:19:59,735 INFO  [Thread-125] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 is not formatted for namespace 744571073. Formatting...
2020-04-16 00:19:59,735 INFO  [Thread-125] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d01ca016-b542-4e8b-b35e-0567e497fca4 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 
2020-04-16 00:19:59,800 INFO  [Thread-125] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,801 INFO  [Thread-125] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,801 INFO  [Thread-125] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 and block pool id BP-1147382952-172.17.0.3-1586996392031 is not formatted. Formatting ...
2020-04-16 00:19:59,802 INFO  [Thread-125] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1147382952-172.17.0.3-1586996392031 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1147382952-172.17.0.3-1586996392031/current
2020-04-16 00:19:59,879 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x40d9c39af2b0321a: Processing first storage report for DS-bf3a0f32-d8b4-4f2c-b8ea-937d3aeab879 from datanode 17a857e8-15de-4f55-a2ee-0372c16121a7
2020-04-16 00:19:59,881 INFO  [Thread-125] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,882 INFO  [Thread-125] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,898 INFO  [Thread-125] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 and block pool id BP-1147382952-172.17.0.3-1586996392031 is not formatted. Formatting ...
2020-04-16 00:19:59,898 INFO  [Thread-125] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1147382952-172.17.0.3-1586996392031 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1147382952-172.17.0.3-1586996392031/current
2020-04-16 00:19:59,898 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x40d9c39af2b0321a: from storage DS-bf3a0f32-d8b4-4f2c-b8ea-937d3aeab879 node DatanodeRegistration(127.0.0.1:43534, datanodeUuid=17a857e8-15de-4f55-a2ee-0372c16121a7, infoPort=43577, infoSecurePort=0, ipcPort=44874, storageInfo=lv=-57;cid=testClusterID;nsid=744571073;c=1586996392031), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-16 00:19:59,898 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbe4d1665bbad81aa: Processing first storage report for DS-cb483715-c48a-4bc5-9ca5-5b2d989b506e from datanode ba3b0511-ce87-4e1b-b227-0d521a9c47de
2020-04-16 00:19:59,899 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbe4d1665bbad81aa: from storage DS-cb483715-c48a-4bc5-9ca5-5b2d989b506e node DatanodeRegistration(127.0.0.1:44756, datanodeUuid=ba3b0511-ce87-4e1b-b227-0d521a9c47de, infoPort=42599, infoSecurePort=0, ipcPort=44311, storageInfo=lv=-57;cid=testClusterID;nsid=744571073;c=1586996392031), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-16 00:19:59,899 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x40d9c39af2b0321a: Processing first storage report for DS-9edb8b9c-574a-4693-88c4-605727136ba3 from datanode 17a857e8-15de-4f55-a2ee-0372c16121a7
2020-04-16 00:19:59,899 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x40d9c39af2b0321a: from storage DS-9edb8b9c-574a-4693-88c4-605727136ba3 node DatanodeRegistration(127.0.0.1:43534, datanodeUuid=17a857e8-15de-4f55-a2ee-0372c16121a7, infoPort=43577, infoSecurePort=0, ipcPort=44874, storageInfo=lv=-57;cid=testClusterID;nsid=744571073;c=1586996392031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:59,900 INFO  [Thread-125] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=744571073;bpid=BP-1147382952-172.17.0.3-1586996392031;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=744571073;c=1586996392031;bpid=BP-1147382952-172.17.0.3-1586996392031;dnuuid=null
2020-04-16 00:19:59,901 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbe4d1665bbad81aa: Processing first storage report for DS-455867be-60a3-42d4-9bff-7568de67679b from datanode ba3b0511-ce87-4e1b-b227-0d521a9c47de
2020-04-16 00:19:59,901 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbe4d1665bbad81aa: from storage DS-455867be-60a3-42d4-9bff-7568de67679b node DatanodeRegistration(127.0.0.1:44756, datanodeUuid=ba3b0511-ce87-4e1b-b227-0d521a9c47de, infoPort=42599, infoSecurePort=0, ipcPort=44311, storageInfo=lv=-57;cid=testClusterID;nsid=744571073;c=1586996392031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:59,924 INFO  [Thread-125] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID 6caa24a4-d3f4-4172-a4b0-1dd230126033
2020-04-16 00:19:59,929 INFO  [Thread-125] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d08c0a67-f16a-4291-a119-60c63a7531ce
2020-04-16 00:19:59,929 INFO  [Thread-125] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, StorageType: DISK
2020-04-16 00:19:59,931 INFO  [Thread-125] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d01ca016-b542-4e8b-b35e-0567e497fca4
2020-04-16 00:19:59,931 INFO  [Thread-125] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, StorageType: DISK
2020-04-16 00:19:59,932 INFO  [Thread-125] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:59,948 INFO  [Thread-125] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:59,955 INFO  [Thread-125] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:59,956 INFO  [Thread-125] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:59,956 INFO  [Thread-125] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:59,956 INFO  [Thread-125] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,968 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:19:59,970 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbe4d1665bbad81aa,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 71 msec to generate and 191 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:19:59,970 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:19:59,968 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:19:59,972 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x40d9c39af2b0321a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 32 msec to generate and 218 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:19:59,972 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:20:00,143 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1147382952-172.17.0.3-1586996392031 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 144ms
2020-04-16 00:20:00,190 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1147382952-172.17.0.3-1586996392031 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 222ms
2020-04-16 00:20:00,192 INFO  [Thread-125] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1147382952-172.17.0.3-1586996392031: 236ms
2020-04-16 00:20:00,218 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:20:00,218 INFO  [Thread-142] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1147382952-172.17.0.3-1586996392031/current/replicas doesn't exist 
2020-04-16 00:20:00,220 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:20:00,221 INFO  [Thread-143] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1147382952-172.17.0.3-1586996392031/current/replicas doesn't exist 
2020-04-16 00:20:00,221 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 3ms
2020-04-16 00:20:00,225 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 5ms
2020-04-16 00:20:00,229 INFO  [Thread-125] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1147382952-172.17.0.3-1586996392031: 37ms
2020-04-16 00:20:00,230 INFO  [Thread-125] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 4:19 AM with interval of 21600000ms
2020-04-16 00:20:00,230 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:20:00,237 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1147382952-172.17.0.3-1586996392031 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:20:00,238 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-d08c0a67-f16a-4291-a119-60c63a7531ce): finished scanning block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:20:00,239 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-d08c0a67-f16a-4291-a119-60c63a7531ce): no suitable block pools found to scan.  Waiting 1814399990 ms.
2020-04-16 00:20:00,240 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid 6caa24a4-d3f4-4172-a4b0-1dd230126033) service to localhost/127.0.0.1:38719 beginning handshake with NN
2020-04-16 00:20:00,245 INFO  [IPC Server handler 5 on default port 38719] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37273, datanodeUuid=6caa24a4-d3f4-4172-a4b0-1dd230126033, infoPort=33426, infoSecurePort=0, ipcPort=45719, storageInfo=lv=-57;cid=testClusterID;nsid=744571073;c=1586996392031) storage 6caa24a4-d3f4-4172-a4b0-1dd230126033
2020-04-16 00:20:00,254 INFO  [IPC Server handler 5 on default port 38719] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37273
2020-04-16 00:20:00,255 INFO  [IPC Server handler 5 on default port 38719] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6caa24a4-d3f4-4172-a4b0-1dd230126033 (127.0.0.1:37273).
2020-04-16 00:20:00,255 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-d01ca016-b542-4e8b-b35e-0567e497fca4): finished scanning block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:20:00,256 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-d01ca016-b542-4e8b-b35e-0567e497fca4): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-04-16 00:20:00,257 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid 6caa24a4-d3f4-4172-a4b0-1dd230126033) service to localhost/127.0.0.1:38719 successfully registered with NN
2020-04-16 00:20:00,257 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38719 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:20:00,271 INFO  [IPC Server handler 0 on default port 38719] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d08c0a67-f16a-4291-a119-60c63a7531ce for DN 127.0.0.1:37273
2020-04-16 00:20:00,271 INFO  [IPC Server handler 0 on default port 38719] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d01ca016-b542-4e8b-b35e-0567e497fca4 for DN 127.0.0.1:37273
2020-04-16 00:20:00,302 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6964eb80eedb0b35: Processing first storage report for DS-d01ca016-b542-4e8b-b35e-0567e497fca4 from datanode 6caa24a4-d3f4-4172-a4b0-1dd230126033
2020-04-16 00:20:00,302 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6964eb80eedb0b35: from storage DS-d01ca016-b542-4e8b-b35e-0567e497fca4 node DatanodeRegistration(127.0.0.1:37273, datanodeUuid=6caa24a4-d3f4-4172-a4b0-1dd230126033, infoPort=33426, infoSecurePort=0, ipcPort=45719, storageInfo=lv=-57;cid=testClusterID;nsid=744571073;c=1586996392031), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:20:00,305 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6964eb80eedb0b35: Processing first storage report for DS-d08c0a67-f16a-4291-a119-60c63a7531ce from datanode 6caa24a4-d3f4-4172-a4b0-1dd230126033
2020-04-16 00:20:00,305 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6964eb80eedb0b35: from storage DS-d08c0a67-f16a-4291-a119-60c63a7531ce node DatanodeRegistration(127.0.0.1:37273, datanodeUuid=6caa24a4-d3f4-4172-a4b0-1dd230126033, infoPort=33426, infoSecurePort=0, ipcPort=45719, storageInfo=lv=-57;cid=testClusterID;nsid=744571073;c=1586996392031), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:20:00,321 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6964eb80eedb0b35,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 34 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:20:00,321 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:20:00,814 INFO  [IPC Server handler 7 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-16 00:20:00,831 INFO  [Listener at localhost/45719] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-04-16 00:20:00,863 INFO  [IPC Server handler 8 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive	dst=null	perm=null	proto=rpc
2020-04-16 00:20:00,877 INFO  [IPC Server handler 9 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:00,908 INFO  [IPC Server handler 5 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/input	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:20:00,997 INFO  [IPC Server handler 0 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/a	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:01,093 INFO  [IPC Server handler 1 on default port 38719] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:43534, 127.0.0.1:44756, 127.0.0.1:37273 for /user/root/input/a
2020-04-16 00:20:01,116 INFO  [Thread-150] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:01,259 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38356 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001 src: /127.0.0.1:38356 dest: /127.0.0.1:43534
2020-04-16 00:20:01,289 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38356 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:01,314 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:37932 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001 src: /127.0.0.1:37932 dest: /127.0.0.1:44756
2020-04-16 00:20:01,319 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:37932 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:01,330 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33586 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001 src: /127.0.0.1:33586 dest: /127.0.0.1:37273
2020-04-16 00:20:01,430 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33586, dest: /127.0.0.1:37273, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 6caa24a4-d3f4-4172-a4b0-1dd230126033, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, duration(ns): 56457187
2020-04-16 00:20:01,438 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:01,444 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37273]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37932, dest: /127.0.0.1:44756, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: ba3b0511-ce87-4e1b-b227-0d521a9c47de, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, duration(ns): 76079335
2020-04-16 00:20:01,445 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37273]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37273] terminating
2020-04-16 00:20:01,450 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44756, 127.0.0.1:37273]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38356, dest: /127.0.0.1:43534, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 17a857e8-15de-4f55-a2ee-0372c16121a7, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, duration(ns): 81321770
2020-04-16 00:20:01,451 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44756, 127.0.0.1:37273]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44756, 127.0.0.1:37273] terminating
2020-04-16 00:20:01,488 INFO  [IPC Server handler 3 on default port 38719] namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/input/a
2020-04-16 00:20:01,929 INFO  [IPC Server handler 5 on default port 38719] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/a is closed by DFSClient_NONMAPREDUCE_-1298265553_1
2020-04-16 00:20:01,935 INFO  [IPC Server handler 0 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/b	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:01,943 INFO  [IPC Server handler 1 on default port 38719] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:37273, 127.0.0.1:44756, 127.0.0.1:43534 for /user/root/input/b
2020-04-16 00:20:01,946 INFO  [Thread-159] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:01,963 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33598 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002 src: /127.0.0.1:33598 dest: /127.0.0.1:37273
2020-04-16 00:20:01,965 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33598 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:01,970 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:37954 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002 src: /127.0.0.1:37954 dest: /127.0.0.1:44756
2020-04-16 00:20:01,972 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:37954 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:01,982 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38382 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002 src: /127.0.0.1:38382 dest: /127.0.0.1:43534
2020-04-16 00:20:02,070 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38382, dest: /127.0.0.1:43534, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 17a857e8-15de-4f55-a2ee-0372c16121a7, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, duration(ns): 82852044
2020-04-16 00:20:02,070 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:02,086 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43534]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37954, dest: /127.0.0.1:44756, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: ba3b0511-ce87-4e1b-b227-0d521a9c47de, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, duration(ns): 90389148
2020-04-16 00:20:02,087 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43534]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43534] terminating
2020-04-16 00:20:02,107 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44756, 127.0.0.1:43534]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33598, dest: /127.0.0.1:37273, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 6caa24a4-d3f4-4172-a4b0-1dd230126033, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, duration(ns): 99391417
2020-04-16 00:20:02,107 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44756, 127.0.0.1:43534]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44756, 127.0.0.1:43534] terminating
2020-04-16 00:20:02,127 INFO  [IPC Server handler 4 on default port 38719] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/b is closed by DFSClient_NONMAPREDUCE_-1298265553_1
2020-04-16 00:20:02,147 INFO  [IPC Server handler 3 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/c	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:02,163 INFO  [IPC Server handler 8 on default port 38719] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:43534, 127.0.0.1:37273, 127.0.0.1:44756 for /user/root/input/c
2020-04-16 00:20:02,174 INFO  [Thread-167] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,184 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38392 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003 src: /127.0.0.1:38392 dest: /127.0.0.1:43534
2020-04-16 00:20:02,185 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38392 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,205 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33620 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003 src: /127.0.0.1:33620 dest: /127.0.0.1:37273
2020-04-16 00:20:02,207 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33620 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,224 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:37972 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003 src: /127.0.0.1:37972 dest: /127.0.0.1:44756
2020-04-16 00:20:02,285 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37972, dest: /127.0.0.1:44756, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: ba3b0511-ce87-4e1b-b227-0d521a9c47de, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, duration(ns): 47328040
2020-04-16 00:20:02,290 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:02,306 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44756]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33620, dest: /127.0.0.1:37273, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 6caa24a4-d3f4-4172-a4b0-1dd230126033, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, duration(ns): 73119857
2020-04-16 00:20:02,307 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44756]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44756] terminating
2020-04-16 00:20:02,318 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:44756]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38392, dest: /127.0.0.1:43534, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 17a857e8-15de-4f55-a2ee-0372c16121a7, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, duration(ns): 84315717
2020-04-16 00:20:02,318 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:44756]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:44756] terminating
2020-04-16 00:20:02,342 INFO  [IPC Server handler 1 on default port 38719] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/c is closed by DFSClient_NONMAPREDUCE_-1298265553_1
2020-04-16 00:20:02,359 INFO  [IPC Server handler 2 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/input/dir1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:20:02,366 INFO  [IPC Server handler 6 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/dir1/a	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:02,406 INFO  [IPC Server handler 7 on default port 38719] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:44756, 127.0.0.1:37273, 127.0.0.1:43534 for /user/root/input/dir1/a
2020-04-16 00:20:02,409 INFO  [Thread-175] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,435 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:37984 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004 src: /127.0.0.1:37984 dest: /127.0.0.1:44756
2020-04-16 00:20:02,437 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:37984 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,482 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33638 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004 src: /127.0.0.1:33638 dest: /127.0.0.1:37273
2020-04-16 00:20:02,483 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33638 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:02,490 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38414 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004 src: /127.0.0.1:38414 dest: /127.0.0.1:43534
2020-04-16 00:20:02,560 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38414, dest: /127.0.0.1:43534, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 17a857e8-15de-4f55-a2ee-0372c16121a7, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, duration(ns): 67643595
2020-04-16 00:20:02,560 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:02,568 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43534]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33638, dest: /127.0.0.1:37273, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 6caa24a4-d3f4-4172-a4b0-1dd230126033, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, duration(ns): 50140833
2020-04-16 00:20:02,569 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43534]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43534] terminating
2020-04-16 00:20:02,591 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:43534]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37984, dest: /127.0.0.1:44756, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: ba3b0511-ce87-4e1b-b227-0d521a9c47de, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, duration(ns): 62286137
2020-04-16 00:20:02,592 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:43534]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:43534] terminating
2020-04-16 00:20:02,598 INFO  [IPC Server handler 1 on default port 38719] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/dir1/a is closed by DFSClient_NONMAPREDUCE_-1298265553_1
lsr root=input
2020-04-16 00:20:02,716 INFO  [IPC Server handler 2 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,731 INFO  [IPC Server handler 6 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,744 INFO  [IPC Server handler 7 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
lsr results:
lsr: DEPRECATED: Please use 'ls -R' instead.
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 input/a
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 input/b
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 input/c
drwxr-xr-x   - root supergroup          0 2020-04-16 00:20 input/dir1
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 input/dir1/a

lsr paths = [/a,
  /b,
  /c,
  /dir1,
  /dir1/a]
originalPaths: [/a, /b, /c, /dir1, /dir1/a]
parentPathStr = /user/root/input
2020-04-16 00:20:02,764 INFO  [IPC Server handler 4 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,777 INFO  [IPC Server handler 3 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,783 INFO  [IPC Server handler 8 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,790 INFO  [IPC Server handler 9 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,796 INFO  [IPC Server handler 5 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,807 INFO  [IPC Server handler 0 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,809 INFO  [IPC Server handler 1 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,826 INFO  [Listener at localhost/45719] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:02,882 INFO  [IPC Server handler 2 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,889 INFO  [IPC Server handler 6 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,895 INFO  [IPC Server handler 7 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,902 INFO  [IPC Server handler 4 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,906 INFO  [IPC Server handler 3 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:02,942 INFO  [Listener at localhost/45719] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:02,952 INFO  [Listener at localhost/45719] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:03,003 INFO  [Listener at localhost/45719] mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:1
2020-04-16 00:20:03,230 INFO  [Listener at localhost/45719] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1035220135_0001
2020-04-16 00:20:03,231 INFO  [Listener at localhost/45719] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2020-04-16 00:20:03,513 INFO  [Listener at localhost/45719] mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2020-04-16 00:20:03,515 INFO  [Listener at localhost/45719] mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1035220135_0001
2020-04-16 00:20:03,543 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2020-04-16 00:20:03,545 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2020-04-16 00:20:03,579 INFO  [Thread-183] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:20:03,580 INFO  [Thread-183] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:20:03,606 INFO  [IPC Server handler 9 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/archive/foo.har/_temporary/0	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:20:03,670 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2020-04-16 00:20:03,674 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1035220135_0001_m_000000_0
2020-04-16 00:20:03,708 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:20:03,709 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:20:03,760 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2020-04-16 00:20:03,762 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:updateJobWithSplit(497)) - Processing split: file:/tmp/hadoop/mapred/staging/root1372943404/.staging/har_8ntacn/_har_src_files:0+376
2020-04-16 00:20:03,783 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:runOldMapper(451)) - numReduceTasks: 1
2020-04-16 00:20:03,901 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:setEquator(1219)) - (EQUATOR) 0 kvi 26214396(104857584)
2020-04-16 00:20:03,902 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1012)) - mapreduce.task.io.sort.mb: 100
2020-04-16 00:20:03,902 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1013)) - soft limit at 83886080
2020-04-16 00:20:03,902 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1014)) - bufstart = 0; bufvoid = 104857600
2020-04-16 00:20:03,902 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1015)) - kvstart = 26214396; length = 6553600
2020-04-16 00:20:03,909 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:createSortingCollector(409)) - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-04-16 00:20:03,915 INFO  [IPC Server handler 8 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_m_000000_0/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:03,920 INFO  [IPC Server handler 9 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_m_000000_0/part-0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:03,934 INFO  [IPC Server handler 5 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:03,942 INFO  [IPC Server handler 0 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:03,956 INFO  [IPC Server handler 1 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:03,999 INFO  [LocalJobRunner Map Task Executor #0] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,058 INFO  [IPC Server handler 2 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,064 INFO  [IPC Server handler 6 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,074 INFO  [IPC Server handler 7 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,077 INFO  [IPC Server handler 4 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,080 INFO  [LocalJobRunner Map Task Executor #0] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,094 INFO  [IPC Server handler 3 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,101 INFO  [IPC Server handler 8 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,103 INFO  [IPC Server handler 9 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/dir1/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,119 INFO  [IPC Server handler 5 on default port 38719] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:44756, 127.0.0.1:37273, 127.0.0.1:43534 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_m_000000_0/part-0
2020-04-16 00:20:04,121 INFO  [Thread-187] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,125 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38098 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005 src: /127.0.0.1:38098 dest: /127.0.0.1:44756
2020-04-16 00:20:04,126 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38098 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,134 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33752 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005 src: /127.0.0.1:33752 dest: /127.0.0.1:37273
2020-04-16 00:20:04,136 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33752 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,138 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38528 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005 src: /127.0.0.1:38528 dest: /127.0.0.1:43534
2020-04-16 00:20:04,173 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38528, dest: /127.0.0.1:43534, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 17a857e8-15de-4f55-a2ee-0372c16121a7, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, duration(ns): 15219480
2020-04-16 00:20:04,174 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:04,175 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43534]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33752, dest: /127.0.0.1:37273, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 6caa24a4-d3f4-4172-a4b0-1dd230126033, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, duration(ns): 28937890
2020-04-16 00:20:04,175 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43534]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43534] terminating
2020-04-16 00:20:04,197 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:43534]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38098, dest: /127.0.0.1:44756, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: ba3b0511-ce87-4e1b-b227-0d521a9c47de, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, duration(ns): 27347824
2020-04-16 00:20:04,198 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:43534]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:43534] terminating
2020-04-16 00:20:04,222 INFO  [IPC Server handler 6 on default port 38719] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_m_000000_0/part-0 is closed by DFSClient_NONMAPREDUCE_-1298265553_1
2020-04-16 00:20:04,245 INFO  [IPC Server handler 7 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_m_000000_0/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,269 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2020-04-16 00:20:04,269 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1476)) - Starting flush of map output
2020-04-16 00:20:04,269 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1498)) - Spilling map output
2020-04-16 00:20:04,269 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1499)) - bufstart = 0; bufend = 366; bufvoid = 104857600
2020-04-16 00:20:04,269 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1501)) - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2020-04-16 00:20:04,277 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:sortAndSpill(1696)) - Finished spill 0
2020-04-16 00:20:04,296 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:done(1244)) - Task:attempt_local1035220135_0001_m_000000_0 is done. And is in the process of committing
2020-04-16 00:20:04,298 INFO  [IPC Server handler 4 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,300 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2020-04-16 00:20:04,301 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:commit(1421)) - Task attempt_local1035220135_0001_m_000000_0 is allowed to commit now
2020-04-16 00:20:04,305 INFO  [IPC Server handler 3 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,308 INFO  [IPC Server handler 8 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,317 INFO  [IPC Server handler 9 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,328 INFO  [IPC Server handler 5 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,367 INFO  [IPC Server handler 0 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_m_000000_0/part-0	dst=/user/root/archive/foo.har/part-0	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:04,377 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:commitTask(606)) - Saved output of task 'attempt_local1035220135_0001_m_000000_0' to hdfs://localhost:38719/user/root/archive/foo.har
2020-04-16 00:20:04,382 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file hdfs://localhost:38719/user/root/input/dir1/a to archive.
2020-04-16 00:20:04,383 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1035220135_0001_m_000000_0' done.
2020-04-16 00:20:04,385 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1035220135_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=62563
		FILE: Number of bytes written=590337
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4
		HDFS: Number of bytes written=8
		HDFS: Number of read operations=30
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=13
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=366
		Map output materialized bytes=384
		Input split bytes=133
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1906311168
	File Input Format Counters 
		Bytes Read=388
2020-04-16 00:20:04,386 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1035220135_0001_m_000000_0
2020-04-16 00:20:04,390 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2020-04-16 00:20:04,405 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for reduce tasks
2020-04-16 00:20:04,411 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:run(330)) - Starting task: attempt_local1035220135_0001_r_000000_0
2020-04-16 00:20:04,426 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:20:04,426 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:20:04,427 INFO  [pool-49-thread-1] mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2020-04-16 00:20:04,432 INFO  [pool-49-thread-1] mapred.ReduceTask (ReduceTask.java:run(363)) - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3125847a
2020-04-16 00:20:04,433 INFO  [pool-49-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:04,456 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:<init>(208)) - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-04-16 00:20:04,465 INFO  [EventFetcher for fetching Map Completion Events] reduce.EventFetcher (EventFetcher.java:run(61)) - attempt_local1035220135_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-04-16 00:20:04,516 INFO  [localfetcher#1] reduce.LocalFetcher (LocalFetcher.java:copyMapOutput(145)) - localfetcher#1 about to shuffle output of map attempt_local1035220135_0001_m_000000_0 decomp: 380 len: 384 to MEMORY
2020-04-16 00:20:04,721 INFO  [Listener at localhost/45719] mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1035220135_0001 running in uber mode : false
2020-04-16 00:20:04,722 INFO  [Listener at localhost/45719] mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2020-04-16 00:20:04,735 INFO  [localfetcher#1] reduce.InMemoryMapOutput (InMemoryMapOutput.java:doShuffle(94)) - Read 380 bytes from map-output for attempt_local1035220135_0001_m_000000_0
2020-04-16 00:20:04,737 WARN  [Readahead Thread #0] io.ReadaheadPool (ReadaheadPool.java:run(218)) - Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:271)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:148)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:209)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-16 00:20:04,736 INFO  [localfetcher#1] reduce.MergeManagerImpl (MergeManagerImpl.java:closeInMemoryFile(323)) - closeInMemoryFile -> map-output of size: 380, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->380
2020-04-16 00:20:04,744 INFO  [EventFetcher for fetching Map Completion Events] reduce.EventFetcher (EventFetcher.java:run(76)) - EventFetcher is interrupted.. Returning
2020-04-16 00:20:04,755 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:20:04,755 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(695)) - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-04-16 00:20:04,777 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(606)) - Merging 1 sorted segments
2020-04-16 00:20:04,779 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(705)) - Down to the last merge-pass, with 1 segments left of total size: 374 bytes
2020-04-16 00:20:04,783 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(762)) - Merged 1 segments, 380 bytes to disk to satisfy reduce memory limit
2020-04-16 00:20:04,784 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(792)) - Merging 1 files, 384 bytes from disk
2020-04-16 00:20:04,785 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(807)) - Merging 0 segments, 0 bytes from memory into reduce
2020-04-16 00:20:04,785 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(606)) - Merging 1 sorted segments
2020-04-16 00:20:04,786 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(705)) - Down to the last merge-pass, with 1 segments left of total size: 374 bytes
2020-04-16 00:20:04,786 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:20:04,797 INFO  [IPC Server handler 1 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,801 INFO  [IPC Server handler 2 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:04,804 INFO  [IPC Server handler 6 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_index	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:04,819 INFO  [IPC Server handler 7 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_masterindex	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:04,832 INFO  [IPC Server handler 4 on default port 38719] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:43534, 127.0.0.1:37273, 127.0.0.1:44756 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_masterindex
2020-04-16 00:20:04,838 INFO  [Thread-204] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,841 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38566 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006 src: /127.0.0.1:38566 dest: /127.0.0.1:43534
2020-04-16 00:20:04,842 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38566 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,846 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33794 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006 src: /127.0.0.1:33794 dest: /127.0.0.1:37273
2020-04-16 00:20:04,873 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33794 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,877 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38144 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006 src: /127.0.0.1:38144 dest: /127.0.0.1:44756
2020-04-16 00:20:04,921 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38144, dest: /127.0.0.1:44756, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: ba3b0511-ce87-4e1b-b227-0d521a9c47de, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, duration(ns): 38964156
2020-04-16 00:20:04,922 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:04,924 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44756]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33794, dest: /127.0.0.1:37273, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 6caa24a4-d3f4-4172-a4b0-1dd230126033, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, duration(ns): 38366671
2020-04-16 00:20:04,925 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44756]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44756] terminating
2020-04-16 00:20:04,941 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:44756]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38566, dest: /127.0.0.1:43534, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 17a857e8-15de-4f55-a2ee-0372c16121a7, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, duration(ns): 40091391
2020-04-16 00:20:04,942 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:44756]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37273, 127.0.0.1:44756] terminating
2020-04-16 00:20:04,954 INFO  [IPC Server handler 5 on default port 38719] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_masterindex is closed by DFSClient_NONMAPREDUCE_-1298265553_1
2020-04-16 00:20:04,970 INFO  [IPC Server handler 0 on default port 38719] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:43534, 127.0.0.1:44756, 127.0.0.1:37273 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_index
2020-04-16 00:20:04,974 INFO  [Thread-203] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,982 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38584 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007 src: /127.0.0.1:38584 dest: /127.0.0.1:43534
2020-04-16 00:20:04,984 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38584 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,986 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38160 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007 src: /127.0.0.1:38160 dest: /127.0.0.1:44756
2020-04-16 00:20:04,987 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:38160 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,988 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1298265553_1 at /127.0.0.1:33814 [Receiving block BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007 src: /127.0.0.1:33814 dest: /127.0.0.1:37273
2020-04-16 00:20:05,022 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33814, dest: /127.0.0.1:37273, bytes: 342, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 6caa24a4-d3f4-4172-a4b0-1dd230126033, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, duration(ns): 32344751
2020-04-16 00:20:05,023 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:05,029 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37273]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38160, dest: /127.0.0.1:44756, bytes: 342, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: ba3b0511-ce87-4e1b-b227-0d521a9c47de, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, duration(ns): 34712654
2020-04-16 00:20:05,029 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37273]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37273] terminating
2020-04-16 00:20:05,030 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44756, 127.0.0.1:37273]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38584, dest: /127.0.0.1:43534, bytes: 342, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1298265553_1, offset: 0, srvID: 17a857e8-15de-4f55-a2ee-0372c16121a7, blockid: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, duration(ns): 40955031
2020-04-16 00:20:05,031 INFO  [PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44756, 127.0.0.1:37273]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1147382952-172.17.0.3-1586996392031:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44756, 127.0.0.1:37273] terminating
2020-04-16 00:20:05,042 INFO  [IPC Server handler 7 on default port 38719] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_index is closed by DFSClient_NONMAPREDUCE_-1298265553_1
2020-04-16 00:20:05,049 INFO  [IPC Server handler 4 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,053 INFO  [IPC Server handler 8 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,055 INFO  [pool-49-thread-1] mapred.Task (Task.java:done(1244)) - Task:attempt_local1035220135_0001_r_000000_0 is done. And is in the process of committing
2020-04-16 00:20:05,061 INFO  [IPC Server handler 3 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,063 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:20:05,063 INFO  [pool-49-thread-1] mapred.Task (Task.java:commit(1421)) - Task attempt_local1035220135_0001_r_000000_0 is allowed to commit now
2020-04-16 00:20:05,066 INFO  [IPC Server handler 9 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,082 INFO  [IPC Server handler 5 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,086 INFO  [IPC Server handler 0 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,089 INFO  [IPC Server handler 1 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,098 INFO  [IPC Server handler 2 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_index	dst=/user/root/archive/foo.har/_index	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:05,099 INFO  [IPC Server handler 6 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,101 INFO  [IPC Server handler 7 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1035220135_0001_r_000000_0/_masterindex	dst=/user/root/archive/foo.har/_masterindex	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:05,102 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:commitTask(606)) - Saved output of task 'attempt_local1035220135_0001_r_000000_0' to hdfs://localhost:38719/user/root/archive/foo.har
2020-04-16 00:20:05,103 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - reduce > reduce
2020-04-16 00:20:05,103 INFO  [pool-49-thread-1] mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1035220135_0001_r_000000_0' done.
2020-04-16 00:20:05,104 INFO  [pool-49-thread-1] mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1035220135_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=63363
		FILE: Number of bytes written=590721
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4
		HDFS: Number of bytes written=373
		HDFS: Number of read operations=36
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=21
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=384
		Reduce input records=6
		Reduce output records=0
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=193
		Total committed heap usage (bytes)=1906311168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2020-04-16 00:20:05,105 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:run(353)) - Finishing task: attempt_local1035220135_0001_r_000000_0
2020-04-16 00:20:05,105 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - reduce task executor complete.
2020-04-16 00:20:05,128 INFO  [IPC Server handler 4 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,131 INFO  [IPC Server handler 8 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_SUCCESS	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:05,147 INFO  [IPC Server handler 3 on default port 38719] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1298265553_1
2020-04-16 00:20:05,723 INFO  [Listener at localhost/45719] mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 100%
2020-04-16 00:20:05,724 INFO  [Listener at localhost/45719] mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1035220135_0001 completed successfully
2020-04-16 00:20:05,761 INFO  [Listener at localhost/45719] mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 36
	File System Counters
		FILE: Number of bytes read=125926
		FILE: Number of bytes written=1181058
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=8
		HDFS: Number of bytes written=381
		HDFS: Number of read operations=66
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=34
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=366
		Map output materialized bytes=384
		Input split bytes=133
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=384
		Reduce input records=6
		Reduce output records=0
		Spilled Records=12
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=193
		Total committed heap usage (bytes)=3812622336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=388
	File Output Format Counters 
		Bytes Written=0
lsr root=har://hdfs-localhost:38719/user/root/archive/foo.har
2020-04-16 00:20:05,772 INFO  [IPC Server handler 0 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,779 INFO  [IPC Server handler 1 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,783 INFO  [IPC Server handler 2 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,787 INFO  [IPC Server handler 6 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,792 INFO  [Listener at localhost/45719] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:05,798 INFO  [IPC Server handler 7 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,809 INFO  [IPC Server handler 4 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,820 INFO  [IPC Server handler 8 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,832 INFO  [IPC Server handler 3 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,848 INFO  [IPC Server handler 9 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,854 INFO  [IPC Server handler 5 on default port 38719] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
lsr results:
lsr: DEPRECATED: Please use 'ls -R' instead.
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 har://hdfs-localhost:38719/user/root/archive/foo.har/a
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 har://hdfs-localhost:38719/user/root/archive/foo.har/b
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 har://hdfs-localhost:38719/user/root/archive/foo.har/c
drwxr-xr-x   - root supergroup          0 2020-04-16 00:20 har://hdfs-localhost:38719/user/root/archive/foo.har/dir1
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 har://hdfs-localhost:38719/user/root/archive/foo.har/dir1/a

lsr paths = [/a,
  /b,
  /c,
  /dir1,
  /dir1/a]
2020-04-16 00:20:05,855 INFO  [Listener at localhost/45719] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-04-16 00:20:05,856 INFO  [Listener at localhost/45719] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-04-16 00:20:05,856 INFO  [Listener at localhost/45719] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:20:05,857 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4565a70a] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:20:05,858 WARN  [Listener at localhost/45719] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:20:05,861 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-d08c0a67-f16a-4291-a119-60c63a7531ce) exiting.
2020-04-16 00:20:05,865 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-d01ca016-b542-4e8b-b35e-0567e497fca4) exiting.
2020-04-16 00:20:05,962 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@17ae7628{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:20:05,972 INFO  [Listener at localhost/45719] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1136b469{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:05,973 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d7e1102{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:05,973 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@466d49f0{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:20:05,991 INFO  [Listener at localhost/45719] ipc.Server (Server.java:stop(3359)) - Stopping server on 45719
2020-04-16 00:20:06,012 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:06,013 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:06,015 WARN  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:20:06,015 WARN  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid 6caa24a4-d3f4-4172-a4b0-1dd230126033) service to localhost/127.0.0.1:38719
2020-04-16 00:20:06,015 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid 6caa24a4-d3f4-4172-a4b0-1dd230126033)
2020-04-16 00:20:06,015 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:20:06,017 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1147382952-172.17.0.3-1586996392031] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,017 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1147382952-172.17.0.3-1586996392031] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,021 INFO  [Listener at localhost/45719] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:20:06,021 INFO  [Listener at localhost/45719] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:20:06,022 INFO  [Listener at localhost/45719] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:20:06,022 INFO  [Listener at localhost/45719] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:20:06,037 INFO  [Listener at localhost/45719] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:20:06,037 INFO  [Listener at localhost/45719] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-04-16 00:20:06,038 INFO  [Listener at localhost/45719] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:20:06,039 WARN  [Listener at localhost/45719] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:20:06,045 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5bb8f9e2] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:20:06,052 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-cb483715-c48a-4bc5-9ca5-5b2d989b506e) exiting.
2020-04-16 00:20:06,053 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-455867be-60a3-42d4-9bff-7568de67679b) exiting.
2020-04-16 00:20:06,236 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58065f0c{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:20:06,239 INFO  [Listener at localhost/45719] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3605c4d3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:06,240 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@bcb09a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:06,240 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30feffc{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:20:06,249 INFO  [Listener at localhost/45719] ipc.Server (Server.java:stop(3359)) - Stopping server on 44311
2020-04-16 00:20:06,252 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:06,252 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:06,252 WARN  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:20:06,260 WARN  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid ba3b0511-ce87-4e1b-b227-0d521a9c47de) service to localhost/127.0.0.1:38719
2020-04-16 00:20:06,261 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid ba3b0511-ce87-4e1b-b227-0d521a9c47de)
2020-04-16 00:20:06,261 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:20:06,261 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1147382952-172.17.0.3-1586996392031] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,264 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1147382952-172.17.0.3-1586996392031] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,266 INFO  [Listener at localhost/45719] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:20:06,273 INFO  [Listener at localhost/45719] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:20:06,276 INFO  [Listener at localhost/45719] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:20:06,276 INFO  [Listener at localhost/45719] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:20:06,281 INFO  [Listener at localhost/45719] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:20:06,282 INFO  [Listener at localhost/45719] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-04-16 00:20:06,282 INFO  [Listener at localhost/45719] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:20:06,283 WARN  [Listener at localhost/45719] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:20:06,283 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6b5f8707] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:20:06,285 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-9edb8b9c-574a-4693-88c4-605727136ba3) exiting.
2020-04-16 00:20:06,285 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-bf3a0f32-d8b4-4f2c-b8ea-937d3aeab879) exiting.
2020-04-16 00:20:06,450 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1af1347d{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:20:06,452 INFO  [Listener at localhost/45719] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:06,453 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@282308c3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:06,453 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7726e185{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:20:06,456 INFO  [Listener at localhost/45719] ipc.Server (Server.java:stop(3359)) - Stopping server on 44874
2020-04-16 00:20:06,464 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:06,464 WARN  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:20:06,465 WARN  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid 17a857e8-15de-4f55-a2ee-0372c16121a7) service to localhost/127.0.0.1:38719
2020-04-16 00:20:06,497 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:06,574 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1147382952-172.17.0.3-1586996392031 (Datanode Uuid 17a857e8-15de-4f55-a2ee-0372c16121a7)
2020-04-16 00:20:06,574 INFO  [BP-1147382952-172.17.0.3-1586996392031 heartbeating to localhost/127.0.0.1:38719] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1147382952-172.17.0.3-1586996392031
2020-04-16 00:20:06,574 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1147382952-172.17.0.3-1586996392031] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,576 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1147382952-172.17.0.3-1586996392031] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:06,583 INFO  [Listener at localhost/45719] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:20:06,583 INFO  [Listener at localhost/45719] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:20:06,584 INFO  [Listener at localhost/45719] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:20:06,589 INFO  [Listener at localhost/45719] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:20:06,592 INFO  [Listener at localhost/45719] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:20:06,605 INFO  [Listener at localhost/45719] hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-04-16 00:20:06,605 INFO  [Listener at localhost/45719] namenode.NameNode (NameNode.java:stop(1013)) - msx-hdfs NameNode stop
2020-04-16 00:20:06,605 INFO  [Listener at localhost/45719] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:20:06,613 INFO  [Listener at localhost/45719] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 56
2020-04-16 00:20:06,614 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@73393584] namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-16 00:20:06,614 INFO  [Listener at localhost/45719] namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 57 Total time for transactions(ms): 54 Number of transactions batched in Syncs: 18 Number of syncs: 40 SyncTimes(ms): 5 4 
2020-04-16 00:20:06,616 INFO  [Listener at localhost/45719] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000057
2020-04-16 00:20:06,616 INFO  [Listener at localhost/45719] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000057
2020-04-16 00:20:06,619 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@70e659aa] namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-16 00:20:06,619 INFO  [FSEditLogAsync] namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-16 00:20:06,620 INFO  [Listener at localhost/45719] ipc.Server (Server.java:stop(3359)) - Stopping server on 38719
2020-04-16 00:20:06,621 INFO  [CacheReplicationMonitor(806121773)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-16 00:20:06,625 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:06,625 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:06,625 INFO  [RedundancyMonitor] blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-04-16 00:20:06,626 INFO  [StorageInfoMonitor] blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-04-16 00:20:06,691 INFO  [Listener at localhost/45719] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:20:06,691 INFO  [Listener at localhost/45719] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-04-16 00:20:06,698 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33fe57a9{/,null,UNAVAILABLE}{/hdfs}
2020-04-16 00:20:06,729 INFO  [Listener at localhost/45719] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:06,730 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:06,731 INFO  [Listener at localhost/45719] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
msx-listener testfinished org.apache.hadoop.tools.TestHadoopArchives#testRelativePath
msx-listener writeFile testName is org.apache.hadoop.tools.TestHadoopArchives#testRelativePath
msx-listener succeed
msx-listener all testRunFinished
