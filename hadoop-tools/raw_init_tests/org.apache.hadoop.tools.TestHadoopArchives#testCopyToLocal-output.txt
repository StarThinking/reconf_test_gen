msx-listener test started org.apache.hadoop.tools.TestHadoopArchives#testCopyToLocal
msx-listener unitTestCounterInClass = 0
2020-04-16 00:19:40,011 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-16 00:19:40,897 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:40,921 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:40,924 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:40,925 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:40,967 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:40,968 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:40,968 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:40,969 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:41,068 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:41,075 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-16 00:19:41,076 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:41,076 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:41,083 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:41,084 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:41
2020-04-16 00:19:41,087 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:41,089 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:41,092 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-16 00:19:41,093 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:41,126 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:41,127 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:41,139 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:41,140 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:41,140 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:41,140 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:41,142 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:41,142 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:41,142 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:41,143 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:41,143 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:41,143 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:41,144 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:41,191 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-04-16 00:19:41,192 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:41,192 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:41,192 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:41,214 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:41,214 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:41,215 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-16 00:19:41,215 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:41,224 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:41,225 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:41,225 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:41,226 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:41,235 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:41,238 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:41,246 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:41,247 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:41,248 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-16 00:19:41,248 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:41,267 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:41,268 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:41,269 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:41,275 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:41,275 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:41,282 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:41,283 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:41,284 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-16 00:19:41,285 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:41,329 INFO  [main] namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:41,349 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 has been successfully formatted.
2020-04-16 00:19:41,352 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 has been successfully formatted.
2020-04-16 00:19:41,404 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:41,409 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:41,579 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:41,581 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:41,621 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-16 00:19:41,627 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1635)) - createNameNode []
2020-04-16 00:19:41,711 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-04-16 00:19:42,560 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-04-16 00:19:42,560 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-16 00:19:42,589 INFO  [main] namenode.NameNode (NameNode.java:<init>(932)) - msx-hdfs NameNode init
2020-04-16 00:19:42,620 INFO  [main] namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-16 00:19:42,698 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2205a05d] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:42,723 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-16 00:19:42,747 INFO  [main] util.log (Log.java:initialized(192)) - Logging initialized @4484ms
2020-04-16 00:19:42,940 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:42,946 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-16 00:19:42,965 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:42,969 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-16 00:19:42,970 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:42,971 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:43,010 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-16 00:19:43,010 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-16 00:19:43,030 INFO  [main] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36467
2020-04-16 00:19:43,033 INFO  [main] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:43,106 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:43,113 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:43,498 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33fe57a9{/,file:///tmp/jetty-localhost-36467-hdfs-_-any-7158983062274064938.dir/webapp/,AVAILABLE}{/hdfs}
2020-04-16 00:19:43,513 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:36467}
2020-04-16 00:19:43,514 INFO  [main] server.Server (Server.java:doStart(419)) - Started @5251ms
2020-04-16 00:19:43,530 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:43,531 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:43,532 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:43,532 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:43,532 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:43,533 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:43,533 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:43,533 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:43,534 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:43,535 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:43,535 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:43,535 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:43,536 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:43
2020-04-16 00:19:43,536 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:43,536 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:43,536 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-16 00:19:43,537 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:43,549 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:43,549 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:43,550 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:43,550 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:43,550 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:43,551 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:43,551 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:43,551 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:43,552 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:43,552 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:43,552 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:43,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:43,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:43,555 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:43,555 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:43,556 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-16 00:19:43,569 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:43,577 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:43,577 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:43,578 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:43,578 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:43,578 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:43,578 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:43,579 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:43,579 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:43,579 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-16 00:19:43,579 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:43,582 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:43,583 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:43,583 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:43,583 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:43,583 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:43,584 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:43,584 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:43,584 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-16 00:19:43,584 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:43,610 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/in_use.lock acquired by nodename 4791@afac0abd37ee
2020-04-16 00:19:43,616 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/in_use.lock acquired by nodename 4791@afac0abd37ee
2020-04-16 00:19:43,620 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current
2020-04-16 00:19:43,621 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current
2020-04-16 00:19:43,622 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-04-16 00:19:43,622 INFO  [main] namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-16 00:19:43,676 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-04-16 00:19:43,686 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-04-16 00:19:43,687 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-16 00:19:43,693 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-16 00:19:43,694 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-04-16 00:19:43,731 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-16 00:19:43,731 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 143 msecs
2020-04-16 00:19:43,975 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-04-16 00:19:44,009 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:44,025 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:44,366 INFO  [Listener at localhost/36787] namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:36787 to access this namenode/service.
2020-04-16 00:19:44,382 INFO  [Listener at localhost/36787] namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-16 00:19:44,484 INFO  [Listener at localhost/36787] namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-16 00:19:44,532 INFO  [Listener at localhost/36787] blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-04-16 00:19:44,533 INFO  [Listener at localhost/36787] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-04-16 00:19:44,543 INFO  [Listener at localhost/36787] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-16 00:19:44,547 INFO  [Listener at localhost/36787] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-16 00:19:44,553 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-04-16 00:19:44,553 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-04-16 00:19:44,553 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-04-16 00:19:44,585 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-04-16 00:19:44,585 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-04-16 00:19:44,585 INFO  [Reconstruction Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 44 msec
2020-04-16 00:19:44,595 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:44,603 INFO  [Listener at localhost/36787] namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:36787
2020-04-16 00:19:44,597 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:44,613 INFO  [Listener at localhost/36787] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-04-16 00:19:44,613 INFO  [Listener at localhost/36787] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-04-16 00:19:44,623 INFO  [Listener at localhost/36787] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 9 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-16 00:19:44,639 INFO  [Listener at localhost/36787] namenode.NameNode (NameNode.java:<init>(969)) - msx-hdfs NameNode start
2020-04-16 00:19:44,649 INFO  [CacheReplicationMonitor(1965723639)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-16 00:19:44,683 INFO  [Listener at localhost/36787] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:44,794 INFO  [Listener at localhost/36787] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:44,813 INFO  [Listener at localhost/36787] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:44,863 INFO  [Listener at localhost/36787] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:44,864 INFO  [Listener at localhost/36787] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:44,884 INFO  [Listener at localhost/36787] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:44,899 INFO  [Listener at localhost/36787] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:44,907 INFO  [Listener at localhost/36787] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:44,909 INFO  [Listener at localhost/36787] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:44,925 INFO  [Listener at localhost/36787] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:44,935 INFO  [Listener at localhost/36787] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:45154
2020-04-16 00:19:44,940 INFO  [Listener at localhost/36787] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:44,940 INFO  [Listener at localhost/36787] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:45,003 INFO  [Listener at localhost/36787] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:45,013 INFO  [Listener at localhost/36787] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:45,019 INFO  [Listener at localhost/36787] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:45,021 INFO  [Listener at localhost/36787] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:45,029 INFO  [Listener at localhost/36787] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:45,029 INFO  [Listener at localhost/36787] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:45,036 INFO  [Listener at localhost/36787] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33788
2020-04-16 00:19:45,036 INFO  [Listener at localhost/36787] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:45,063 INFO  [Listener at localhost/36787] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7726e185{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:45,084 INFO  [Listener at localhost/36787] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@282308c3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:45,334 INFO  [Listener at localhost/36787] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1af1347d{/,file:///tmp/jetty-localhost-33788-datanode-_-any-8155975119987601110.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:45,345 INFO  [Listener at localhost/36787] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:33788}
2020-04-16 00:19:45,346 INFO  [Listener at localhost/36787] server.Server (Server.java:doStart(419)) - Started @7083ms
2020-04-16 00:19:46,580 INFO  [Listener at localhost/36787] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33017
2020-04-16 00:19:46,585 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61f2c3f0] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:46,588 INFO  [Listener at localhost/36787] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:46,588 INFO  [Listener at localhost/36787] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:46,608 INFO  [Listener at localhost/36787] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:46,609 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:46,662 INFO  [Listener at localhost/39347] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:39347
2020-04-16 00:19:46,704 INFO  [Listener at localhost/39347] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:46,705 INFO  [Listener at localhost/39347] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:46,765 INFO  [Listener at localhost/39347] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:46,757 INFO  [Thread-58] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36787 starting to offer service
2020-04-16 00:19:46,777 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:46,777 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:46,787 INFO  [Listener at localhost/39347] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:46,790 INFO  [Listener at localhost/39347] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:46,793 INFO  [Listener at localhost/39347] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:46,825 INFO  [Listener at localhost/39347] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:46,825 INFO  [Listener at localhost/39347] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:46,826 INFO  [Listener at localhost/39347] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:46,826 INFO  [Listener at localhost/39347] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:46,827 INFO  [Listener at localhost/39347] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:46,827 INFO  [Listener at localhost/39347] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:46,827 INFO  [Listener at localhost/39347] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:46,828 INFO  [Listener at localhost/39347] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:37638
2020-04-16 00:19:46,849 INFO  [Listener at localhost/39347] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:46,849 INFO  [Listener at localhost/39347] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:46,855 INFO  [Listener at localhost/39347] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:46,856 INFO  [Listener at localhost/39347] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:46,863 INFO  [Listener at localhost/39347] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:46,869 INFO  [Listener at localhost/39347] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:46,870 INFO  [Listener at localhost/39347] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:46,870 INFO  [Listener at localhost/39347] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:46,871 INFO  [Listener at localhost/39347] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41145
2020-04-16 00:19:46,872 INFO  [Listener at localhost/39347] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:46,882 INFO  [Listener at localhost/39347] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30feffc{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:46,889 INFO  [Listener at localhost/39347] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@bcb09a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:47,216 INFO  [Listener at localhost/39347] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58065f0c{/,file:///tmp/jetty-localhost-41145-datanode-_-any-5438560317906717734.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:47,216 INFO  [Listener at localhost/39347] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3605c4d3{HTTP/1.1,[http/1.1]}{localhost:41145}
2020-04-16 00:19:47,217 INFO  [Listener at localhost/39347] server.Server (Server.java:doStart(419)) - Started @8954ms
2020-04-16 00:19:47,296 INFO  [Thread-58] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36787
2020-04-16 00:19:47,314 INFO  [Thread-58] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:47,317 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/in_use.lock acquired by nodename 4791@afac0abd37ee
2020-04-16 00:19:47,318 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 is not formatted for namespace 1280205967. Formatting...
2020-04-16 00:19:47,320 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-25e60a9d-6c15-4a76-a8eb-b33c61affe2c for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 
2020-04-16 00:19:47,426 INFO  [Listener at localhost/39347] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45958
2020-04-16 00:19:47,434 INFO  [Listener at localhost/39347] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:47,434 INFO  [Listener at localhost/39347] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:47,435 INFO  [Listener at localhost/39347] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:47,436 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/in_use.lock acquired by nodename 4791@afac0abd37ee
2020-04-16 00:19:47,434 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@187eb9a8] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:47,436 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 is not formatted for namespace 1280205967. Formatting...
2020-04-16 00:19:47,437 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-022936fe-1b05-4407-ba26-45e3be0aa500 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 
2020-04-16 00:19:47,436 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:47,445 INFO  [Listener at localhost/44760] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:44760
2020-04-16 00:19:47,459 INFO  [Listener at localhost/44760] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:47,470 INFO  [Listener at localhost/44760] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:47,481 INFO  [Thread-81] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36787 starting to offer service
2020-04-16 00:19:47,481 INFO  [Listener at localhost/44760] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:47,482 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:47,482 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:47,497 INFO  [Listener at localhost/44760] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:47,499 INFO  [Listener at localhost/44760] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:47,500 INFO  [Listener at localhost/44760] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:47,533 INFO  [Listener at localhost/44760] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:47,533 INFO  [Listener at localhost/44760] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:47,533 INFO  [Listener at localhost/44760] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:47,534 INFO  [Listener at localhost/44760] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:47,534 INFO  [Listener at localhost/44760] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:47,535 INFO  [Listener at localhost/44760] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:47,535 INFO  [Listener at localhost/44760] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:47,536 INFO  [Listener at localhost/44760] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:46263
2020-04-16 00:19:47,536 INFO  [Listener at localhost/44760] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:47,536 INFO  [Listener at localhost/44760] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:47,550 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:47,550 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:47,551 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 and block pool id BP-1521424173-172.17.0.18-1586996381310 is not formatted. Formatting ...
2020-04-16 00:19:47,554 INFO  [Listener at localhost/44760] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:47,603 INFO  [Thread-81] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36787
2020-04-16 00:19:47,603 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1521424173-172.17.0.18-1586996381310 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1521424173-172.17.0.18-1586996381310/current
2020-04-16 00:19:47,604 INFO  [Thread-81] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:47,605 INFO  [Listener at localhost/44760] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:47,606 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/in_use.lock acquired by nodename 4791@afac0abd37ee
2020-04-16 00:19:47,606 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 is not formatted for namespace 1280205967. Formatting...
2020-04-16 00:19:47,606 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-93eafd50-a67a-4adb-aa7f-865bbdce2ef3 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 
2020-04-16 00:19:47,608 INFO  [Listener at localhost/44760] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:47,609 INFO  [Listener at localhost/44760] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:47,609 INFO  [Listener at localhost/44760] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:47,609 INFO  [Listener at localhost/44760] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:47,610 INFO  [Listener at localhost/44760] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44655
2020-04-16 00:19:47,610 INFO  [Listener at localhost/44760] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:47,619 INFO  [Listener at localhost/44760] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@710d7aff{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:47,620 INFO  [Listener at localhost/44760] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65327f5{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:47,631 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:47,632 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:47,632 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 and block pool id BP-1521424173-172.17.0.18-1586996381310 is not formatted. Formatting ...
2020-04-16 00:19:47,632 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1521424173-172.17.0.18-1586996381310 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1521424173-172.17.0.18-1586996381310/current
2020-04-16 00:19:47,651 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/in_use.lock acquired by nodename 4791@afac0abd37ee
2020-04-16 00:19:47,652 INFO  [Thread-58] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=1280205967;bpid=BP-1521424173-172.17.0.18-1586996381310;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1280205967;c=1586996381310;bpid=BP-1521424173-172.17.0.18-1586996381310;dnuuid=null
2020-04-16 00:19:47,653 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 is not formatted for namespace 1280205967. Formatting...
2020-04-16 00:19:47,654 INFO  [Thread-58] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID c23a653d-4cc4-42cb-839a-ea5f84192a04
2020-04-16 00:19:47,654 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-beb43da9-4871-4671-a473-dffbfc8e4233 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 
2020-04-16 00:19:47,761 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:47,761 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:47,761 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 and block pool id BP-1521424173-172.17.0.18-1586996381310 is not formatted. Formatting ...
2020-04-16 00:19:47,761 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1521424173-172.17.0.18-1586996381310 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1521424173-172.17.0.18-1586996381310/current
2020-04-16 00:19:47,795 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:47,796 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:47,796 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 and block pool id BP-1521424173-172.17.0.18-1586996381310 is not formatted. Formatting ...
2020-04-16 00:19:47,796 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1521424173-172.17.0.18-1586996381310 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1521424173-172.17.0.18-1586996381310/current
2020-04-16 00:19:47,798 INFO  [Thread-81] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=1280205967;bpid=BP-1521424173-172.17.0.18-1586996381310;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1280205967;c=1586996381310;bpid=BP-1521424173-172.17.0.18-1586996381310;dnuuid=null
2020-04-16 00:19:47,800 INFO  [Thread-81] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID 1c6313ab-52f0-4498-b5d4-ccf6f229caf8
2020-04-16 00:19:48,031 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-93eafd50-a67a-4adb-aa7f-865bbdce2ef3
2020-04-16 00:19:48,031 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, StorageType: DISK
2020-04-16 00:19:48,033 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-25e60a9d-6c15-4a76-a8eb-b33c61affe2c
2020-04-16 00:19:48,079 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, StorageType: DISK
2020-04-16 00:19:48,101 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-beb43da9-4871-4671-a473-dffbfc8e4233
2020-04-16 00:19:48,101 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, StorageType: DISK
2020-04-16 00:19:48,113 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-022936fe-1b05-4407-ba26-45e3be0aa500
2020-04-16 00:19:48,114 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, StorageType: DISK
2020-04-16 00:19:48,118 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:48,121 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:48,125 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:48,130 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:48,142 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:48,144 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:48,144 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:48,194 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:48,209 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:48,209 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:48,211 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,213 INFO  [Thread-101] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:19:48,232 INFO  [Thread-102] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:19:48,234 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,236 INFO  [Thread-104] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:19:48,241 INFO  [Thread-103] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:19:48,254 INFO  [Listener at localhost/44760] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1136b469{/,file:///tmp/jetty-localhost-44655-datanode-_-any-816586717032356862.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:48,257 INFO  [Listener at localhost/44760] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6579c3d9{HTTP/1.1,[http/1.1]}{localhost:44655}
2020-04-16 00:19:48,259 INFO  [Listener at localhost/44760] server.Server (Server.java:doStart(419)) - Started @9997ms
2020-04-16 00:19:48,412 INFO  [Thread-104] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1521424173-172.17.0.18-1586996381310 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 176ms
2020-04-16 00:19:48,449 INFO  [Listener at localhost/44760] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44675
2020-04-16 00:19:48,451 INFO  [Thread-103] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1521424173-172.17.0.18-1586996381310 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 210ms
2020-04-16 00:19:48,451 INFO  [Listener at localhost/44760] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:19:48,452 INFO  [Listener at localhost/44760] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:19:48,452 INFO  [Listener at localhost/44760] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:48,453 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@66434cc8] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:48,461 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1521424173-172.17.0.18-1586996381310: 227ms
2020-04-16 00:19:48,466 INFO  [Thread-101] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1521424173-172.17.0.18-1586996381310 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 253ms
2020-04-16 00:19:48,481 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:48,494 INFO  [Listener at localhost/34378] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:34378
2020-04-16 00:19:48,510 INFO  [Thread-114] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:19:48,510 INFO  [Thread-114] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1521424173-172.17.0.18-1586996381310/current/replicas doesn't exist 
2020-04-16 00:19:48,513 INFO  [Thread-111] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:19:48,518 INFO  [Listener at localhost/34378] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:19:48,518 INFO  [Listener at localhost/34378] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:19:48,526 INFO  [Thread-117] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36787 starting to offer service
2020-04-16 00:19:48,526 INFO  [Listener at localhost/34378] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:19:48,536 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:48,536 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:48,562 INFO  [Thread-114] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 51ms
2020-04-16 00:19:48,589 INFO  [Thread-102] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1521424173-172.17.0.18-1586996381310 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 357ms
2020-04-16 00:19:48,593 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1521424173-172.17.0.18-1586996381310: 381ms
2020-04-16 00:19:48,513 INFO  [Thread-111] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1521424173-172.17.0.18-1586996381310/current/replicas doesn't exist 
2020-04-16 00:19:48,677 INFO  [Thread-129] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:19:48,650 INFO  [Thread-128] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:19:48,677 INFO  [Thread-128] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1521424173-172.17.0.18-1586996381310/current/replicas doesn't exist 
2020-04-16 00:19:48,677 INFO  [Thread-111] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 164ms
2020-04-16 00:19:48,678 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310: 215ms
2020-04-16 00:19:48,678 INFO  [Thread-129] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1521424173-172.17.0.18-1586996381310/current/replicas doesn't exist 
2020-04-16 00:19:48,680 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:48,682 INFO  [Thread-117] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36787
2020-04-16 00:19:48,682 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-022936fe-1b05-4407-ba26-45e3be0aa500): finished scanning block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,681 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:48,694 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-25e60a9d-6c15-4a76-a8eb-b33c61affe2c): finished scanning block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,697 INFO  [Thread-117] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:19:48,700 INFO  [Thread-117] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/in_use.lock acquired by nodename 4791@afac0abd37ee
2020-04-16 00:19:48,701 INFO  [Thread-117] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 is not formatted for namespace 1280205967. Formatting...
2020-04-16 00:19:48,701 INFO  [Thread-117] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f93de1f9-3a15-4b13-9e59-e5a558eeec1e for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 
2020-04-16 00:19:48,705 INFO  [Thread-129] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 27ms
2020-04-16 00:19:48,718 INFO  [Thread-117] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/in_use.lock acquired by nodename 4791@afac0abd37ee
2020-04-16 00:19:48,718 INFO  [Thread-117] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 is not formatted for namespace 1280205967. Formatting...
2020-04-16 00:19:48,718 INFO  [Thread-117] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-185cb03f-759d-414a-9d7a-4828d3a782c5 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 
2020-04-16 00:19:48,724 INFO  [Thread-128] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 47ms
2020-04-16 00:19:48,725 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310: 76ms
2020-04-16 00:19:48,729 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:19:48,729 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-beb43da9-4871-4671-a473-dffbfc8e4233): finished scanning block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,732 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:19:48,732 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-93eafd50-a67a-4adb-aa7f-865bbdce2ef3): finished scanning block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,778 INFO  [Thread-58] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 12:33 AM with interval of 21600000ms
2020-04-16 00:19:48,786 INFO  [Thread-117] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,783 INFO  [Thread-81] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 12:54 AM with interval of 21600000ms
2020-04-16 00:19:48,802 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-93eafd50-a67a-4adb-aa7f-865bbdce2ef3): no suitable block pools found to scan.  Waiting 1814399923 ms.
2020-04-16 00:19:48,802 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-beb43da9-4871-4671-a473-dffbfc8e4233): no suitable block pools found to scan.  Waiting 1814399924 ms.
2020-04-16 00:19:48,805 INFO  [Thread-117] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,805 INFO  [Thread-117] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 and block pool id BP-1521424173-172.17.0.18-1586996381310 is not formatted. Formatting ...
2020-04-16 00:19:48,805 INFO  [Thread-117] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1521424173-172.17.0.18-1586996381310 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1521424173-172.17.0.18-1586996381310/current
2020-04-16 00:19:48,812 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-25e60a9d-6c15-4a76-a8eb-b33c61affe2c): no suitable block pools found to scan.  Waiting 1814399868 ms.
2020-04-16 00:19:48,821 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-022936fe-1b05-4407-ba26-45e3be0aa500): no suitable block pools found to scan.  Waiting 1814399864 ms.
2020-04-16 00:19:48,831 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid 1c6313ab-52f0-4498-b5d4-ccf6f229caf8) service to localhost/127.0.0.1:36787 beginning handshake with NN
2020-04-16 00:19:48,849 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid c23a653d-4cc4-42cb-839a-ea5f84192a04) service to localhost/127.0.0.1:36787 beginning handshake with NN
2020-04-16 00:19:48,897 INFO  [IPC Server handler 0 on default port 36787] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45154, datanodeUuid=c23a653d-4cc4-42cb-839a-ea5f84192a04, infoPort=33017, infoSecurePort=0, ipcPort=39347, storageInfo=lv=-57;cid=testClusterID;nsid=1280205967;c=1586996381310) storage c23a653d-4cc4-42cb-839a-ea5f84192a04
2020-04-16 00:19:48,900 INFO  [IPC Server handler 0 on default port 36787] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45154
2020-04-16 00:19:48,901 INFO  [IPC Server handler 0 on default port 36787] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c23a653d-4cc4-42cb-839a-ea5f84192a04 (127.0.0.1:45154).
2020-04-16 00:19:48,909 INFO  [IPC Server handler 1 on default port 36787] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37638, datanodeUuid=1c6313ab-52f0-4498-b5d4-ccf6f229caf8, infoPort=45958, infoSecurePort=0, ipcPort=44760, storageInfo=lv=-57;cid=testClusterID;nsid=1280205967;c=1586996381310) storage 1c6313ab-52f0-4498-b5d4-ccf6f229caf8
2020-04-16 00:19:48,909 INFO  [IPC Server handler 1 on default port 36787] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37638
2020-04-16 00:19:48,913 INFO  [IPC Server handler 1 on default port 36787] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1c6313ab-52f0-4498-b5d4-ccf6f229caf8 (127.0.0.1:37638).
2020-04-16 00:19:48,915 INFO  [Thread-117] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,925 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid c23a653d-4cc4-42cb-839a-ea5f84192a04) service to localhost/127.0.0.1:36787 successfully registered with NN
2020-04-16 00:19:48,925 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36787 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:19:48,937 INFO  [Thread-117] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:48,937 INFO  [Thread-117] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 and block pool id BP-1521424173-172.17.0.18-1586996381310 is not formatted. Formatting ...
2020-04-16 00:19:48,937 INFO  [Thread-117] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1521424173-172.17.0.18-1586996381310 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1521424173-172.17.0.18-1586996381310/current
2020-04-16 00:19:48,938 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid 1c6313ab-52f0-4498-b5d4-ccf6f229caf8) service to localhost/127.0.0.1:36787 successfully registered with NN
2020-04-16 00:19:48,938 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36787 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:19:48,959 INFO  [Thread-117] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=1280205967;bpid=BP-1521424173-172.17.0.18-1586996381310;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1280205967;c=1586996381310;bpid=BP-1521424173-172.17.0.18-1586996381310;dnuuid=null
2020-04-16 00:19:48,962 INFO  [Thread-117] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID 24d1ef49-3cc0-43ca-ba61-688bf1483ea4
2020-04-16 00:19:48,985 INFO  [Thread-117] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f93de1f9-3a15-4b13-9e59-e5a558eeec1e
2020-04-16 00:19:48,985 INFO  [Thread-117] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, StorageType: DISK
2020-04-16 00:19:48,987 INFO  [Thread-117] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-185cb03f-759d-414a-9d7a-4828d3a782c5
2020-04-16 00:19:48,987 INFO  [Thread-117] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, StorageType: DISK
2020-04-16 00:19:48,988 INFO  [Thread-117] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:19:48,992 INFO  [Thread-117] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:49,029 INFO  [Thread-117] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:49,029 INFO  [Thread-117] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:49,030 INFO  [Thread-117] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:49,040 INFO  [Thread-117] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:49,040 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:19:49,042 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:19:49,119 INFO  [IPC Server handler 7 on default port 36787] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-25e60a9d-6c15-4a76-a8eb-b33c61affe2c for DN 127.0.0.1:45154
2020-04-16 00:19:49,120 INFO  [IPC Server handler 7 on default port 36787] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-022936fe-1b05-4407-ba26-45e3be0aa500 for DN 127.0.0.1:45154
2020-04-16 00:19:49,124 INFO  [IPC Server handler 8 on default port 36787] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-93eafd50-a67a-4adb-aa7f-865bbdce2ef3 for DN 127.0.0.1:37638
2020-04-16 00:19:49,131 INFO  [IPC Server handler 8 on default port 36787] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-beb43da9-4871-4671-a473-dffbfc8e4233 for DN 127.0.0.1:37638
2020-04-16 00:19:49,136 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1521424173-172.17.0.18-1586996381310 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 96ms
2020-04-16 00:19:49,142 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1521424173-172.17.0.18-1586996381310 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 100ms
2020-04-16 00:19:49,142 INFO  [Thread-117] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1521424173-172.17.0.18-1586996381310: 102ms
2020-04-16 00:19:49,144 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:19:49,144 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:19:49,145 INFO  [Thread-142] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1521424173-172.17.0.18-1586996381310/current/replicas doesn't exist 
2020-04-16 00:19:49,145 INFO  [Thread-143] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1521424173-172.17.0.18-1586996381310/current/replicas doesn't exist 
2020-04-16 00:19:49,145 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 1ms
2020-04-16 00:19:49,146 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 1ms
2020-04-16 00:19:49,146 INFO  [Thread-117] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1521424173-172.17.0.18-1586996381310: 3ms
2020-04-16 00:19:49,147 INFO  [Thread-117] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 4:26 AM with interval of 21600000ms
2020-04-16 00:19:49,150 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid 24d1ef49-3cc0-43ca-ba61-688bf1483ea4) service to localhost/127.0.0.1:36787 beginning handshake with NN
2020-04-16 00:19:49,152 INFO  [IPC Server handler 2 on default port 36787] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46263, datanodeUuid=24d1ef49-3cc0-43ca-ba61-688bf1483ea4, infoPort=44675, infoSecurePort=0, ipcPort=34378, storageInfo=lv=-57;cid=testClusterID;nsid=1280205967;c=1586996381310) storage 24d1ef49-3cc0-43ca-ba61-688bf1483ea4
2020-04-16 00:19:49,152 INFO  [IPC Server handler 2 on default port 36787] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46263
2020-04-16 00:19:49,152 INFO  [IPC Server handler 2 on default port 36787] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 24d1ef49-3cc0-43ca-ba61-688bf1483ea4 (127.0.0.1:46263).
2020-04-16 00:19:49,154 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid 24d1ef49-3cc0-43ca-ba61-688bf1483ea4) service to localhost/127.0.0.1:36787 successfully registered with NN
2020-04-16 00:19:49,154 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36787 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:19:49,158 INFO  [IPC Server handler 6 on default port 36787] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f93de1f9-3a15-4b13-9e59-e5a558eeec1e for DN 127.0.0.1:46263
2020-04-16 00:19:49,158 INFO  [IPC Server handler 6 on default port 36787] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-185cb03f-759d-414a-9d7a-4828d3a782c5 for DN 127.0.0.1:46263
2020-04-16 00:19:49,165 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:19:49,166 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1521424173-172.17.0.18-1586996381310 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:19:49,167 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-f93de1f9-3a15-4b13-9e59-e5a558eeec1e): finished scanning block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:49,167 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-f93de1f9-3a15-4b13-9e59-e5a558eeec1e): no suitable block pools found to scan.  Waiting 1814399979 ms.
2020-04-16 00:19:49,181 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-185cb03f-759d-414a-9d7a-4828d3a782c5): finished scanning block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:49,182 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-185cb03f-759d-414a-9d7a-4828d3a782c5): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-04-16 00:19:49,235 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x40a9c3fe602eaf3b: Processing first storage report for DS-022936fe-1b05-4407-ba26-45e3be0aa500 from datanode c23a653d-4cc4-42cb-839a-ea5f84192a04
2020-04-16 00:19:49,253 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x40a9c3fe602eaf3b: from storage DS-022936fe-1b05-4407-ba26-45e3be0aa500 node DatanodeRegistration(127.0.0.1:45154, datanodeUuid=c23a653d-4cc4-42cb-839a-ea5f84192a04, infoPort=33017, infoSecurePort=0, ipcPort=39347, storageInfo=lv=-57;cid=testClusterID;nsid=1280205967;c=1586996381310), blocks: 0, hasStaleStorage: true, processing time: 11 msecs, invalidatedBlocks: 0
2020-04-16 00:19:49,254 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x37109ed82661f3a1: Processing first storage report for DS-beb43da9-4871-4671-a473-dffbfc8e4233 from datanode 1c6313ab-52f0-4498-b5d4-ccf6f229caf8
2020-04-16 00:19:49,254 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x37109ed82661f3a1: from storage DS-beb43da9-4871-4671-a473-dffbfc8e4233 node DatanodeRegistration(127.0.0.1:37638, datanodeUuid=1c6313ab-52f0-4498-b5d4-ccf6f229caf8, infoPort=45958, infoSecurePort=0, ipcPort=44760, storageInfo=lv=-57;cid=testClusterID;nsid=1280205967;c=1586996381310), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:49,254 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x16c30f8890c84dc1: Processing first storage report for DS-f93de1f9-3a15-4b13-9e59-e5a558eeec1e from datanode 24d1ef49-3cc0-43ca-ba61-688bf1483ea4
2020-04-16 00:19:49,254 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x16c30f8890c84dc1: from storage DS-f93de1f9-3a15-4b13-9e59-e5a558eeec1e node DatanodeRegistration(127.0.0.1:46263, datanodeUuid=24d1ef49-3cc0-43ca-ba61-688bf1483ea4, infoPort=44675, infoSecurePort=0, ipcPort=34378, storageInfo=lv=-57;cid=testClusterID;nsid=1280205967;c=1586996381310), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:49,254 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x37109ed82661f3a1: Processing first storage report for DS-93eafd50-a67a-4adb-aa7f-865bbdce2ef3 from datanode 1c6313ab-52f0-4498-b5d4-ccf6f229caf8
2020-04-16 00:19:49,254 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x37109ed82661f3a1: from storage DS-93eafd50-a67a-4adb-aa7f-865bbdce2ef3 node DatanodeRegistration(127.0.0.1:37638, datanodeUuid=1c6313ab-52f0-4498-b5d4-ccf6f229caf8, infoPort=45958, infoSecurePort=0, ipcPort=44760, storageInfo=lv=-57;cid=testClusterID;nsid=1280205967;c=1586996381310), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:49,256 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x16c30f8890c84dc1: Processing first storage report for DS-185cb03f-759d-414a-9d7a-4828d3a782c5 from datanode 24d1ef49-3cc0-43ca-ba61-688bf1483ea4
2020-04-16 00:19:49,256 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x16c30f8890c84dc1: from storage DS-185cb03f-759d-414a-9d7a-4828d3a782c5 node DatanodeRegistration(127.0.0.1:46263, datanodeUuid=24d1ef49-3cc0-43ca-ba61-688bf1483ea4, infoPort=44675, infoSecurePort=0, ipcPort=34378, storageInfo=lv=-57;cid=testClusterID;nsid=1280205967;c=1586996381310), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:49,256 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x40a9c3fe602eaf3b: Processing first storage report for DS-25e60a9d-6c15-4a76-a8eb-b33c61affe2c from datanode c23a653d-4cc4-42cb-839a-ea5f84192a04
2020-04-16 00:19:49,256 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x40a9c3fe602eaf3b: from storage DS-25e60a9d-6c15-4a76-a8eb-b33c61affe2c node DatanodeRegistration(127.0.0.1:45154, datanodeUuid=c23a653d-4cc4-42cb-839a-ea5f84192a04, infoPort=33017, infoSecurePort=0, ipcPort=39347, storageInfo=lv=-57;cid=testClusterID;nsid=1280205967;c=1586996381310), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:19:49,334 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x40a9c3fe602eaf3b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 103 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:19:49,334 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:49,336 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x16c30f8890c84dc1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 126 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:19:49,336 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:49,337 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x37109ed82661f3a1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 117 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:19:49,337 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:49,794 INFO  [IPC Server handler 9 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-16 00:19:49,823 INFO  [Listener at localhost/34378] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-04-16 00:19:49,872 INFO  [IPC Server handler 0 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive	dst=null	perm=null	proto=rpc
2020-04-16 00:19:49,879 INFO  [IPC Server handler 1 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:19:49,900 INFO  [IPC Server handler 2 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/input	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:19:49,996 INFO  [IPC Server handler 6 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/a	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:50,080 INFO  [IPC Server handler 7 on default port 36787] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:37638, 127.0.0.1:46263, 127.0.0.1:45154 for /user/root/input/a
2020-04-16 00:19:50,099 INFO  [Thread-150] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:50,219 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:36972 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001 src: /127.0.0.1:36972 dest: /127.0.0.1:37638
2020-04-16 00:19:50,254 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:36972 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:50,287 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:56788 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001 src: /127.0.0.1:56788 dest: /127.0.0.1:46263
2020-04-16 00:19:50,289 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:56788 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:50,321 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57604 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001 src: /127.0.0.1:57604 dest: /127.0.0.1:45154
2020-04-16 00:19:50,430 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57604, dest: /127.0.0.1:45154, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: c23a653d-4cc4-42cb-839a-ea5f84192a04, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, duration(ns): 39287292
2020-04-16 00:19:50,431 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:50,457 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45154]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56788, dest: /127.0.0.1:46263, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 24d1ef49-3cc0-43ca-ba61-688bf1483ea4, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, duration(ns): 45040267
2020-04-16 00:19:50,462 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45154]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45154] terminating
2020-04-16 00:19:50,478 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46263, 127.0.0.1:45154]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36972, dest: /127.0.0.1:37638, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 1c6313ab-52f0-4498-b5d4-ccf6f229caf8, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, duration(ns): 62058704
2020-04-16 00:19:50,478 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46263, 127.0.0.1:45154]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46263, 127.0.0.1:45154] terminating
2020-04-16 00:19:50,502 INFO  [IPC Server handler 2 on default port 36787] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/a is closed by DFSClient_NONMAPREDUCE_823319680_1
2020-04-16 00:19:50,531 INFO  [IPC Server handler 6 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/b	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:50,559 INFO  [IPC Server handler 7 on default port 36787] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:37638, 127.0.0.1:46263, 127.0.0.1:45154 for /user/root/input/b
2020-04-16 00:19:50,572 INFO  [Thread-159] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:50,577 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:36980 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002 src: /127.0.0.1:36980 dest: /127.0.0.1:37638
2020-04-16 00:19:50,585 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:36980 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:50,589 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:56796 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002 src: /127.0.0.1:56796 dest: /127.0.0.1:46263
2020-04-16 00:19:50,591 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:56796 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:50,600 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57612 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002 src: /127.0.0.1:57612 dest: /127.0.0.1:45154
2020-04-16 00:19:50,697 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57612, dest: /127.0.0.1:45154, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: c23a653d-4cc4-42cb-839a-ea5f84192a04, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, duration(ns): 91446933
2020-04-16 00:19:50,697 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:50,742 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45154]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56796, dest: /127.0.0.1:46263, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 24d1ef49-3cc0-43ca-ba61-688bf1483ea4, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, duration(ns): 124761138
2020-04-16 00:19:50,742 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45154]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45154] terminating
2020-04-16 00:19:50,777 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46263, 127.0.0.1:45154]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36980, dest: /127.0.0.1:37638, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 1c6313ab-52f0-4498-b5d4-ccf6f229caf8, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, duration(ns): 144525458
2020-04-16 00:19:50,777 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46263, 127.0.0.1:45154]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46263, 127.0.0.1:45154] terminating
2020-04-16 00:19:50,810 INFO  [IPC Server handler 5 on default port 36787] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/b is closed by DFSClient_NONMAPREDUCE_823319680_1
2020-04-16 00:19:50,830 INFO  [IPC Server handler 5 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/c	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:50,852 INFO  [IPC Server handler 1 on default port 36787] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:45154, 127.0.0.1:37638, 127.0.0.1:46263 for /user/root/input/c
2020-04-16 00:19:50,860 INFO  [Thread-167] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:50,870 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57614 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003 src: /127.0.0.1:57614 dest: /127.0.0.1:45154
2020-04-16 00:19:50,872 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57614 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:50,877 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:36988 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003 src: /127.0.0.1:36988 dest: /127.0.0.1:37638
2020-04-16 00:19:50,878 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:36988 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:50,889 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:56804 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003 src: /127.0.0.1:56804 dest: /127.0.0.1:46263
2020-04-16 00:19:50,979 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56804, dest: /127.0.0.1:46263, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 24d1ef49-3cc0-43ca-ba61-688bf1483ea4, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, duration(ns): 77518796
2020-04-16 00:19:50,980 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:51,017 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46263]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36988, dest: /127.0.0.1:37638, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 1c6313ab-52f0-4498-b5d4-ccf6f229caf8, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, duration(ns): 35835774
2020-04-16 00:19:51,017 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46263]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46263] terminating
2020-04-16 00:19:51,065 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37638, 127.0.0.1:46263]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57614, dest: /127.0.0.1:45154, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: c23a653d-4cc4-42cb-839a-ea5f84192a04, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, duration(ns): 160918033
2020-04-16 00:19:51,069 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37638, 127.0.0.1:46263]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37638, 127.0.0.1:46263] terminating
2020-04-16 00:19:51,099 INFO  [IPC Server handler 7 on default port 36787] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/c is closed by DFSClient_NONMAPREDUCE_823319680_1
parentPathStr = /user/root/input
2020-04-16 00:19:51,178 INFO  [IPC Server handler 8 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:19:51,203 INFO  [IPC Server handler 4 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:19:51,209 INFO  [IPC Server handler 3 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:19:51,212 INFO  [IPC Server handler 5 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:19:51,220 INFO  [IPC Server handler 0 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:19:51,229 INFO  [IPC Server handler 1 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive	dst=null	perm=null	proto=rpc
2020-04-16 00:19:51,246 INFO  [Listener at localhost/34378] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:19:51,294 INFO  [IPC Server handler 9 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:19:51,298 INFO  [IPC Server handler 2 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:19:51,306 INFO  [IPC Server handler 6 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:19:51,341 INFO  [Listener at localhost/34378] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:19:51,351 INFO  [Listener at localhost/34378] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:19:51,405 INFO  [Listener at localhost/34378] mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:1
2020-04-16 00:19:51,608 INFO  [Listener at localhost/34378] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1970353137_0001
2020-04-16 00:19:51,608 INFO  [Listener at localhost/34378] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2020-04-16 00:19:51,981 INFO  [Listener at localhost/34378] mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2020-04-16 00:19:51,983 INFO  [Listener at localhost/34378] mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1970353137_0001
2020-04-16 00:19:51,997 INFO  [Thread-175] mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2020-04-16 00:19:52,000 INFO  [Thread-175] mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2020-04-16 00:19:52,008 INFO  [Thread-175] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:19:52,008 INFO  [Thread-175] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:19:52,032 INFO  [IPC Server handler 4 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/archive/foo.har/_temporary/0	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:19:52,078 INFO  [Thread-175] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2020-04-16 00:19:52,094 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1970353137_0001_m_000000_0
2020-04-16 00:19:52,143 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:19:52,145 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:19:52,205 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2020-04-16 00:19:52,207 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:updateJobWithSplit(497)) - Processing split: file:/tmp/hadoop/mapred/staging/root2147329545/.staging/har_wbmfy7/_har_src_files:0+277
2020-04-16 00:19:52,229 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:runOldMapper(451)) - numReduceTasks: 1
2020-04-16 00:19:52,322 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:setEquator(1219)) - (EQUATOR) 0 kvi 26214396(104857584)
2020-04-16 00:19:52,322 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1012)) - mapreduce.task.io.sort.mb: 100
2020-04-16 00:19:52,322 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1013)) - soft limit at 83886080
2020-04-16 00:19:52,322 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1014)) - bufstart = 0; bufvoid = 104857600
2020-04-16 00:19:52,322 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1015)) - kvstart = 26214396; length = 6553600
2020-04-16 00:19:52,334 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:createSortingCollector(409)) - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-04-16 00:19:52,339 INFO  [IPC Server handler 7 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_m_000000_0/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,347 INFO  [IPC Server handler 8 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_m_000000_0/part-0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:52,382 INFO  [IPC Server handler 4 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,386 INFO  [IPC Server handler 3 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,404 INFO  [IPC Server handler 5 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/a	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,457 INFO  [LocalJobRunner Map Task Executor #0] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:52,521 INFO  [IPC Server handler 0 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,542 INFO  [IPC Server handler 1 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/b	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,550 INFO  [LocalJobRunner Map Task Executor #0] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:52,568 INFO  [IPC Server handler 9 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,571 INFO  [IPC Server handler 2 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/c	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,576 INFO  [LocalJobRunner Map Task Executor #0] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:52,587 INFO  [IPC Server handler 6 on default port 36787] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:45154, 127.0.0.1:37638, 127.0.0.1:46263 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_m_000000_0/part-0
2020-04-16 00:19:52,592 INFO  [Thread-179] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:52,599 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57652 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004 src: /127.0.0.1:57652 dest: /127.0.0.1:45154
2020-04-16 00:19:52,601 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57652 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:52,613 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:37026 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004 src: /127.0.0.1:37026 dest: /127.0.0.1:37638
2020-04-16 00:19:52,614 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:37026 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:52,623 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:56842 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004 src: /127.0.0.1:56842 dest: /127.0.0.1:46263
2020-04-16 00:19:52,689 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56842, dest: /127.0.0.1:46263, bytes: 3, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 24d1ef49-3cc0-43ca-ba61-688bf1483ea4, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, duration(ns): 64494875
2020-04-16 00:19:52,690 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:52,703 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46263]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37026, dest: /127.0.0.1:37638, bytes: 3, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 1c6313ab-52f0-4498-b5d4-ccf6f229caf8, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, duration(ns): 73020906
2020-04-16 00:19:52,703 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46263]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46263] terminating
2020-04-16 00:19:52,713 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37638, 127.0.0.1:46263]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57652, dest: /127.0.0.1:45154, bytes: 3, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: c23a653d-4cc4-42cb-839a-ea5f84192a04, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, duration(ns): 70015409
2020-04-16 00:19:52,713 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37638, 127.0.0.1:46263]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37638, 127.0.0.1:46263] terminating
2020-04-16 00:19:52,750 INFO  [IPC Server handler 3 on default port 36787] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_m_000000_0/part-0 is closed by DFSClient_NONMAPREDUCE_823319680_1
2020-04-16 00:19:52,761 INFO  [IPC Server handler 5 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_m_000000_0/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,768 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2020-04-16 00:19:52,768 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1476)) - Starting flush of map output
2020-04-16 00:19:52,768 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1498)) - Spilling map output
2020-04-16 00:19:52,768 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1499)) - bufstart = 0; bufend = 237; bufvoid = 104857600
2020-04-16 00:19:52,768 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1501)) - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
2020-04-16 00:19:52,782 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:sortAndSpill(1696)) - Finished spill 0
2020-04-16 00:19:52,795 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:done(1244)) - Task:attempt_local1970353137_0001_m_000000_0 is done. And is in the process of committing
2020-04-16 00:19:52,798 INFO  [IPC Server handler 0 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,802 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2020-04-16 00:19:52,802 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:commit(1421)) - Task attempt_local1970353137_0001_m_000000_0 is allowed to commit now
2020-04-16 00:19:52,804 INFO  [IPC Server handler 1 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,812 INFO  [IPC Server handler 9 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,819 INFO  [IPC Server handler 2 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,826 INFO  [IPC Server handler 6 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:52,847 INFO  [IPC Server handler 7 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_m_000000_0/part-0	dst=/user/root/archive/foo.har/part-0	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:52,851 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:commitTask(606)) - Saved output of task 'attempt_local1970353137_0001_m_000000_0' to hdfs://localhost:36787/user/root/archive/foo.har
2020-04-16 00:19:52,856 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file hdfs://localhost:36787/user/root/input/c to archive.
2020-04-16 00:19:52,856 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1970353137_0001_m_000000_0' done.
2020-04-16 00:19:52,859 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1970353137_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=62365
		FILE: Number of bytes written=590107
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3
		HDFS: Number of bytes written=6
		HDFS: Number of read operations=21
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=11
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=237
		Map output materialized bytes=251
		Input split bytes=133
		Combine input records=0
		Spilled Records=4
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2023751680
	File Input Format Counters 
		Bytes Read=289
2020-04-16 00:19:52,859 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1970353137_0001_m_000000_0
2020-04-16 00:19:52,864 INFO  [Thread-175] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2020-04-16 00:19:52,870 INFO  [Thread-175] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for reduce tasks
2020-04-16 00:19:52,871 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:run(330)) - Starting task: attempt_local1970353137_0001_r_000000_0
2020-04-16 00:19:52,905 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:19:52,905 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:19:52,906 INFO  [pool-49-thread-1] mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2020-04-16 00:19:52,911 INFO  [pool-49-thread-1] mapred.ReduceTask (ReduceTask.java:run(363)) - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65ad38a5
2020-04-16 00:19:52,926 INFO  [pool-49-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:19:52,947 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:<init>(208)) - MergerManager: memoryLimit=1416626176, maxSingleShuffleLimit=354156544, mergeThreshold=934973312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-04-16 00:19:52,976 INFO  [EventFetcher for fetching Map Completion Events] reduce.EventFetcher (EventFetcher.java:run(61)) - attempt_local1970353137_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-04-16 00:19:53,001 INFO  [Listener at localhost/34378] mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1970353137_0001 running in uber mode : false
2020-04-16 00:19:53,002 INFO  [Listener at localhost/34378] mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2020-04-16 00:19:53,030 INFO  [localfetcher#1] reduce.LocalFetcher (LocalFetcher.java:copyMapOutput(145)) - localfetcher#1 about to shuffle output of map attempt_local1970353137_0001_m_000000_0 decomp: 247 len: 251 to MEMORY
2020-04-16 00:19:53,034 INFO  [localfetcher#1] reduce.InMemoryMapOutput (InMemoryMapOutput.java:doShuffle(94)) - Read 247 bytes from map-output for attempt_local1970353137_0001_m_000000_0
2020-04-16 00:19:53,034 INFO  [localfetcher#1] reduce.MergeManagerImpl (MergeManagerImpl.java:closeInMemoryFile(323)) - closeInMemoryFile -> map-output of size: 247, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->247
2020-04-16 00:19:53,053 INFO  [EventFetcher for fetching Map Completion Events] reduce.EventFetcher (EventFetcher.java:run(76)) - EventFetcher is interrupted.. Returning
2020-04-16 00:19:53,061 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:19:53,062 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(695)) - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-04-16 00:19:53,071 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(606)) - Merging 1 sorted segments
2020-04-16 00:19:53,077 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(705)) - Down to the last merge-pass, with 1 segments left of total size: 241 bytes
2020-04-16 00:19:53,083 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(762)) - Merged 1 segments, 247 bytes to disk to satisfy reduce memory limit
2020-04-16 00:19:53,084 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(792)) - Merging 1 files, 251 bytes from disk
2020-04-16 00:19:53,084 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(807)) - Merging 0 segments, 0 bytes from memory into reduce
2020-04-16 00:19:53,084 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(606)) - Merging 1 sorted segments
2020-04-16 00:19:53,086 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(705)) - Down to the last merge-pass, with 1 segments left of total size: 241 bytes
2020-04-16 00:19:53,087 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:19:53,105 INFO  [IPC Server handler 8 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,117 INFO  [IPC Server handler 4 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,127 INFO  [IPC Server handler 3 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_index	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:53,135 INFO  [IPC Server handler 5 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_masterindex	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:53,150 INFO  [IPC Server handler 0 on default port 36787] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:46263, 127.0.0.1:45154, 127.0.0.1:37638 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_masterindex
2020-04-16 00:19:53,159 INFO  [Thread-197] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,184 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:56860 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005 src: /127.0.0.1:56860 dest: /127.0.0.1:46263
2020-04-16 00:19:53,185 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:56860 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,198 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57676 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005 src: /127.0.0.1:57676 dest: /127.0.0.1:45154
2020-04-16 00:19:53,203 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57676 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,210 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:37050 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005 src: /127.0.0.1:37050 dest: /127.0.0.1:37638
2020-04-16 00:19:53,325 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37050, dest: /127.0.0.1:37638, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 1c6313ab-52f0-4498-b5d4-ccf6f229caf8, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, duration(ns): 104436330
2020-04-16 00:19:53,326 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:53,338 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37638]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57676, dest: /127.0.0.1:45154, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: c23a653d-4cc4-42cb-839a-ea5f84192a04, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, duration(ns): 86802457
2020-04-16 00:19:53,339 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37638]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37638] terminating
2020-04-16 00:19:53,347 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45154, 127.0.0.1:37638]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56860, dest: /127.0.0.1:46263, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 24d1ef49-3cc0-43ca-ba61-688bf1483ea4, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, duration(ns): 117454839
2020-04-16 00:19:53,348 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45154, 127.0.0.1:37638]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45154, 127.0.0.1:37638] terminating
2020-04-16 00:19:53,354 INFO  [IPC Server handler 6 on default port 36787] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_masterindex is closed by DFSClient_NONMAPREDUCE_823319680_1
2020-04-16 00:19:53,383 INFO  [IPC Server handler 7 on default port 36787] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:45154, 127.0.0.1:37638, 127.0.0.1:46263 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_index
2020-04-16 00:19:53,390 INFO  [Thread-196] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,394 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57682 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006 src: /127.0.0.1:57682 dest: /127.0.0.1:45154
2020-04-16 00:19:53,395 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:57682 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,410 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:37056 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006 src: /127.0.0.1:37056 dest: /127.0.0.1:37638
2020-04-16 00:19:53,411 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:37056 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:19:53,413 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_823319680_1 at /127.0.0.1:56872 [Receiving block BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006 src: /127.0.0.1:56872 dest: /127.0.0.1:46263
2020-04-16 00:19:53,654 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56872, dest: /127.0.0.1:46263, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 24d1ef49-3cc0-43ca-ba61-688bf1483ea4, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, duration(ns): 216520545
2020-04-16 00:19:53,654 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-16 00:19:53,669 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46263]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37056, dest: /127.0.0.1:37638, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: 1c6313ab-52f0-4498-b5d4-ccf6f229caf8, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, duration(ns): 245307127
2020-04-16 00:19:53,669 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46263]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46263] terminating
2020-04-16 00:19:53,690 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37638, 127.0.0.1:46263]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57682, dest: /127.0.0.1:45154, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_823319680_1, offset: 0, srvID: c23a653d-4cc4-42cb-839a-ea5f84192a04, blockid: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, duration(ns): 101805203
2020-04-16 00:19:53,691 INFO  [PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37638, 127.0.0.1:46263]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1521424173-172.17.0.18-1586996381310:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37638, 127.0.0.1:46263] terminating
2020-04-16 00:19:53,697 INFO  [IPC Server handler 5 on default port 36787] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_index is closed by DFSClient_NONMAPREDUCE_823319680_1
2020-04-16 00:19:53,703 INFO  [IPC Server handler 0 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,705 INFO  [IPC Server handler 1 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,706 INFO  [pool-49-thread-1] mapred.Task (Task.java:done(1244)) - Task:attempt_local1970353137_0001_r_000000_0 is done. And is in the process of committing
2020-04-16 00:19:53,708 INFO  [IPC Server handler 9 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,714 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:19:53,714 INFO  [pool-49-thread-1] mapred.Task (Task.java:commit(1421)) - Task attempt_local1970353137_0001_r_000000_0 is allowed to commit now
2020-04-16 00:19:53,717 INFO  [IPC Server handler 2 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,725 INFO  [IPC Server handler 6 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,733 INFO  [IPC Server handler 7 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,739 INFO  [IPC Server handler 8 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,745 INFO  [IPC Server handler 4 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_index	dst=/user/root/archive/foo.har/_index	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:53,749 INFO  [IPC Server handler 3 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,757 INFO  [IPC Server handler 5 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1970353137_0001_r_000000_0/_masterindex	dst=/user/root/archive/foo.har/_masterindex	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:53,758 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:commitTask(606)) - Saved output of task 'attempt_local1970353137_0001_r_000000_0' to hdfs://localhost:36787/user/root/archive/foo.har
2020-04-16 00:19:53,766 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - reduce > reduce
2020-04-16 00:19:53,767 INFO  [pool-49-thread-1] mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1970353137_0001_r_000000_0' done.
2020-04-16 00:19:53,768 INFO  [pool-49-thread-1] mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1970353137_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=62899
		FILE: Number of bytes written=590358
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=3
		HDFS: Number of bytes written=244
		HDFS: Number of read operations=27
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=19
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=251
		Reduce input records=4
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=140
		Total committed heap usage (bytes)=2023751680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2020-04-16 00:19:53,768 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:run(353)) - Finishing task: attempt_local1970353137_0001_r_000000_0
2020-04-16 00:19:53,770 INFO  [Thread-175] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - reduce task executor complete.
2020-04-16 00:19:53,788 INFO  [IPC Server handler 0 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary	dst=null	perm=null	proto=rpc
2020-04-16 00:19:53,806 INFO  [IPC Server handler 1 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_SUCCESS	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:19:53,814 INFO  [IPC Server handler 9 on default port 36787] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_SUCCESS is closed by DFSClient_NONMAPREDUCE_823319680_1
2020-04-16 00:19:54,003 INFO  [Listener at localhost/34378] mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 100%
2020-04-16 00:19:54,004 INFO  [Listener at localhost/34378] mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1970353137_0001 completed successfully
2020-04-16 00:19:54,023 INFO  [Listener at localhost/34378] mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 36
	File System Counters
		FILE: Number of bytes read=125264
		FILE: Number of bytes written=1180465
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6
		HDFS: Number of bytes written=250
		HDFS: Number of read operations=48
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=30
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=237
		Map output materialized bytes=251
		Input split bytes=133
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=251
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=140
		Total committed heap usage (bytes)=4047503360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=0
2020-04-16 00:19:54,049 INFO  [IPC Server handler 2 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,061 INFO  [IPC Server handler 6 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,080 INFO  [IPC Server handler 7 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,090 INFO  [IPC Server handler 8 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,115 INFO  [IPC Server handler 4 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,119 INFO  [IPC Server handler 3 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,133 INFO  [IPC Server handler 5 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,145 INFO  [IPC Server handler 0 on default port 36787] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:19:54,152 INFO  [Listener at localhost/34378] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-04-16 00:19:54,158 INFO  [Listener at localhost/34378] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-04-16 00:19:54,158 INFO  [Listener at localhost/34378] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:19:54,159 WARN  [Listener at localhost/34378] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:19:54,160 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@a0a9fa5] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:19:54,166 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-f93de1f9-3a15-4b13-9e59-e5a558eeec1e) exiting.
2020-04-16 00:19:54,169 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-185cb03f-759d-414a-9d7a-4828d3a782c5) exiting.
2020-04-16 00:19:54,259 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1136b469{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:19:54,270 INFO  [Listener at localhost/34378] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6579c3d9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:19:54,271 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65327f5{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:19:54,272 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@710d7aff{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:19:54,285 INFO  [Listener at localhost/34378] ipc.Server (Server.java:stop(3359)) - Stopping server on 34378
2020-04-16 00:19:54,291 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:19:54,292 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:19:54,301 WARN  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:19:54,301 WARN  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid 24d1ef49-3cc0-43ca-ba61-688bf1483ea4) service to localhost/127.0.0.1:36787
2020-04-16 00:19:54,301 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid 24d1ef49-3cc0-43ca-ba61-688bf1483ea4)
2020-04-16 00:19:54,301 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:54,304 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1521424173-172.17.0.18-1586996381310] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:54,304 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1521424173-172.17.0.18-1586996381310] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:54,324 INFO  [Listener at localhost/34378] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:19:54,324 INFO  [Listener at localhost/34378] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:19:54,325 INFO  [Listener at localhost/34378] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:19:54,325 INFO  [Listener at localhost/34378] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:19:54,332 INFO  [Listener at localhost/34378] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:19:54,332 INFO  [Listener at localhost/34378] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-04-16 00:19:54,332 INFO  [Listener at localhost/34378] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:19:54,332 WARN  [Listener at localhost/34378] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:19:54,338 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-93eafd50-a67a-4adb-aa7f-865bbdce2ef3) exiting.
2020-04-16 00:19:54,339 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-beb43da9-4871-4671-a473-dffbfc8e4233) exiting.
2020-04-16 00:19:54,340 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5bb8f9e2] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:19:54,430 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58065f0c{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:19:54,437 INFO  [Listener at localhost/34378] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3605c4d3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:19:54,438 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@bcb09a6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:19:54,438 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30feffc{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:19:54,441 INFO  [Listener at localhost/34378] ipc.Server (Server.java:stop(3359)) - Stopping server on 44760
2020-04-16 00:19:54,466 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:19:54,468 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:19:54,466 WARN  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:19:54,469 WARN  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid 1c6313ab-52f0-4498-b5d4-ccf6f229caf8) service to localhost/127.0.0.1:36787
2020-04-16 00:19:54,469 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid 1c6313ab-52f0-4498-b5d4-ccf6f229caf8)
2020-04-16 00:19:54,469 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:54,470 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1521424173-172.17.0.18-1586996381310] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:54,470 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1521424173-172.17.0.18-1586996381310] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:54,478 INFO  [Listener at localhost/34378] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:19:54,478 INFO  [Listener at localhost/34378] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:19:54,479 INFO  [Listener at localhost/34378] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:19:54,480 INFO  [Listener at localhost/34378] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:19:54,482 INFO  [Listener at localhost/34378] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:19:54,485 INFO  [Listener at localhost/34378] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-04-16 00:19:54,485 INFO  [Listener at localhost/34378] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:19:54,489 WARN  [Listener at localhost/34378] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:19:54,490 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6b5f8707] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:19:54,517 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-25e60a9d-6c15-4a76-a8eb-b33c61affe2c) exiting.
2020-04-16 00:19:54,521 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-022936fe-1b05-4407-ba26-45e3be0aa500) exiting.
2020-04-16 00:19:54,632 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1af1347d{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:19:54,633 INFO  [Listener at localhost/34378] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@632aa1a3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:19:54,633 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@282308c3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:19:54,634 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7726e185{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:19:54,651 INFO  [Listener at localhost/34378] ipc.Server (Server.java:stop(3359)) - Stopping server on 39347
2020-04-16 00:19:54,701 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:19:54,703 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:19:54,704 WARN  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:19:54,704 WARN  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid c23a653d-4cc4-42cb-839a-ea5f84192a04) service to localhost/127.0.0.1:36787
2020-04-16 00:19:54,807 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1521424173-172.17.0.18-1586996381310 (Datanode Uuid c23a653d-4cc4-42cb-839a-ea5f84192a04)
2020-04-16 00:19:54,807 INFO  [BP-1521424173-172.17.0.18-1586996381310 heartbeating to localhost/127.0.0.1:36787] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1521424173-172.17.0.18-1586996381310
2020-04-16 00:19:54,808 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1521424173-172.17.0.18-1586996381310] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:54,809 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1521424173-172.17.0.18-1586996381310] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:19:54,829 INFO  [Listener at localhost/34378] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:19:54,829 INFO  [Listener at localhost/34378] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:19:54,831 INFO  [Listener at localhost/34378] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:19:54,831 INFO  [Listener at localhost/34378] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:19:54,835 INFO  [Listener at localhost/34378] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:19:54,836 INFO  [Listener at localhost/34378] hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-04-16 00:19:54,836 INFO  [Listener at localhost/34378] namenode.NameNode (NameNode.java:stop(1013)) - msx-hdfs NameNode stop
2020-04-16 00:19:54,836 INFO  [Listener at localhost/34378] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:19:54,837 INFO  [Listener at localhost/34378] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 50
2020-04-16 00:19:54,838 INFO  [Listener at localhost/34378] namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 51 Total time for transactions(ms): 41 Number of transactions batched in Syncs: 14 Number of syncs: 38 SyncTimes(ms): 7 7 
2020-04-16 00:19:54,838 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@73393584] namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-16 00:19:54,840 INFO  [Listener at localhost/34378] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000051
2020-04-16 00:19:54,842 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@70e659aa] namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-16 00:19:54,843 INFO  [Listener at localhost/34378] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000051
2020-04-16 00:19:54,845 INFO  [FSEditLogAsync] namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-16 00:19:54,856 INFO  [CacheReplicationMonitor(1965723639)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-16 00:19:54,864 INFO  [Listener at localhost/34378] ipc.Server (Server.java:stop(3359)) - Stopping server on 36787
2020-04-16 00:19:54,868 INFO  [RedundancyMonitor] blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-04-16 00:19:54,868 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:19:54,876 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:19:54,909 INFO  [StorageInfoMonitor] blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-04-16 00:19:54,979 INFO  [Listener at localhost/34378] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:19:54,979 INFO  [Listener at localhost/34378] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-04-16 00:19:54,982 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33fe57a9{/,null,UNAVAILABLE}{/hdfs}
2020-04-16 00:19:54,985 INFO  [Listener at localhost/34378] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:19:54,985 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:19:54,986 INFO  [Listener at localhost/34378] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
msx-listener testfinished org.apache.hadoop.tools.TestHadoopArchives#testCopyToLocal
msx-listener writeFile testName is org.apache.hadoop.tools.TestHadoopArchives#testCopyToLocal
msx-listener succeed
msx-listener all testRunFinished
