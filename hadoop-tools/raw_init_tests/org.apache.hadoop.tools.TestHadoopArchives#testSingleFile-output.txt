msx-listener test started org.apache.hadoop.tools.TestHadoopArchives#testSingleFile
msx-listener unitTestCounterInClass = 0
2020-04-16 00:19:53,802 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-16 00:19:54,760 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:54,775 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:54,777 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:54,778 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:54,809 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:54,810 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:54,810 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:54,811 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:54,889 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:54,896 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-16 00:19:54,897 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:54,897 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:54,905 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:54,906 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:54
2020-04-16 00:19:54,909 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:54,911 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:54,914 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-16 00:19:54,915 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:54,945 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:54,946 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:54,957 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:54,958 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:54,958 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:54,959 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:54,960 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:54,960 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:54,961 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:54,961 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:54,961 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:54,961 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:54,961 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:55,008 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-04-16 00:19:55,008 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:55,009 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:55,009 INFO  [main] namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-04-16 00:19:55,034 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:55,034 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:55,035 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-16 00:19:55,035 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:55,041 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:55,042 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:55,042 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:55,042 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:55,050 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:55,054 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:55,061 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:55,061 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:55,062 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-16 00:19:55,062 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:55,077 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:55,078 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:55,078 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:55,084 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:55,085 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:55,087 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:55,087 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:55,088 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-16 00:19:55,088 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:55,141 INFO  [main] namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:19:55,158 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 has been successfully formatted.
2020-04-16 00:19:55,161 INFO  [main] common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 has been successfully formatted.
2020-04-16 00:19:55,227 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:55,232 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-16 00:19:55,389 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:55,398 INFO  [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2 of type IMAGE_AND_EDITS] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-04-16 00:19:55,427 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-16 00:19:55,432 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1635)) - createNameNode []
2020-04-16 00:19:55,539 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-04-16 00:19:56,110 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-04-16 00:19:56,110 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-16 00:19:56,118 INFO  [main] namenode.NameNode (NameNode.java:<init>(932)) - msx-hdfs NameNode init
2020-04-16 00:19:56,161 INFO  [main] namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-16 00:19:56,201 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2205a05d] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:19:56,222 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-16 00:19:56,244 INFO  [main] util.log (Log.java:initialized(192)) - Logging initialized @4103ms
2020-04-16 00:19:56,378 INFO  [main] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:56,385 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-16 00:19:56,404 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:56,414 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-16 00:19:56,415 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:56,417 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:56,474 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-16 00:19:56,475 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-16 00:19:56,489 INFO  [main] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37385
2020-04-16 00:19:56,491 INFO  [main] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:56,559 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:56,566 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:56,912 INFO  [main] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33fe57a9{/,file:///tmp/jetty-localhost-37385-hdfs-_-any-5314222917082716059.dir/webapp/,AVAILABLE}{/hdfs}
2020-04-16 00:19:56,926 INFO  [main] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:37385}
2020-04-16 00:19:56,927 INFO  [main] server.Server (Server.java:doStart(419)) - Started @4786ms
2020-04-16 00:19:56,939 INFO  [main] namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-04-16 00:19:56,940 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-04-16 00:19:56,941 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-04-16 00:19:56,941 INFO  [main] namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-04-16 00:19:56,941 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-04-16 00:19:56,942 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-04-16 00:19:56,942 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-04-16 00:19:56,950 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-04-16 00:19:56,951 INFO  [main] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:56,952 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-16 00:19:56,968 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-16 00:19:56,969 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-16 00:19:56,970 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 16 00:19:56
2020-04-16 00:19:56,970 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-16 00:19:56,970 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:56,971 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-16 00:19:56,971 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-16 00:19:56,987 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-04-16 00:19:56,987 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-04-16 00:19:56,994 INFO  [main] Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-16 00:19:57,001 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-16 00:19:57,001 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-16 00:19:57,002 INFO  [main] blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-16 00:19:57,002 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-04-16 00:19:57,002 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-04-16 00:19:57,002 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-04-16 00:19:57,002 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-04-16 00:19:57,003 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-04-16 00:19:57,010 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-04-16 00:19:57,010 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-04-16 00:19:57,011 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-16 00:19:57,011 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:57,012 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-16 00:19:57,012 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-16 00:19:57,019 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-04-16 00:19:57,020 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-04-16 00:19:57,020 INFO  [main] namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-04-16 00:19:57,020 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-04-16 00:19:57,020 INFO  [main] snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-16 00:19:57,029 INFO  [main] snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-16 00:19:57,029 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-16 00:19:57,030 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:57,030 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-16 00:19:57,030 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-16 00:19:57,032 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-16 00:19:57,032 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-16 00:19:57,033 INFO  [main] metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-16 00:19:57,033 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-04-16 00:19:57,033 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-16 00:19:57,033 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-16 00:19:57,033 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-16 00:19:57,034 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-16 00:19:57,034 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-16 00:19:57,049 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/in_use.lock acquired by nodename 5428@9716efb801d0
2020-04-16 00:19:57,056 INFO  [main] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/in_use.lock acquired by nodename 5428@9716efb801d0
2020-04-16 00:19:57,073 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current
2020-04-16 00:19:57,073 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current
2020-04-16 00:19:57,074 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-04-16 00:19:57,074 INFO  [main] namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-16 00:19:57,158 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-04-16 00:19:57,174 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-04-16 00:19:57,175 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-16 00:19:57,190 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-16 00:19:57,198 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-04-16 00:19:57,264 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-16 00:19:57,269 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 232 msecs
2020-04-16 00:19:57,501 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-04-16 00:19:57,562 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:19:57,593 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:19:58,102 INFO  [Listener at localhost/36960] namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:36960 to access this namenode/service.
2020-04-16 00:19:58,105 INFO  [Listener at localhost/36960] namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-16 00:19:58,229 INFO  [Listener at localhost/36960] namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-16 00:19:58,260 INFO  [Listener at localhost/36960] blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-04-16 00:19:58,262 INFO  [Listener at localhost/36960] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-04-16 00:19:58,262 INFO  [Listener at localhost/36960] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-16 00:19:58,263 INFO  [Listener at localhost/36960] hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-16 00:19:58,284 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-04-16 00:19:58,284 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-04-16 00:19:58,284 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-04-16 00:19:58,284 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-04-16 00:19:58,284 INFO  [Reconstruction Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-04-16 00:19:58,284 INFO  [Reconstruction Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2020-04-16 00:19:58,377 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:19:58,382 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:19:58,419 INFO  [Listener at localhost/36960] namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:36960
2020-04-16 00:19:58,422 INFO  [Listener at localhost/36960] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-04-16 00:19:58,422 INFO  [Listener at localhost/36960] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-04-16 00:19:58,439 INFO  [Listener at localhost/36960] namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 17 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-16 00:19:58,447 INFO  [Listener at localhost/36960] namenode.NameNode (NameNode.java:<init>(969)) - msx-hdfs NameNode start
2020-04-16 00:19:58,500 INFO  [Listener at localhost/36960] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:58,510 INFO  [CacheReplicationMonitor(593581395)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-16 00:19:58,770 INFO  [Listener at localhost/36960] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:19:58,811 INFO  [Listener at localhost/36960] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:19:58,906 INFO  [Listener at localhost/36960] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:19:58,906 INFO  [Listener at localhost/36960] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:19:58,923 INFO  [Listener at localhost/36960] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:58,928 INFO  [Listener at localhost/36960] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:19:58,933 INFO  [Listener at localhost/36960] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:19:58,935 INFO  [Listener at localhost/36960] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:19:58,943 INFO  [Listener at localhost/36960] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:19:58,978 INFO  [Listener at localhost/36960] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:35140
2020-04-16 00:19:58,988 INFO  [Listener at localhost/36960] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:19:58,988 INFO  [Listener at localhost/36960] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:19:59,100 INFO  [Listener at localhost/36960] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:19:59,133 INFO  [Listener at localhost/36960] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:19:59,139 INFO  [Listener at localhost/36960] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:19:59,155 INFO  [Listener at localhost/36960] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:19:59,156 INFO  [Listener at localhost/36960] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:19:59,157 INFO  [Listener at localhost/36960] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:19:59,169 INFO  [Listener at localhost/36960] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46663
2020-04-16 00:19:59,170 INFO  [Listener at localhost/36960] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:19:59,199 INFO  [Listener at localhost/36960] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@31198ceb{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:19:59,200 INFO  [Listener at localhost/36960] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75201592{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:19:59,530 INFO  [Listener at localhost/36960] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@450794b4{/,file:///tmp/jetty-localhost-46663-datanode-_-any-7174367131600196084.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:19:59,538 INFO  [Listener at localhost/36960] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@383192b4{HTTP/1.1,[http/1.1]}{localhost:46663}
2020-04-16 00:19:59,538 INFO  [Listener at localhost/36960] server.Server (Server.java:doStart(419)) - Started @7397ms
2020-04-16 00:20:00,849 INFO  [Listener at localhost/36960] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39847
2020-04-16 00:20:00,858 INFO  [Listener at localhost/36960] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:20:00,859 INFO  [Listener at localhost/36960] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:20:00,859 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@62515a47] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:20:00,888 INFO  [Listener at localhost/36960] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:20:00,893 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:20:00,910 INFO  [Listener at localhost/43265] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:43265
2020-04-16 00:20:00,939 INFO  [Listener at localhost/43265] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:20:00,941 INFO  [Listener at localhost/43265] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:20:00,981 INFO  [Listener at localhost/43265] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:20:00,985 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:20:00,960 INFO  [Thread-58] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36960 starting to offer service
2020-04-16 00:20:00,993 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:20:01,001 INFO  [Listener at localhost/43265] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:20:01,004 INFO  [Listener at localhost/43265] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:20:01,009 INFO  [Listener at localhost/43265] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:20:01,013 INFO  [Listener at localhost/43265] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:20:01,013 INFO  [Listener at localhost/43265] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:20:01,014 INFO  [Listener at localhost/43265] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:20:01,014 INFO  [Listener at localhost/43265] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:20:01,015 INFO  [Listener at localhost/43265] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:20:01,015 INFO  [Listener at localhost/43265] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:20:01,015 INFO  [Listener at localhost/43265] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:20:01,016 INFO  [Listener at localhost/43265] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:44148
2020-04-16 00:20:01,036 INFO  [Listener at localhost/43265] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:20:01,036 INFO  [Listener at localhost/43265] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:20:01,095 INFO  [Listener at localhost/43265] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:20:01,096 INFO  [Listener at localhost/43265] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:20:01,099 INFO  [Listener at localhost/43265] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:20:01,101 INFO  [Listener at localhost/43265] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:20:01,109 INFO  [Listener at localhost/43265] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:20:01,109 INFO  [Listener at localhost/43265] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:20:01,111 INFO  [Listener at localhost/43265] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36753
2020-04-16 00:20:01,111 INFO  [Listener at localhost/43265] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:20:01,113 INFO  [Listener at localhost/43265] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3eba57a7{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:20:01,115 INFO  [Listener at localhost/43265] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30feffc{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:20:01,480 INFO  [Listener at localhost/43265] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5f462e3b{/,file:///tmp/jetty-localhost-36753-datanode-_-any-7787978445692773829.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:20:01,485 INFO  [Listener at localhost/43265] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2303dff{HTTP/1.1,[http/1.1]}{localhost:36753}
2020-04-16 00:20:01,501 INFO  [Listener at localhost/43265] server.Server (Server.java:doStart(419)) - Started @9360ms
2020-04-16 00:20:01,615 INFO  [Listener at localhost/43265] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41567
2020-04-16 00:20:01,617 INFO  [Listener at localhost/43265] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:20:01,617 INFO  [Listener at localhost/43265] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:20:01,620 INFO  [Listener at localhost/43265] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:20:01,617 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58065f0c] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:20:01,625 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:20:01,634 INFO  [Listener at localhost/38091] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:38091
2020-04-16 00:20:01,671 INFO  [Listener at localhost/38091] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:20:01,671 INFO  [Listener at localhost/38091] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:20:01,672 INFO  [Thread-81] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36960 starting to offer service
2020-04-16 00:20:01,673 INFO  [Listener at localhost/38091] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:20:01,677 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:20:01,677 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:20:01,706 INFO  [Listener at localhost/38091] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:20:01,747 INFO  [Listener at localhost/38091] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:20:01,747 INFO  [Listener at localhost/38091] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:20:01,783 INFO  [Listener at localhost/38091] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-16 00:20:01,784 INFO  [Listener at localhost/38091] datanode.DataNode (DataNode.java:<init>(450)) - msx-hdfs DataNode init
2020-04-16 00:20:01,802 INFO  [Listener at localhost/38091] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:20:01,802 INFO  [Listener at localhost/38091] datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-16 00:20:01,803 INFO  [Listener at localhost/38091] datanode.DataNode (DataNode.java:<init>(502)) - Configured hostname is 127.0.0.1
2020-04-16 00:20:01,803 INFO  [Listener at localhost/38091] common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-16 00:20:01,804 INFO  [Listener at localhost/38091] datanode.DataNode (DataNode.java:startDataNode(1402)) - Starting DataNode with maxLockedMemory = 0
2020-04-16 00:20:01,804 INFO  [Listener at localhost/38091] datanode.DataNode (DataNode.java:initDataXceiver(1150)) - Opened streaming server at /127.0.0.1:33629
2020-04-16 00:20:01,805 INFO  [Listener at localhost/38091] datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-16 00:20:01,805 INFO  [Listener at localhost/38091] datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-16 00:20:01,817 INFO  [Listener at localhost/38091] server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-16 00:20:01,821 INFO  [Listener at localhost/38091] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-16 00:20:01,831 INFO  [Listener at localhost/38091] http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-16 00:20:01,831 INFO  [Thread-58] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36960
2020-04-16 00:20:01,839 INFO  [Thread-58] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:20:01,843 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/in_use.lock acquired by nodename 5428@9716efb801d0
2020-04-16 00:20:01,844 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 is not formatted for namespace 1570598134. Formatting...
2020-04-16 00:20:01,845 INFO  [Listener at localhost/38091] http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-16 00:20:01,846 INFO  [Listener at localhost/38091] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-16 00:20:01,846 INFO  [Listener at localhost/38091] http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-16 00:20:01,845 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3f005943-d3f4-4239-90c0-caba4bb376bf for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 
2020-04-16 00:20:01,850 INFO  [Thread-81] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36960
2020-04-16 00:20:01,851 INFO  [Thread-81] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:20:01,852 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/in_use.lock acquired by nodename 5428@9716efb801d0
2020-04-16 00:20:01,853 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 is not formatted for namespace 1570598134. Formatting...
2020-04-16 00:20:01,854 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7d98812e-87b0-4227-99e6-a41dbf71256d for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 
2020-04-16 00:20:01,856 INFO  [Thread-58] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/in_use.lock acquired by nodename 5428@9716efb801d0
2020-04-16 00:20:01,856 INFO  [Thread-81] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/in_use.lock acquired by nodename 5428@9716efb801d0
2020-04-16 00:20:01,857 INFO  [Thread-58] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 is not formatted for namespace 1570598134. Formatting...
2020-04-16 00:20:01,857 INFO  [Thread-81] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 is not formatted for namespace 1570598134. Formatting...
2020-04-16 00:20:01,857 INFO  [Thread-81] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-762f887a-c31f-4ca8-91f7-9ec6dbe28d38 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 
2020-04-16 00:20:01,857 INFO  [Thread-58] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-72f92deb-536a-4084-8f86-688da704b3ce for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 
2020-04-16 00:20:01,870 INFO  [Listener at localhost/38091] http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37197
2020-04-16 00:20:01,870 INFO  [Listener at localhost/38091] server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-16 00:20:01,895 INFO  [Listener at localhost/38091] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b60c3e{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,AVAILABLE}
2020-04-16 00:20:01,902 INFO  [Listener at localhost/38091] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6569dded{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-04-16 00:20:01,937 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:01,938 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:01,939 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1 and block pool id BP-1806308713-172.17.0.5-1586996395114 is not formatted. Formatting ...
2020-04-16 00:20:01,939 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1806308713-172.17.0.5-1586996395114 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1806308713-172.17.0.5-1586996395114/current
2020-04-16 00:20:01,945 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:01,945 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:01,946 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3 and block pool id BP-1806308713-172.17.0.5-1586996395114 is not formatted. Formatting ...
2020-04-16 00:20:01,946 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1806308713-172.17.0.5-1586996395114 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1806308713-172.17.0.5-1586996395114/current
2020-04-16 00:20:01,978 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:01,979 INFO  [Thread-58] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:01,979 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2 and block pool id BP-1806308713-172.17.0.5-1586996395114 is not formatted. Formatting ...
2020-04-16 00:20:01,979 INFO  [Thread-58] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1806308713-172.17.0.5-1586996395114 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1806308713-172.17.0.5-1586996395114/current
2020-04-16 00:20:01,986 INFO  [Thread-58] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=1570598134;bpid=BP-1806308713-172.17.0.5-1586996395114;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1570598134;c=1586996395114;bpid=BP-1806308713-172.17.0.5-1586996395114;dnuuid=null
2020-04-16 00:20:01,989 INFO  [Thread-58] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID 878e1773-6868-4713-bbf7-fd73f7190e03
2020-04-16 00:20:01,991 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:01,991 INFO  [Thread-81] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:01,991 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4 and block pool id BP-1806308713-172.17.0.5-1586996395114 is not formatted. Formatting ...
2020-04-16 00:20:01,992 INFO  [Thread-81] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1806308713-172.17.0.5-1586996395114 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1806308713-172.17.0.5-1586996395114/current
2020-04-16 00:20:01,994 INFO  [Thread-81] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=1570598134;bpid=BP-1806308713-172.17.0.5-1586996395114;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1570598134;c=1586996395114;bpid=BP-1806308713-172.17.0.5-1586996395114;dnuuid=null
2020-04-16 00:20:01,996 INFO  [Thread-81] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID 735afa23-3741-452e-9baa-3e39565531e5
2020-04-16 00:20:02,213 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7d98812e-87b0-4227-99e6-a41dbf71256d
2020-04-16 00:20:02,214 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, StorageType: DISK
2020-04-16 00:20:02,228 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-762f887a-c31f-4ca8-91f7-9ec6dbe28d38
2020-04-16 00:20:02,229 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, StorageType: DISK
2020-04-16 00:20:02,214 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3f005943-d3f4-4239-90c0-caba4bb376bf
2020-04-16 00:20:02,238 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, StorageType: DISK
2020-04-16 00:20:02,245 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-72f92deb-536a-4084-8f86-688da704b3ce
2020-04-16 00:20:02,247 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, StorageType: DISK
2020-04-16 00:20:02,247 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:20:02,248 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:20:02,254 INFO  [Listener at localhost/38091] handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a699efa{/,file:///tmp/jetty-localhost-37197-datanode-_-any-6003291926276538187.dir/webapp/,AVAILABLE}{/datanode}
2020-04-16 00:20:02,255 INFO  [Listener at localhost/38091] server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@38499e48{HTTP/1.1,[http/1.1]}{localhost:37197}
2020-04-16 00:20:02,256 INFO  [Listener at localhost/38091] server.Server (Server.java:doStart(419)) - Started @10114ms
2020-04-16 00:20:02,265 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:20:02,258 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:20:02,287 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:20:02,290 INFO  [Thread-81] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:20:02,296 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:20:02,297 INFO  [Thread-81] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:20:02,325 INFO  [Thread-81] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,323 INFO  [Thread-58] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:20:02,328 INFO  [Thread-58] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:20:02,328 INFO  [Thread-58] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,328 INFO  [Thread-102] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:20:02,328 INFO  [Thread-101] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:20:02,329 INFO  [Thread-103] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:20:02,330 INFO  [Thread-104] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:20:02,455 INFO  [Listener at localhost/38091] web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35212
2020-04-16 00:20:02,456 INFO  [Listener at localhost/38091] datanode.DataNode (DataNode.java:startDataNode(1430)) - dnUserName = root
2020-04-16 00:20:02,456 INFO  [org.apache.hadoop.util.JvmPauseMonitor$Monitor@17ae7628] util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-16 00:20:02,456 INFO  [Listener at localhost/38091] datanode.DataNode (DataNode.java:startDataNode(1431)) - supergroup = supergroup
2020-04-16 00:20:02,457 INFO  [Listener at localhost/38091] ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-04-16 00:20:02,458 INFO  [Socket Reader #1 for port 0] ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-04-16 00:20:02,461 INFO  [Listener at localhost/35248] datanode.DataNode (DataNode.java:initIpcServer(1036)) - Opened IPC server at /127.0.0.1:35248
2020-04-16 00:20:02,489 INFO  [Thread-104] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1806308713-172.17.0.5-1586996395114 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 159ms
2020-04-16 00:20:02,513 INFO  [Listener at localhost/35248] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-16 00:20:02,514 INFO  [Listener at localhost/35248] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-16 00:20:02,516 INFO  [Thread-103] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1806308713-172.17.0.5-1586996395114 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 186ms
2020-04-16 00:20:02,517 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1806308713-172.17.0.5-1586996395114: 189ms
2020-04-16 00:20:02,520 INFO  [Thread-115] datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36960 starting to offer service
2020-04-16 00:20:02,537 INFO  [Thread-102] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1806308713-172.17.0.5-1586996395114 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 208ms
2020-04-16 00:20:02,559 INFO  [Thread-116] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1...
2020-04-16 00:20:02,560 INFO  [Thread-116] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1806308713-172.17.0.5-1586996395114/current/replicas doesn't exist 
2020-04-16 00:20:02,560 INFO  [Thread-117] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2...
2020-04-16 00:20:02,560 INFO  [Listener at localhost/35248] datanode.DataNode (DataNode.java:runDatanodeDaemon(2662)) - msx-hdfs DataNode start
2020-04-16 00:20:02,585 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-04-16 00:20:02,589 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-04-16 00:20:02,560 INFO  [Thread-117] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1806308713-172.17.0.5-1586996395114/current/replicas doesn't exist 
2020-04-16 00:20:02,604 INFO  [Thread-101] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1806308713-172.17.0.5-1586996395114 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 275ms
2020-04-16 00:20:02,638 INFO  [Thread-117] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2: 78ms
2020-04-16 00:20:02,657 INFO  [Thread-115] datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36960
2020-04-16 00:20:02,665 INFO  [Thread-116] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1: 106ms
2020-04-16 00:20:02,666 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1806308713-172.17.0.5-1586996395114: 341ms
2020-04-16 00:20:02,689 INFO  [Thread-128] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3...
2020-04-16 00:20:02,690 INFO  [Thread-128] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1806308713-172.17.0.5-1586996395114/current/replicas doesn't exist 
2020-04-16 00:20:02,691 INFO  [Thread-128] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3: 1ms
2020-04-16 00:20:02,691 INFO  [Thread-129] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4...
2020-04-16 00:20:02,691 INFO  [Thread-129] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1806308713-172.17.0.5-1586996395114/current/replicas doesn't exist 
2020-04-16 00:20:02,692 INFO  [Thread-129] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4: 1ms
2020-04-16 00:20:02,692 INFO  [Thread-81] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114: 3ms
2020-04-16 00:20:02,669 INFO  [Thread-58] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114: 150ms
2020-04-16 00:20:02,668 INFO  [Thread-115] common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-16 00:20:02,709 INFO  [Thread-115] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/in_use.lock acquired by nodename 5428@9716efb801d0
2020-04-16 00:20:02,709 INFO  [Thread-115] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 is not formatted for namespace 1570598134. Formatting...
2020-04-16 00:20:02,709 INFO  [Thread-115] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-12e8a7c6-3f9f-4033-a666-2d0139341f87 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 
2020-04-16 00:20:02,711 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2
2020-04-16 00:20:02,712 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-72f92deb-536a-4084-8f86-688da704b3ce): finished scanning block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,713 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3
2020-04-16 00:20:02,714 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-7d98812e-87b0-4227-99e6-a41dbf71256d): finished scanning block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,716 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4
2020-04-16 00:20:02,717 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-762f887a-c31f-4ca8-91f7-9ec6dbe28d38): finished scanning block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,720 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1
2020-04-16 00:20:02,720 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-3f005943-d3f4-4239-90c0-caba4bb376bf): finished scanning block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,727 INFO  [Thread-115] common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/in_use.lock acquired by nodename 5428@9716efb801d0
2020-04-16 00:20:02,728 INFO  [Thread-115] common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 is not formatted for namespace 1570598134. Formatting...
2020-04-16 00:20:02,733 INFO  [Thread-115] common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0a514001-f208-4ae4-ab60-0767387b8a13 for directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 
2020-04-16 00:20:02,749 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-72f92deb-536a-4084-8f86-688da704b3ce): no suitable block pools found to scan.  Waiting 1814399960 ms.
2020-04-16 00:20:02,750 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-3f005943-d3f4-4239-90c0-caba4bb376bf): no suitable block pools found to scan.  Waiting 1814399959 ms.
2020-04-16 00:20:02,749 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-7d98812e-87b0-4227-99e6-a41dbf71256d): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-04-16 00:20:02,750 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-762f887a-c31f-4ca8-91f7-9ec6dbe28d38): no suitable block pools found to scan.  Waiting 1814399960 ms.
2020-04-16 00:20:02,763 INFO  [Thread-58] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 2:42 AM with interval of 21600000ms
2020-04-16 00:20:02,773 INFO  [Thread-81] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 2:02 AM with interval of 21600000ms
2020-04-16 00:20:02,806 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,806 INFO  [Thread-115] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,806 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5 and block pool id BP-1806308713-172.17.0.5-1586996395114 is not formatted. Formatting ...
2020-04-16 00:20:02,807 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1806308713-172.17.0.5-1586996395114 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1806308713-172.17.0.5-1586996395114/current
2020-04-16 00:20:02,830 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 878e1773-6868-4713-bbf7-fd73f7190e03) service to localhost/127.0.0.1:36960 beginning handshake with NN
2020-04-16 00:20:02,833 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 735afa23-3741-452e-9baa-3e39565531e5) service to localhost/127.0.0.1:36960 beginning handshake with NN
2020-04-16 00:20:02,855 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,861 INFO  [Thread-115] common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,861 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6 and block pool id BP-1806308713-172.17.0.5-1586996395114 is not formatted. Formatting ...
2020-04-16 00:20:02,861 INFO  [Thread-115] common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1806308713-172.17.0.5-1586996395114 directory /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1806308713-172.17.0.5-1586996395114/current
2020-04-16 00:20:02,869 INFO  [Thread-115] datanode.DataNode (DataNode.java:initStorage(1748)) - Setting up storage: nsid=1570598134;bpid=BP-1806308713-172.17.0.5-1586996395114;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1570598134;c=1586996395114;bpid=BP-1806308713-172.17.0.5-1586996395114;dnuuid=null
2020-04-16 00:20:02,871 INFO  [IPC Server handler 2 on default port 36960] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35140, datanodeUuid=878e1773-6868-4713-bbf7-fd73f7190e03, infoPort=39847, infoSecurePort=0, ipcPort=43265, storageInfo=lv=-57;cid=testClusterID;nsid=1570598134;c=1586996395114) storage 878e1773-6868-4713-bbf7-fd73f7190e03
2020-04-16 00:20:02,874 INFO  [IPC Server handler 2 on default port 36960] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35140
2020-04-16 00:20:02,875 INFO  [IPC Server handler 2 on default port 36960] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 878e1773-6868-4713-bbf7-fd73f7190e03 (127.0.0.1:35140).
2020-04-16 00:20:02,878 INFO  [IPC Server handler 0 on default port 36960] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44148, datanodeUuid=735afa23-3741-452e-9baa-3e39565531e5, infoPort=41567, infoSecurePort=0, ipcPort=38091, storageInfo=lv=-57;cid=testClusterID;nsid=1570598134;c=1586996395114) storage 735afa23-3741-452e-9baa-3e39565531e5
2020-04-16 00:20:02,878 INFO  [IPC Server handler 0 on default port 36960] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44148
2020-04-16 00:20:02,879 INFO  [Thread-115] datanode.DataNode (DataNode.java:checkDatanodeUuid(1548)) - Generated and persisted new Datanode UUID 81440589-fb84-43a4-8b6a-4ced7423774d
2020-04-16 00:20:02,883 INFO  [Thread-115] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-12e8a7c6-3f9f-4033-a666-2d0139341f87
2020-04-16 00:20:02,883 INFO  [Thread-115] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, StorageType: DISK
2020-04-16 00:20:02,885 INFO  [IPC Server handler 0 on default port 36960] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 735afa23-3741-452e-9baa-3e39565531e5 (127.0.0.1:44148).
2020-04-16 00:20:02,891 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 878e1773-6868-4713-bbf7-fd73f7190e03) service to localhost/127.0.0.1:36960 successfully registered with NN
2020-04-16 00:20:02,891 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36960 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:20:02,891 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 735afa23-3741-452e-9baa-3e39565531e5) service to localhost/127.0.0.1:36960 successfully registered with NN
2020-04-16 00:20:02,891 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36960 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:20:02,893 INFO  [Thread-115] impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0a514001-f208-4ae4-ab60-0767387b8a13
2020-04-16 00:20:02,896 INFO  [Thread-115] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, StorageType: DISK
2020-04-16 00:20:02,898 INFO  [Thread-115] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-16 00:20:02,899 INFO  [Thread-115] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:20:02,900 INFO  [Thread-115] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:20:02,900 INFO  [Thread-115] checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:20:02,900 INFO  [Thread-115] checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:20:02,925 INFO  [Thread-115] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:02,929 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:20:02,929 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:20:02,984 INFO  [IPC Server handler 1 on default port 36960] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7d98812e-87b0-4227-99e6-a41dbf71256d for DN 127.0.0.1:44148
2020-04-16 00:20:02,985 INFO  [IPC Server handler 1 on default port 36960] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-762f887a-c31f-4ca8-91f7-9ec6dbe28d38 for DN 127.0.0.1:44148
2020-04-16 00:20:02,998 INFO  [IPC Server handler 3 on default port 36960] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3f005943-d3f4-4239-90c0-caba4bb376bf for DN 127.0.0.1:35140
2020-04-16 00:20:03,002 INFO  [IPC Server handler 3 on default port 36960] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-72f92deb-536a-4084-8f86-688da704b3ce for DN 127.0.0.1:35140
2020-04-16 00:20:03,015 INFO  [Thread-139] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1806308713-172.17.0.5-1586996395114 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 85ms
2020-04-16 00:20:03,053 INFO  [Thread-138] impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1806308713-172.17.0.5-1586996395114 on /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 124ms
2020-04-16 00:20:03,054 INFO  [Thread-115] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1806308713-172.17.0.5-1586996395114: 128ms
2020-04-16 00:20:03,057 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6...
2020-04-16 00:20:03,057 INFO  [Thread-143] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1806308713-172.17.0.5-1586996395114/current/replicas doesn't exist 
2020-04-16 00:20:03,059 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6: 2ms
2020-04-16 00:20:03,061 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5...
2020-04-16 00:20:03,061 INFO  [Thread-142] impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1806308713-172.17.0.5-1586996395114/current/replicas doesn't exist 
2020-04-16 00:20:03,062 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5: 0ms
2020-04-16 00:20:03,069 INFO  [Thread-115] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1806308713-172.17.0.5-1586996395114: 15ms
2020-04-16 00:20:03,070 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5
2020-04-16 00:20:03,070 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-12e8a7c6-3f9f-4033-a666-2d0139341f87): finished scanning block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:03,071 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-12e8a7c6-3f9f-4033-a666-2d0139341f87): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-16 00:20:03,072 INFO  [Thread-115] datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 4/16/20 1:52 AM with interval of 21600000ms
2020-04-16 00:20:03,074 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 81440589-fb84-43a4-8b6a-4ced7423774d) service to localhost/127.0.0.1:36960 beginning handshake with NN
2020-04-16 00:20:03,089 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1806308713-172.17.0.5-1586996395114 on volume /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6
2020-04-16 00:20:03,090 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-0a514001-f208-4ae4-ab60-0767387b8a13): finished scanning block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:03,091 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-0a514001-f208-4ae4-ab60-0767387b8a13): no suitable block pools found to scan.  Waiting 1814399980 ms.
2020-04-16 00:20:03,095 INFO  [IPC Server handler 4 on default port 36960] hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33629, datanodeUuid=81440589-fb84-43a4-8b6a-4ced7423774d, infoPort=35212, infoSecurePort=0, ipcPort=35248, storageInfo=lv=-57;cid=testClusterID;nsid=1570598134;c=1586996395114) storage 81440589-fb84-43a4-8b6a-4ced7423774d
2020-04-16 00:20:03,095 INFO  [IPC Server handler 4 on default port 36960] net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33629
2020-04-16 00:20:03,095 INFO  [IPC Server handler 4 on default port 36960] blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 81440589-fb84-43a4-8b6a-4ced7423774d (127.0.0.1:33629).
2020-04-16 00:20:03,097 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 81440589-fb84-43a4-8b6a-4ced7423774d) service to localhost/127.0.0.1:36960 successfully registered with NN
2020-04-16 00:20:03,125 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36960 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-16 00:20:03,128 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa157f38716c42567: Processing first storage report for DS-7d98812e-87b0-4227-99e6-a41dbf71256d from datanode 735afa23-3741-452e-9baa-3e39565531e5
2020-04-16 00:20:03,159 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa157f38716c42567: from storage DS-7d98812e-87b0-4227-99e6-a41dbf71256d node DatanodeRegistration(127.0.0.1:44148, datanodeUuid=735afa23-3741-452e-9baa-3e39565531e5, infoPort=41567, infoSecurePort=0, ipcPort=38091, storageInfo=lv=-57;cid=testClusterID;nsid=1570598134;c=1586996395114), blocks: 0, hasStaleStorage: true, processing time: 30 msecs, invalidatedBlocks: 0
2020-04-16 00:20:03,159 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x971592a35280e22f: Processing first storage report for DS-72f92deb-536a-4084-8f86-688da704b3ce from datanode 878e1773-6868-4713-bbf7-fd73f7190e03
2020-04-16 00:20:03,159 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x971592a35280e22f: from storage DS-72f92deb-536a-4084-8f86-688da704b3ce node DatanodeRegistration(127.0.0.1:35140, datanodeUuid=878e1773-6868-4713-bbf7-fd73f7190e03, infoPort=39847, infoSecurePort=0, ipcPort=43265, storageInfo=lv=-57;cid=testClusterID;nsid=1570598134;c=1586996395114), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:20:03,160 INFO  [IPC Server handler 6 on default port 36960] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-12e8a7c6-3f9f-4033-a666-2d0139341f87 for DN 127.0.0.1:33629
2020-04-16 00:20:03,160 INFO  [IPC Server handler 6 on default port 36960] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0a514001-f208-4ae4-ab60-0767387b8a13 for DN 127.0.0.1:33629
2020-04-16 00:20:03,161 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x971592a35280e22f: Processing first storage report for DS-3f005943-d3f4-4239-90c0-caba4bb376bf from datanode 878e1773-6868-4713-bbf7-fd73f7190e03
2020-04-16 00:20:03,161 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x971592a35280e22f: from storage DS-3f005943-d3f4-4239-90c0-caba4bb376bf node DatanodeRegistration(127.0.0.1:35140, datanodeUuid=878e1773-6868-4713-bbf7-fd73f7190e03, infoPort=39847, infoSecurePort=0, ipcPort=43265, storageInfo=lv=-57;cid=testClusterID;nsid=1570598134;c=1586996395114), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:20:03,162 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa157f38716c42567: Processing first storage report for DS-762f887a-c31f-4ca8-91f7-9ec6dbe28d38 from datanode 735afa23-3741-452e-9baa-3e39565531e5
2020-04-16 00:20:03,162 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa157f38716c42567: from storage DS-762f887a-c31f-4ca8-91f7-9ec6dbe28d38 node DatanodeRegistration(127.0.0.1:44148, datanodeUuid=735afa23-3741-452e-9baa-3e39565531e5, infoPort=41567, infoSecurePort=0, ipcPort=38091, storageInfo=lv=-57;cid=testClusterID;nsid=1570598134;c=1586996395114), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-16 00:20:03,178 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7de6bb19424cbf3e: Processing first storage report for DS-12e8a7c6-3f9f-4033-a666-2d0139341f87 from datanode 81440589-fb84-43a4-8b6a-4ced7423774d
2020-04-16 00:20:03,178 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7de6bb19424cbf3e: from storage DS-12e8a7c6-3f9f-4033-a666-2d0139341f87 node DatanodeRegistration(127.0.0.1:33629, datanodeUuid=81440589-fb84-43a4-8b6a-4ced7423774d, infoPort=35212, infoSecurePort=0, ipcPort=35248, storageInfo=lv=-57;cid=testClusterID;nsid=1570598134;c=1586996395114), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-16 00:20:03,178 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7de6bb19424cbf3e: Processing first storage report for DS-0a514001-f208-4ae4-ab60-0767387b8a13 from datanode 81440589-fb84-43a4-8b6a-4ced7423774d
2020-04-16 00:20:03,179 INFO  [Block report processor] BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7de6bb19424cbf3e: from storage DS-0a514001-f208-4ae4-ab60-0767387b8a13 node DatanodeRegistration(127.0.0.1:33629, datanodeUuid=81440589-fb84-43a4-8b6a-4ced7423774d, infoPort=35212, infoSecurePort=0, ipcPort=35248, storageInfo=lv=-57;cid=testClusterID;nsid=1570598134;c=1586996395114), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-16 00:20:03,207 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x971592a35280e22f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 166 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:20:03,207 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:03,213 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa157f38716c42567,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 167 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:20:03,213 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:03,214 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7de6bb19424cbf3e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 39 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-16 00:20:03,214 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:03,528 INFO  [IPC Server handler 8 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-16 00:20:03,551 INFO  [Listener at localhost/35248] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-04-16 00:20:03,593 INFO  [IPC Server handler 2 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive	dst=null	perm=null	proto=rpc
2020-04-16 00:20:03,604 INFO  [IPC Server handler 0 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/input	dst=null	perm=null	proto=rpc
2020-04-16 00:20:03,631 INFO  [IPC Server handler 3 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/input	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:20:03,725 INFO  [IPC Server handler 1 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/a	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:03,802 INFO  [IPC Server handler 4 on default port 36960] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:44148, 127.0.0.1:33629, 127.0.0.1:35140 for /user/root/input/a
2020-04-16 00:20:03,835 INFO  [Thread-150] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:03,939 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:52856 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001 src: /127.0.0.1:52856 dest: /127.0.0.1:44148
2020-04-16 00:20:03,966 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:52856 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:03,976 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48660 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001 src: /127.0.0.1:48660 dest: /127.0.0.1:33629
2020-04-16 00:20:03,979 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48660 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:03,982 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37454 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001 src: /127.0.0.1:37454 dest: /127.0.0.1:35140
2020-04-16 00:20:04,078 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37454, dest: /127.0.0.1:35140, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 878e1773-6868-4713-bbf7-fd73f7190e03, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, duration(ns): 76579689
2020-04-16 00:20:04,078 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:04,091 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35140]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48660, dest: /127.0.0.1:33629, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 81440589-fb84-43a4-8b6a-4ced7423774d, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, duration(ns): 89381601
2020-04-16 00:20:04,095 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35140]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35140] terminating
2020-04-16 00:20:04,102 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33629, 127.0.0.1:35140]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52856, dest: /127.0.0.1:44148, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 735afa23-3741-452e-9baa-3e39565531e5, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, duration(ns): 101188591
2020-04-16 00:20:04,103 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33629, 127.0.0.1:35140]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33629, 127.0.0.1:35140] terminating
2020-04-16 00:20:04,144 INFO  [IPC Server handler 7 on default port 36960] namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/input/a
2020-04-16 00:20:04,559 INFO  [IPC Server handler 2 on default port 36960] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/a is closed by DFSClient_NONMAPREDUCE_-535871073_1
2020-04-16 00:20:04,564 INFO  [IPC Server handler 0 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/b	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:04,573 INFO  [IPC Server handler 3 on default port 36960] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:33629, 127.0.0.1:35140, 127.0.0.1:44148 for /user/root/input/b
2020-04-16 00:20:04,578 INFO  [Thread-159] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,586 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48700 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002 src: /127.0.0.1:48700 dest: /127.0.0.1:33629
2020-04-16 00:20:04,587 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48700 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,594 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37492 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002 src: /127.0.0.1:37492 dest: /127.0.0.1:35140
2020-04-16 00:20:04,600 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37492 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,623 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:52916 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002 src: /127.0.0.1:52916 dest: /127.0.0.1:44148
2020-04-16 00:20:04,676 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52916, dest: /127.0.0.1:44148, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 735afa23-3741-452e-9baa-3e39565531e5, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, duration(ns): 42705916
2020-04-16 00:20:04,676 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:04,697 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44148]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37492, dest: /127.0.0.1:35140, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 878e1773-6868-4713-bbf7-fd73f7190e03, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, duration(ns): 59474830
2020-04-16 00:20:04,698 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44148]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44148] terminating
2020-04-16 00:20:04,746 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:44148]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48700, dest: /127.0.0.1:33629, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 81440589-fb84-43a4-8b6a-4ced7423774d, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, duration(ns): 107761416
2020-04-16 00:20:04,747 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:44148]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:44148] terminating
2020-04-16 00:20:04,767 INFO  [IPC Server handler 9 on default port 36960] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/b is closed by DFSClient_NONMAPREDUCE_-535871073_1
2020-04-16 00:20:04,781 INFO  [IPC Server handler 5 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/c	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:04,791 INFO  [IPC Server handler 7 on default port 36960] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:33629, 127.0.0.1:35140, 127.0.0.1:44148 for /user/root/input/c
2020-04-16 00:20:04,793 INFO  [Thread-167] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,814 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48716 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003 src: /127.0.0.1:48716 dest: /127.0.0.1:33629
2020-04-16 00:20:04,815 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48716 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,826 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37508 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003 src: /127.0.0.1:37508 dest: /127.0.0.1:35140
2020-04-16 00:20:04,827 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37508 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:04,838 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:52934 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003 src: /127.0.0.1:52934 dest: /127.0.0.1:44148
2020-04-16 00:20:04,897 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52934, dest: /127.0.0.1:44148, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 735afa23-3741-452e-9baa-3e39565531e5, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, duration(ns): 51078546
2020-04-16 00:20:04,897 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:04,903 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44148]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37508, dest: /127.0.0.1:35140, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 878e1773-6868-4713-bbf7-fd73f7190e03, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, duration(ns): 55846825
2020-04-16 00:20:04,912 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:44148]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48716, dest: /127.0.0.1:33629, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 81440589-fb84-43a4-8b6a-4ced7423774d, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, duration(ns): 66314798
2020-04-16 00:20:04,913 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:44148]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:44148] terminating
2020-04-16 00:20:04,913 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44148]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44148] terminating
2020-04-16 00:20:04,926 INFO  [IPC Server handler 2 on default port 36960] namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741827_1003 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/input/c
2020-04-16 00:20:05,338 INFO  [IPC Server handler 1 on default port 36960] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/c is closed by DFSClient_NONMAPREDUCE_-535871073_1
2020-04-16 00:20:05,344 INFO  [IPC Server handler 4 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/input/dir1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:20:05,349 INFO  [IPC Server handler 6 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/input/dir1/a	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:05,361 INFO  [IPC Server handler 9 on default port 36960] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:33629, 127.0.0.1:35140, 127.0.0.1:44148 for /user/root/input/dir1/a
2020-04-16 00:20:05,367 INFO  [Thread-175] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:05,377 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48768 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004 src: /127.0.0.1:48768 dest: /127.0.0.1:33629
2020-04-16 00:20:05,379 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48768 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:05,389 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37560 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004 src: /127.0.0.1:37560 dest: /127.0.0.1:35140
2020-04-16 00:20:05,390 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37560 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:05,401 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:52984 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004 src: /127.0.0.1:52984 dest: /127.0.0.1:44148
2020-04-16 00:20:05,456 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52984, dest: /127.0.0.1:44148, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 735afa23-3741-452e-9baa-3e39565531e5, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, duration(ns): 46427277
2020-04-16 00:20:05,458 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:05,470 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44148]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37560, dest: /127.0.0.1:35140, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 878e1773-6868-4713-bbf7-fd73f7190e03, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, duration(ns): 65600797
2020-04-16 00:20:05,470 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44148]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44148] terminating
2020-04-16 00:20:05,482 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:44148]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48768, dest: /127.0.0.1:33629, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 81440589-fb84-43a4-8b6a-4ced7423774d, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, duration(ns): 53705150
2020-04-16 00:20:05,482 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:44148]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:44148] terminating
2020-04-16 00:20:05,495 INFO  [IPC Server handler 2 on default port 36960] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/input/dir1/a is closed by DFSClient_NONMAPREDUCE_-535871073_1
lsr root=hdfs://localhost:36960/user/root/input/dir1
2020-04-16 00:20:05,601 INFO  [IPC Server handler 0 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,617 INFO  [IPC Server handler 3 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
lsr results:
lsr: DEPRECATED: Please use 'ls -R' instead.
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 hdfs://localhost:36960/user/root/input/dir1/a

lsr paths = [/a]
originalPaths: [/a]
parentPathStr = /user/root/input/dir1
2020-04-16 00:20:05,633 INFO  [IPC Server handler 1 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,642 INFO  [IPC Server handler 4 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,651 INFO  [IPC Server handler 6 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,654 INFO  [IPC Server handler 9 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,672 INFO  [Listener at localhost/35248] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:05,703 INFO  [IPC Server handler 5 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:05,723 INFO  [Listener at localhost/35248] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:05,734 INFO  [Listener at localhost/35248] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:05,787 INFO  [Listener at localhost/35248] mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:1
2020-04-16 00:20:05,978 INFO  [Listener at localhost/35248] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1267532488_0001
2020-04-16 00:20:05,978 INFO  [Listener at localhost/35248] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2020-04-16 00:20:06,168 INFO  [Listener at localhost/35248] mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2020-04-16 00:20:06,170 INFO  [Listener at localhost/35248] mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1267532488_0001
2020-04-16 00:20:06,174 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2020-04-16 00:20:06,187 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter
2020-04-16 00:20:06,196 INFO  [Thread-183] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:20:06,196 INFO  [Thread-183] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:20:06,206 INFO  [IPC Server handler 0 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/archive/foo.har/_temporary/0	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-16 00:20:06,267 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2020-04-16 00:20:06,271 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1267532488_0001_m_000000_0
2020-04-16 00:20:06,311 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:20:06,317 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:20:06,397 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2020-04-16 00:20:06,399 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:updateJobWithSplit(497)) - Processing split: file:/tmp/hadoop/mapred/staging/root37414530/.staging/har_2vnhj1/_har_src_files:0+193
2020-04-16 00:20:06,416 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:runOldMapper(451)) - numReduceTasks: 1
2020-04-16 00:20:06,521 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:setEquator(1219)) - (EQUATOR) 0 kvi 26214396(104857584)
2020-04-16 00:20:06,521 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1012)) - mapreduce.task.io.sort.mb: 100
2020-04-16 00:20:06,521 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1013)) - soft limit at 83886080
2020-04-16 00:20:06,521 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1014)) - bufstart = 0; bufvoid = 104857600
2020-04-16 00:20:06,522 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:init(1015)) - kvstart = 26214396; length = 6553600
2020-04-16 00:20:06,524 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:createSortingCollector(409)) - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2020-04-16 00:20:06,533 INFO  [IPC Server handler 3 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_m_000000_0/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:06,545 INFO  [IPC Server handler 1 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_m_000000_0/part-0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:06,577 INFO  [IPC Server handler 4 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1	dst=null	perm=null	proto=rpc
2020-04-16 00:20:06,585 INFO  [IPC Server handler 6 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/input/dir1/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:06,603 INFO  [IPC Server handler 9 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/input/dir1/a	dst=null	perm=null	proto=rpc
2020-04-16 00:20:06,639 INFO  [LocalJobRunner Map Task Executor #0] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:06,702 INFO  [IPC Server handler 5 on default port 36960] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:44148, 127.0.0.1:33629, 127.0.0.1:35140 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_m_000000_0/part-0
2020-04-16 00:20:06,710 INFO  [Thread-187] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:06,741 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:52992 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005 src: /127.0.0.1:52992 dest: /127.0.0.1:44148
2020-04-16 00:20:06,743 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:52992 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:06,746 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48782 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005 src: /127.0.0.1:48782 dest: /127.0.0.1:33629
2020-04-16 00:20:06,747 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48782 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:06,754 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37574 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005 src: /127.0.0.1:37574 dest: /127.0.0.1:35140
2020-04-16 00:20:06,819 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37574, dest: /127.0.0.1:35140, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 878e1773-6868-4713-bbf7-fd73f7190e03, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, duration(ns): 62549370
2020-04-16 00:20:06,820 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:06,845 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35140]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48782, dest: /127.0.0.1:33629, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 81440589-fb84-43a4-8b6a-4ced7423774d, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, duration(ns): 60046001
2020-04-16 00:20:06,846 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35140]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35140] terminating
2020-04-16 00:20:06,871 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33629, 127.0.0.1:35140]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52992, dest: /127.0.0.1:44148, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 735afa23-3741-452e-9baa-3e39565531e5, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, duration(ns): 95868896
2020-04-16 00:20:06,872 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33629, 127.0.0.1:35140]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33629, 127.0.0.1:35140] terminating
2020-04-16 00:20:06,876 INFO  [IPC Server handler 0 on default port 36960] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_m_000000_0/part-0 is closed by DFSClient_NONMAPREDUCE_-535871073_1
2020-04-16 00:20:06,903 INFO  [IPC Server handler 3 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_m_000000_0/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:06,911 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2020-04-16 00:20:06,911 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1476)) - Starting flush of map output
2020-04-16 00:20:06,911 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1498)) - Spilling map output
2020-04-16 00:20:06,912 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1499)) - bufstart = 0; bufend = 113; bufvoid = 104857600
2020-04-16 00:20:06,912 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:flush(1501)) - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2020-04-16 00:20:06,927 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask (MapTask.java:sortAndSpill(1696)) - Finished spill 0
2020-04-16 00:20:06,942 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:done(1244)) - Task:attempt_local1267532488_0001_m_000000_0 is done. And is in the process of committing
2020-04-16 00:20:06,945 INFO  [IPC Server handler 1 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:06,957 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2020-04-16 00:20:06,958 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:commit(1421)) - Task attempt_local1267532488_0001_m_000000_0 is allowed to commit now
2020-04-16 00:20:06,960 INFO  [IPC Server handler 4 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:06,966 INFO  [IPC Server handler 6 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:06,971 INFO  [IPC Server handler 9 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_m_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:06,981 INFO  [IPC Server handler 5 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,009 INFO  [IPC Server handler 7 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_m_000000_0/part-0	dst=/user/root/archive/foo.har/part-0	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:07,014 INFO  [LocalJobRunner Map Task Executor #0] output.FileOutputCommitter (FileOutputCommitter.java:commitTask(606)) - Saved output of task 'attempt_local1267532488_0001_m_000000_0' to hdfs://localhost:36960/user/root/archive/foo.har
2020-04-16 00:20:07,023 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file hdfs://localhost:36960/user/root/input/dir1/a to archive.
2020-04-16 00:20:07,024 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1267532488_0001_m_000000_0' done.
2020-04-16 00:20:07,027 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1267532488_0001_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=62194
		FILE: Number of bytes written=589888
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1
		HDFS: Number of bytes written=5
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=13
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=113
		Map output materialized bytes=123
		Input split bytes=131
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2058354688
	File Input Format Counters 
		Bytes Read=205
2020-04-16 00:20:07,027 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1267532488_0001_m_000000_0
2020-04-16 00:20:07,034 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2020-04-16 00:20:07,061 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for reduce tasks
2020-04-16 00:20:07,065 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:run(330)) - Starting task: attempt_local1267532488_0001_r_000000_0
2020-04-16 00:20:07,304 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:<init>(141)) - File Output Committer Algorithm version is 2
2020-04-16 00:20:07,305 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:<init>(156)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2020-04-16 00:20:07,305 INFO  [Listener at localhost/35248] mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1267532488_0001 running in uber mode : false
2020-04-16 00:20:07,314 INFO  [Listener at localhost/35248] mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2020-04-16 00:20:07,316 INFO  [pool-49-thread-1] mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2020-04-16 00:20:07,354 INFO  [pool-49-thread-1] mapred.ReduceTask (ReduceTask.java:run(363)) - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c5d83f7
2020-04-16 00:20:07,367 INFO  [pool-49-thread-1] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2020-04-16 00:20:07,384 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:<init>(208)) - MergerManager: memoryLimit=1440848256, maxSingleShuffleLimit=360212064, mergeThreshold=950959872, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2020-04-16 00:20:07,388 INFO  [EventFetcher for fetching Map Completion Events] reduce.EventFetcher (EventFetcher.java:run(61)) - attempt_local1267532488_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2020-04-16 00:20:07,436 INFO  [localfetcher#1] reduce.LocalFetcher (LocalFetcher.java:copyMapOutput(145)) - localfetcher#1 about to shuffle output of map attempt_local1267532488_0001_m_000000_0 decomp: 119 len: 123 to MEMORY
2020-04-16 00:20:07,440 INFO  [localfetcher#1] reduce.InMemoryMapOutput (InMemoryMapOutput.java:doShuffle(94)) - Read 119 bytes from map-output for attempt_local1267532488_0001_m_000000_0
2020-04-16 00:20:07,440 INFO  [localfetcher#1] reduce.MergeManagerImpl (MergeManagerImpl.java:closeInMemoryFile(323)) - closeInMemoryFile -> map-output of size: 119, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->119
2020-04-16 00:20:07,449 INFO  [EventFetcher for fetching Map Completion Events] reduce.EventFetcher (EventFetcher.java:run(76)) - EventFetcher is interrupted.. Returning
2020-04-16 00:20:07,450 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:20:07,451 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(695)) - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2020-04-16 00:20:07,475 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(606)) - Merging 1 sorted segments
2020-04-16 00:20:07,476 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(705)) - Down to the last merge-pass, with 1 segments left of total size: 113 bytes
2020-04-16 00:20:07,482 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(762)) - Merged 1 segments, 119 bytes to disk to satisfy reduce memory limit
2020-04-16 00:20:07,483 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(792)) - Merging 1 files, 123 bytes from disk
2020-04-16 00:20:07,491 INFO  [pool-49-thread-1] reduce.MergeManagerImpl (MergeManagerImpl.java:finalMerge(807)) - Merging 0 segments, 0 bytes from memory into reduce
2020-04-16 00:20:07,492 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(606)) - Merging 1 sorted segments
2020-04-16 00:20:07,493 INFO  [pool-49-thread-1] mapred.Merger (Merger.java:merge(705)) - Down to the last merge-pass, with 1 segments left of total size: 113 bytes
2020-04-16 00:20:07,494 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:20:07,497 INFO  [IPC Server handler 8 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,503 INFO  [IPC Server handler 2 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,510 INFO  [IPC Server handler 0 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_index	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:07,531 INFO  [IPC Server handler 3 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_masterindex	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:07,539 INFO  [IPC Server handler 1 on default port 36960] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:33629, 127.0.0.1:44148, 127.0.0.1:35140 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_masterindex
2020-04-16 00:20:07,544 INFO  [Thread-203] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:07,554 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48788 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006 src: /127.0.0.1:48788 dest: /127.0.0.1:33629
2020-04-16 00:20:07,555 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48788 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:07,558 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:53002 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006 src: /127.0.0.1:53002 dest: /127.0.0.1:44148
2020-04-16 00:20:07,560 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:53002 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:07,572 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37582 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006 src: /127.0.0.1:37582 dest: /127.0.0.1:35140
2020-04-16 00:20:07,649 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37582, dest: /127.0.0.1:35140, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 878e1773-6868-4713-bbf7-fd73f7190e03, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, duration(ns): 49576902
2020-04-16 00:20:07,649 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:07,658 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35140]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53002, dest: /127.0.0.1:44148, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 735afa23-3741-452e-9baa-3e39565531e5, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, duration(ns): 66071818
2020-04-16 00:20:07,659 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35140]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35140] terminating
2020-04-16 00:20:07,662 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44148, 127.0.0.1:35140]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48788, dest: /127.0.0.1:33629, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 81440589-fb84-43a4-8b6a-4ced7423774d, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, duration(ns): 69752347
2020-04-16 00:20:07,663 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44148, 127.0.0.1:35140]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44148, 127.0.0.1:35140] terminating
2020-04-16 00:20:07,666 INFO  [IPC Server handler 5 on default port 36960] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_masterindex is closed by DFSClient_NONMAPREDUCE_-535871073_1
2020-04-16 00:20:07,678 INFO  [IPC Server handler 7 on default port 36960] hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:44148, 127.0.0.1:35140, 127.0.0.1:33629 for /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_index
2020-04-16 00:20:07,681 INFO  [Thread-202] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:07,689 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:53006 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007 src: /127.0.0.1:53006 dest: /127.0.0.1:44148
2020-04-16 00:20:07,690 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:53006 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:07,692 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37586 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007 src: /127.0.0.1:37586 dest: /127.0.0.1:35140
2020-04-16 00:20:07,696 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:37586 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007]] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:07,697 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-535871073_1 at /127.0.0.1:48798 [Receiving block BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007]] datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007 src: /127.0.0.1:48798 dest: /127.0.0.1:33629
2020-04-16 00:20:07,735 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, type=LAST_IN_PIPELINE] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48798, dest: /127.0.0.1:33629, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 81440589-fb84-43a4-8b6a-4ced7423774d, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, duration(ns): 28945276
2020-04-16 00:20:07,735 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, type=LAST_IN_PIPELINE] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-16 00:20:07,761 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33629]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37586, dest: /127.0.0.1:35140, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 878e1773-6868-4713-bbf7-fd73f7190e03, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, duration(ns): 29321393
2020-04-16 00:20:07,762 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33629]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33629] terminating
2020-04-16 00:20:07,766 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:33629]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53006, dest: /127.0.0.1:44148, bytes: 105, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-535871073_1, offset: 0, srvID: 735afa23-3741-452e-9baa-3e39565531e5, blockid: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, duration(ns): 59766369
2020-04-16 00:20:07,766 INFO  [PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:33629]] datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1806308713-172.17.0.5-1586996395114:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35140, 127.0.0.1:33629] terminating
2020-04-16 00:20:07,774 INFO  [IPC Server handler 2 on default port 36960] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_index is closed by DFSClient_NONMAPREDUCE_-535871073_1
2020-04-16 00:20:07,782 INFO  [IPC Server handler 3 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,793 INFO  [IPC Server handler 4 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,796 INFO  [pool-49-thread-1] mapred.Task (Task.java:done(1244)) - Task:attempt_local1267532488_0001_r_000000_0 is done. And is in the process of committing
2020-04-16 00:20:07,801 INFO  [IPC Server handler 6 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,806 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 1 / 1 copied.
2020-04-16 00:20:07,806 INFO  [pool-49-thread-1] mapred.Task (Task.java:commit(1421)) - Task attempt_local1267532488_0001_r_000000_0 is allowed to commit now
2020-04-16 00:20:07,809 INFO  [IPC Server handler 9 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,818 INFO  [IPC Server handler 5 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,820 INFO  [IPC Server handler 7 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,822 INFO  [IPC Server handler 8 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,824 INFO  [IPC Server handler 7 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_index	dst=/user/root/archive/foo.har/_index	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:07,829 INFO  [IPC Server handler 0 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,834 INFO  [IPC Server handler 3 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/user/root/archive/foo.har/_temporary/0/_temporary/attempt_local1267532488_0001_r_000000_0/_masterindex	dst=/user/root/archive/foo.har/_masterindex	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:07,837 INFO  [pool-49-thread-1] output.FileOutputCommitter (FileOutputCommitter.java:commitTask(606)) - Saved output of task 'attempt_local1267532488_0001_r_000000_0' to hdfs://localhost:36960/user/root/archive/foo.har
2020-04-16 00:20:07,850 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - reduce > reduce
2020-04-16 00:20:07,850 INFO  [pool-49-thread-1] mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1267532488_0001_r_000000_0' done.
2020-04-16 00:20:07,851 INFO  [pool-49-thread-1] mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1267532488_0001_r_000000_0: Counters: 30
	File System Counters
		FILE: Number of bytes read=62472
		FILE: Number of bytes written=590011
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1
		HDFS: Number of bytes written=127
		HDFS: Number of read operations=21
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=21
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=123
		Reduce input records=2
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=173
		Total committed heap usage (bytes)=2058354688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=0
2020-04-16 00:20:07,851 INFO  [pool-49-thread-1] mapred.LocalJobRunner (LocalJobRunner.java:run(353)) - Finishing task: attempt_local1267532488_0001_r_000000_0
2020-04-16 00:20:07,852 INFO  [Thread-183] mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - reduce task executor complete.
2020-04-16 00:20:07,862 INFO  [IPC Server handler 1 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/user/root/archive/foo.har/_temporary	dst=null	perm=null	proto=rpc
2020-04-16 00:20:07,865 INFO  [IPC Server handler 1 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/archive/foo.har/_SUCCESS	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-16 00:20:07,870 INFO  [IPC Server handler 6 on default port 36960] hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /user/root/archive/foo.har/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-535871073_1
2020-04-16 00:20:08,337 INFO  [Listener at localhost/35248] mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 100%
2020-04-16 00:20:08,338 INFO  [Listener at localhost/35248] mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1267532488_0001 completed successfully
2020-04-16 00:20:08,359 INFO  [Listener at localhost/35248] mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 36
	File System Counters
		FILE: Number of bytes read=124666
		FILE: Number of bytes written=1179899
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2
		HDFS: Number of bytes written=132
		HDFS: Number of read operations=36
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=34
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=113
		Map output materialized bytes=123
		Input split bytes=131
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=123
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=173
		Total committed heap usage (bytes)=4116709376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=205
	File Output Format Counters 
		Bytes Written=0
lsr root=har://hdfs-localhost:36960/user/root/archive/foo.har
2020-04-16 00:20:08,364 INFO  [IPC Server handler 9 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:08,369 INFO  [IPC Server handler 5 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:08,377 INFO  [IPC Server handler 8 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:08,385 INFO  [IPC Server handler 2 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_masterindex	dst=null	perm=null	proto=rpc
2020-04-16 00:20:08,391 INFO  [Listener at localhost/35248] sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-04-16 00:20:08,401 INFO  [IPC Server handler 7 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:08,411 INFO  [IPC Server handler 0 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/_index	dst=null	perm=null	proto=rpc
2020-04-16 00:20:08,429 INFO  [IPC Server handler 3 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har	dst=null	perm=null	proto=rpc
2020-04-16 00:20:08,436 INFO  [IPC Server handler 4 on default port 36960] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/archive/foo.har/part-0	dst=null	perm=null	proto=rpc
lsr results:
lsr: DEPRECATED: Please use 'ls -R' instead.
-rw-r--r--   3 root supergroup          1 2020-04-16 00:20 har://hdfs-localhost:36960/user/root/archive/foo.har/a

lsr paths = [/a]
2020-04-16 00:20:08,441 INFO  [Listener at localhost/35248] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-04-16 00:20:08,441 INFO  [Listener at localhost/35248] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-04-16 00:20:08,441 INFO  [Listener at localhost/35248] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:20:08,442 WARN  [Listener at localhost/35248] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:20:08,444 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4fe01803] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:20:08,446 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5, DS-12e8a7c6-3f9f-4033-a666-2d0139341f87) exiting.
2020-04-16 00:20:08,446 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6, DS-0a514001-f208-4ae4-ab60-0767387b8a13) exiting.
2020-04-16 00:20:08,633 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a699efa{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:20:08,640 INFO  [Listener at localhost/35248] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@38499e48{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:08,643 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6569dded{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:08,643 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b60c3e{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:20:08,656 INFO  [Listener at localhost/35248] ipc.Server (Server.java:stop(3359)) - Stopping server on 35248
2020-04-16 00:20:08,657 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:08,682 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:08,685 WARN  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:20:08,685 WARN  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 81440589-fb84-43a4-8b6a-4ced7423774d) service to localhost/127.0.0.1:36960
2020-04-16 00:20:08,685 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 81440589-fb84-43a4-8b6a-4ced7423774d)
2020-04-16 00:20:08,685 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:08,687 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data5/current/BP-1806308713-172.17.0.5-1586996395114] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:08,698 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data6/current/BP-1806308713-172.17.0.5-1586996395114] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:08,701 INFO  [Listener at localhost/35248] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:20:08,702 INFO  [Listener at localhost/35248] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:20:08,703 INFO  [Listener at localhost/35248] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:20:08,703 INFO  [Listener at localhost/35248] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:20:08,712 INFO  [Listener at localhost/35248] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:20:08,713 INFO  [Listener at localhost/35248] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-04-16 00:20:08,713 INFO  [Listener at localhost/35248] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:20:08,713 WARN  [Listener at localhost/35248] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:20:08,713 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@69eb86b4] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:20:08,720 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4, DS-762f887a-c31f-4ca8-91f7-9ec6dbe28d38) exiting.
2020-04-16 00:20:08,721 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3, DS-7d98812e-87b0-4227-99e6-a41dbf71256d) exiting.
2020-04-16 00:20:08,901 WARN  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 735afa23-3741-452e-9baa-3e39565531e5) service to localhost/127.0.0.1:36960
2020-04-16 00:20:08,901 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 735afa23-3741-452e-9baa-3e39565531e5)
2020-04-16 00:20:08,901 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:08,912 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5f462e3b{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:20:08,921 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data3/current/BP-1806308713-172.17.0.5-1586996395114] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:08,921 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data4/current/BP-1806308713-172.17.0.5-1586996395114] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:08,965 INFO  [Listener at localhost/35248] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2303dff{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:08,966 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30feffc{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:08,966 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3eba57a7{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:20:08,985 INFO  [Listener at localhost/35248] ipc.Server (Server.java:stop(3359)) - Stopping server on 38091
2020-04-16 00:20:09,000 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:09,007 INFO  [Listener at localhost/35248] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:20:09,008 INFO  [Listener at localhost/35248] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:20:09,009 INFO  [Listener at localhost/35248] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:20:09,009 INFO  [Listener at localhost/35248] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:20:09,011 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:09,013 INFO  [Listener at localhost/35248] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:20:09,013 INFO  [Listener at localhost/35248] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-04-16 00:20:09,013 INFO  [Listener at localhost/35248] datanode.DataNode (DataNode.java:shutdown(2010)) - msx-hdfs DataNode stop
2020-04-16 00:20:09,014 WARN  [Listener at localhost/35248] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-04-16 00:20:09,014 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@35e52059] datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-16 00:20:09,015 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1, DS-3f005943-d3f4-4239-90c0-caba4bb376bf) exiting.
2020-04-16 00:20:09,025 INFO  [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2)] datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2, DS-72f92deb-536a-4084-8f86-688da704b3ce) exiting.
2020-04-16 00:20:09,174 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@450794b4{/,null,UNAVAILABLE}{/datanode}
2020-04-16 00:20:09,186 INFO  [Listener at localhost/35248] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@383192b4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:09,186 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75201592{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:09,193 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@31198ceb{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
2020-04-16 00:20:09,225 INFO  [Listener at localhost/35248] ipc.Server (Server.java:stop(3359)) - Stopping server on 43265
2020-04-16 00:20:09,237 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:09,237 WARN  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-16 00:20:09,245 WARN  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 878e1773-6868-4713-bbf7-fd73f7190e03) service to localhost/127.0.0.1:36960
2020-04-16 00:20:09,237 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:09,346 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1806308713-172.17.0.5-1586996395114 (Datanode Uuid 878e1773-6868-4713-bbf7-fd73f7190e03)
2020-04-16 00:20:09,346 INFO  [BP-1806308713-172.17.0.5-1586996395114 heartbeating to localhost/127.0.0.1:36960] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1806308713-172.17.0.5-1586996395114
2020-04-16 00:20:09,347 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data1/current/BP-1806308713-172.17.0.5-1586996395114] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:09,347 WARN  [refreshUsed-/root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/data/data2/current/BP-1806308713-172.17.0.5-1586996395114] fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-16 00:20:09,359 INFO  [Listener at localhost/35248] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-04-16 00:20:09,360 INFO  [Listener at localhost/35248] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-04-16 00:20:09,361 INFO  [Listener at localhost/35248] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-04-16 00:20:09,361 INFO  [Listener at localhost/35248] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-04-16 00:20:09,365 INFO  [Listener at localhost/35248] datanode.DataNode (DataNode.java:shutdown(2167)) - Shutdown complete.
2020-04-16 00:20:09,365 INFO  [Listener at localhost/35248] hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-04-16 00:20:09,365 INFO  [Listener at localhost/35248] namenode.NameNode (NameNode.java:stop(1013)) - msx-hdfs NameNode stop
2020-04-16 00:20:09,365 INFO  [Listener at localhost/35248] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:20:09,366 INFO  [Listener at localhost/35248] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 56
2020-04-16 00:20:09,367 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@615f972] namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-16 00:20:09,368 INFO  [Listener at localhost/35248] namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 57 Total time for transactions(ms): 43 Number of transactions batched in Syncs: 19 Number of syncs: 39 SyncTimes(ms): 2 7 
2020-04-16 00:20:09,371 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@31500940] namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-16 00:20:09,371 INFO  [Listener at localhost/35248] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000057
2020-04-16 00:20:09,372 INFO  [Listener at localhost/35248] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/test-dir/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000057
2020-04-16 00:20:09,373 INFO  [FSEditLogAsync] namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-16 00:20:09,373 INFO  [CacheReplicationMonitor(593581395)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-16 00:20:09,374 INFO  [Listener at localhost/35248] ipc.Server (Server.java:stop(3359)) - Stopping server on 36960
2020-04-16 00:20:09,383 INFO  [IPC Server listener on 0] ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-04-16 00:20:09,410 INFO  [IPC Server Responder] ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-04-16 00:20:09,413 INFO  [StorageInfoMonitor] blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-04-16 00:20:09,415 INFO  [RedundancyMonitor] blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-04-16 00:20:09,469 INFO  [Listener at localhost/35248] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-04-16 00:20:09,470 INFO  [Listener at localhost/35248] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-04-16 00:20:09,473 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33fe57a9{/,null,UNAVAILABLE}{/hdfs}
2020-04-16 00:20:09,486 INFO  [Listener at localhost/35248] server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5dcd8c7a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-16 00:20:09,493 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d41f816{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-04-16 00:20:09,497 INFO  [Listener at localhost/35248] handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63f259c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-tools/hadoop-archives/target/log/,UNAVAILABLE}
msx-listener testfinished org.apache.hadoop.tools.TestHadoopArchives#testSingleFile
msx-listener writeFile testName is org.apache.hadoop.tools.TestHadoopArchives#testSingleFile
msx-listener succeed
msx-listener all testRunFinished
