[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------< [0;36morg.apache.hadoop:hadoop-hdfs[0;1m >--------------------[m
[[1;34mINFO[m] [1mBuilding Apache Hadoop HDFS 3.2.1[m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-antrun-plugin:1.7:run[m [1m(create-testdirs)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Executing tasks

main:
[[1;34mINFO[m] Executed tasks
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mhadoop-maven-plugins:3.2.1:protoc[m [1m(compile-protoc)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] No changes detected in protoc files, skipping generation.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mhadoop-maven-plugins:3.2.1:resource-gz[m [1m(resource-gz)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap.min.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap.min.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap-editable.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap-editable.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.min.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.min.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/bootstrap-editable.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/bootstrap-editable.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/npm.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/npm.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/bootstrap.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/bootstrap.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/bootstrap.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/bootstrap.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/moment.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/moment.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dfs-dust.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dfs-dust.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/json-bignum.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/json-bignum.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/d3-v4.1.1.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/d3-v4.1.1.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-helpers-1.1.1.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dust-helpers-1.1.1.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dataTables.bootstrap.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/hadoop.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/hadoop.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery.dataTables.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/jquery.dataTables.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/rest-csrf.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/rest-csrf.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-full-2.0.0.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dust-full-2.0.0.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery-3.3.1.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/jquery-3.3.1.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dataTables.bootstrap.css.gz
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.1:compile[m [1m(default-compile)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Compiling 6 source files to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/classes
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-antrun-plugin:1.7:run[m [1m(create-web-xmls)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Executing tasks

main:
[[1;34mINFO[m] Executed tasks
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 57 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-antrun-plugin:1.7:run[m [1m(create-log-dir)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Executing tasks

main:
   [delete] Deleting directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data
    [mkdir] Created dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data
     [copy] Copying 21 files to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps
[[1;34mINFO[m] Executed tasks
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.1:testCompile[m [1m(default-testCompile)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M1:test[m [1m(default-test)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] Running org.apache.hadoop.tools.[1mTestHdfsConfigFields[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.48 s - in org.apache.hadoop.tools.[1mTestHdfsConfigFields[m
[[1;34mINFO[m] Running org.apache.hadoop.tools.[1mTestJMXGet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.477 s - in org.apache.hadoop.tools.[1mTestJMXGet[m
[[1;34mINFO[m] Running org.apache.hadoop.tools.[1mTestTools[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.69 s - in org.apache.hadoop.tools.[1mTestTools[m
[[1;34mINFO[m] Running org.apache.hadoop.net.[1mTestNetworkTopology[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.049 s - in org.apache.hadoop.net.[1mTestNetworkTopology[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSetrepIncreasing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.375 s - in org.apache.hadoop.hdfs.[1mTestSetrepIncreasing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeConfig[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.564 s - in org.apache.hadoop.hdfs.[1mTestDatanodeConfig[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestAclsEndToEnd[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 59.691 s - in org.apache.hadoop.hdfs.[1mTestAclsEndToEnd[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteReadStripedFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m17[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 215.628 s - in org.apache.hadoop.hdfs.[1mTestWriteReadStripedFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.[1mTestLocatedBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.181 s - in org.apache.hadoop.hdfs.protocol.[1mTestLocatedBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.[1mTestAnnotations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.115 s - in org.apache.hadoop.hdfs.protocol.[1mTestAnnotations[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.[1mTestLayoutVersion[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.207 s - in org.apache.hadoop.hdfs.protocol.[1mTestLayoutVersion[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.datatransfer.[1mTestPacketReceiver[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.321 s - in org.apache.hadoop.hdfs.protocol.datatransfer.[1mTestPacketReceiver[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.datatransfer.sasl.[1mTestSaslDataTransfer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.035 s - in org.apache.hadoop.hdfs.protocol.datatransfer.sasl.[1mTestSaslDataTransfer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.datatransfer.sasl.[1mTestBlackListBasedTrustedChannelResolver[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.286 s - in org.apache.hadoop.hdfs.protocol.datatransfer.sasl.[1mTestBlackListBasedTrustedChannelResolver[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.[1mTestBlockListAsLongs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.832 s - in org.apache.hadoop.hdfs.protocol.[1mTestBlockListAsLongs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.371 s - in org.apache.hadoop.hdfs.[1mTestWriteRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReconstructStripedFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 116.65 s - in org.apache.hadoop.hdfs.[1mTestReconstructStripedFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestEncryptionZones[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m42[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 97 s - in org.apache.hadoop.hdfs.[1mTestEncryptionZones[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReconstructStripedFileWithRandomECPolicy[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m15[m, [1;31mFailures: [0;1;31m4[m, Errors: 0, Skipped: 0, Time elapsed: 121.858 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestReconstructStripedFileWithRandomECPolicy[m
[[1;31mERROR[m] testRecoverAnyBlocks1(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 7.361 s  <<< FAILURE!
arrays first differed at element [1048064]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:399)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverAnyBlocks1(TestReconstructStripedFile.java:229)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testRecoverAllParityBlocks(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 5.282 s  <<< FAILURE!
arrays first differed at element [0]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:399)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverAllParityBlocks(TestReconstructStripedFile.java:180)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testRecoverOneDataBlock1(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 5.176 s  <<< FAILURE!
arrays first differed at element [0]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:399)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverOneDataBlock1(TestReconstructStripedFile.java:208)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testRecoverOneDataBlock2(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 3.934 s  <<< FAILURE!
arrays first differed at element [0]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:399)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverOneDataBlock2(TestReconstructStripedFile.java:215)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.sps.[1mTestExternalStoragePolicySatisfier[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m28[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 377.921 s - in org.apache.hadoop.hdfs.server.sps.[1mTestExternalStoragePolicySatisfier[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestLevelDBFileRegionAliasMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.277 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestLevelDBFileRegionAliasMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestTextBlockAliasMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.262 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestTextBlockAliasMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestInMemoryLevelDBAliasMapClient[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.746 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestInMemoryLevelDBAliasMapClient[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestLevelDbMockAliasMapClient[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.168 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestLevelDbMockAliasMapClient[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.[1mTestGetUriFromString[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.387 s - in org.apache.hadoop.hdfs.server.common.[1mTestGetUriFromString[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.[1mTestJspHelper[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.775 s - in org.apache.hadoop.hdfs.server.common.[1mTestJspHelper[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestKeyManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.447 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestKeyManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithNodeGroup[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.806 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithNodeGroup[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m33[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 327.07 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerRPCDelay[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.375 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerRPCDelay[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithHANameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.857 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithHANameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithEncryptedTransfer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.39 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithEncryptedTransfer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithMultipleNameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 175.567 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithMultipleNameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithSaslDataTransfer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.022 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithSaslDataTransfer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogFileOutputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.432 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogFileOutputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeHttpServer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.911 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeHttpServer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.top.window.[1mTestRollingWindowManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.214 s - in org.apache.hadoop.hdfs.server.namenode.top.window.[1mTestRollingWindowManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.top.window.[1mTestRollingWindow[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.109 s - in org.apache.hadoop.hdfs.server.namenode.top.window.[1mTestRollingWindow[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirAttrOp[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.428 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirAttrOp[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaByStorageType[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m23[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.102 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaByStorageType[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestPersistentStoragePolicySatisfier[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 153.941 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestPersistentStoragePolicySatisfier[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestBootstrapStandby[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.268 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestBootstrapStandby[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestLossyRetryInvocationHandler[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.824 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestLossyRetryInvocationHandler[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestXAttrsWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.008 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestXAttrsWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAAppend[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.532 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAAppend[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAStateTransitions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 61.328 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAStateTransitions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestBootstrapStandbyWithQJM[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.46 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestBootstrapStandbyWithQJM[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestInitializeSharedEdits[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.645 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestInitializeSharedEdits[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.768 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyBlockManagement[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.048 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyBlockManagement[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyCheckpoints[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 189.272 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyCheckpoints[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestPendingCorruptDnMessages[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.148 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestPendingCorruptDnMessages[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHASafeMode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m19[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 79.559 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHASafeMode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestRemoteNameNodeInfo[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.354 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestRemoteNameNodeInfo[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestConsistentReadsObserver[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.04 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestConsistentReadsObserver[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestEditLogsDuringFailover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.814 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestEditLogsDuringFailover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestQuotasWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.995 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestQuotasWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHarFileSystemWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.453 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHarFileSystemWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailoverWithBlockTokensEnabled[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.633 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailoverWithBlockTokensEnabled[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestPipelinesFailover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 93.696 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestPipelinesFailover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestEditLogTailer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m18[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 56.852 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestEditLogTailer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAConfiguration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.002 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAConfiguration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestObserverNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.212 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestObserverNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDNFencing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.509 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDNFencing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDelegationTokensWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.845 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDelegationTokensWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDFSUpgradeWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.947 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDFSUpgradeWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailureToReadEdits[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 81.954 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailureToReadEdits[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailureOfSharedDir[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m4[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 7.833 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailureOfSharedDir[m
[[1;31mERROR[m] testFailureOfSharedDir(org.apache.hadoop.hdfs.server.namenode.ha.TestFailureOfSharedDir)  Time elapsed: 7.243 s  <<< FAILURE!
java.lang.AssertionError: Succeeded in rolling edit log despite shared dir being deleted
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureOfSharedDir.testFailureOfSharedDir(TestFailureOfSharedDir.java:169)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyIsHot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.41 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyIsHot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyInProgressTail[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.295 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyInProgressTail[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestObserverReadProxyProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.697 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestObserverReadProxyProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDNFencingWithReplication[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 68.408 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDNFencingWithReplication[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestSeveralNameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.452 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestSeveralNameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestGetGroupsWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.241 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestGetGroupsWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestMultiObserverNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.349 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestMultiObserverNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestNNHealthCheck[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.036 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestNNHealthCheck[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStateTransitionFailure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.675 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStateTransitionFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestRetryCacheWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 229.051 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestRetryCacheWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAFsck[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.214 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAFsck[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.483 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAllowFormat[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.907 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAllowFormat[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDefaultBlockPlacementPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.195 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDefaultBlockPlacementPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaCounts[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.073 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaCounts[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileJournalManager[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m14[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 2.317 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileJournalManager[m
[[1;31mERROR[m] testDoPreUpgradeIOError(org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager)  Time elapsed: 0.07 s  <<< FAILURE!
java.lang.AssertionError: Expected test to throw (an instance of java.io.IOException and exception with message a string containing "failure in native rename")
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.rules.ExpectedException.failDueToMissingException(ExpectedException.java:184)
	at org.junit.rules.ExpectedException.access$100(ExpectedException.java:85)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:170)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestPathComponents[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.132 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestPathComponents[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.sps.[1mTestBlockStorageMovementAttemptedItems[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.64 s - in org.apache.hadoop.hdfs.server.namenode.sps.[1mTestBlockStorageMovementAttemptedItems[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.sps.[1mTestStoragePolicySatisfierWithStripedFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 66.757 s - in org.apache.hadoop.hdfs.server.namenode.sps.[1mTestStoragePolicySatisfierWithStripedFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNNThroughputBenchmark[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.402 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNNThroughputBenchmark[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestListOpenFiles[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.227 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestListOpenFiles[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAclConfigFlag[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.537 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAclConfigFlag[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStorageRestore[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m4[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 12.663 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestStorageRestore[m
[[1;31mERROR[m] testStorageRestoreFailure(org.apache.hadoop.hdfs.server.namenode.TestStorageRestore)  Time elapsed: 3.718 s  <<< FAILURE!
java.lang.AssertionError
	at org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure(TestStorageRestore.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogAtDebug[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.571 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogAtDebug[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeReconfigure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.118 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeReconfigure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestProcessCorruptBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.24 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestProcessCorruptBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeOptionParsing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.251 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeOptionParsing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestTruncateQuotaUpdate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.302 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestTruncateQuotaUpdate[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogAutoroll[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.369 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogAutoroll[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCacheDirectives[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 122.111 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCacheDirectives[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.698 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileTruncate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m19[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 94.511 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileTruncate[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFsck[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m33[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 139.134 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFsck[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDeleteRace[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 68.276 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDeleteRace[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNNStorageRetentionManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.661 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNNStorageRetentionManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.114 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirWriteFileOp[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.373 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirWriteFileOp[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddStripedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.279 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestReencryptionWithKMS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m33[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 270.077 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestReencryptionWithKMS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSEditLogLoader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m26[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 104.923 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSEditLogLoader[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageStorageInspector[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.302 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageStorageInspector[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestUpgradeDomainBlockPlacementPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.366 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestUpgradeDomainBlockPlacementPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStartupOptionUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.683 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStartupOptionUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStartup[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m13[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 31.679 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestStartup[m
[[1;31mERROR[m] testNNFailToStartOnReadOnlyNNDir(org.apache.hadoop.hdfs.server.namenode.TestStartup)  Time elapsed: 6.447 s  <<< FAILURE!
java.lang.AssertionError: Restarting NN should fail on read only NN dir.
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testNNFailToStartOnReadOnlyNNDir(TestStartup.java:744)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRetryCacheMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.925 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRetryCacheMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeHttpServerXFrame[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.729 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeHttpServerXFrame[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecondaryWebUi[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.398 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecondaryWebUi[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.startupprogress.[1mTestStartupProgress[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.367 s - in org.apache.hadoop.hdfs.server.namenode.startupprogress.[1mTestStartupProgress[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.startupprogress.[1mTestStartupProgressMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.314 s - in org.apache.hadoop.hdfs.server.namenode.startupprogress.[1mTestStartupProgressMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.487 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestRandomOpsWithSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 153.789 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestRandomOpsWithSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotReplication[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.111 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotReplication[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 58.18 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapRootDescendantDiff[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m18[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m2[m, Time elapsed: 45.173 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapRootDescendantDiff[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestDiffListBySkipList[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.765 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestDiffListBySkipList[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotDiffReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m17[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 45.038 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotDiffReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotFileLength[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.317 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotFileLength[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotRename[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.629 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotRename[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotListing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.937 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotListing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestAclWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.164 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestAclWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotDeletion[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 79.598 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotDeletion[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshottableDirListing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.041 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshottableDirListing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestUpdatePipelineWithSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.066 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestUpdatePipelineWithSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotNameWithInvalidCharacters[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.1 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotNameWithInvalidCharacters[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestGetContentSummaryWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.856 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestGetContentSummaryWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.58 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotBlocksMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.044 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotBlocksMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestINodeFileUnderConstructionWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.828 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestINodeFileUnderConstructionWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestDisallowModifyROSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.684 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestDisallowModifyROSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestFileWithSnapshotFeature[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.458 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestFileWithSnapshotFeature[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestNestedSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.383 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestNestedSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestFileContextSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.797 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestFileContextSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestXAttrWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.029 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestXAttrWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestOpenFilesWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 79.935 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestOpenFilesWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestCheckpointsWithSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.192 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestCheckpointsWithSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestRenameWithSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m36[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 98.344 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestRenameWithSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSetQuotaWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.449 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSetQuotaWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotStatsMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.706 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotStatsMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFsckWithMultipleNameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.754 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFsckWithMultipleNameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestBlockPlacementPolicyRackFaultTolerant[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.04 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestBlockPlacementPolicyRackFaultTolerant[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestValidateConfigurationSettings[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.423 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestValidateConfigurationSettings[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestMetaSave[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.608 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestMetaSave[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSPermissionChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.976 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSPermissionChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameEditsConfigs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.87 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameEditsConfigs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaWithStripedBlocksWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.78 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaWithStripedBlocksWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLog[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m52[m, [1;31mFailures: [0;1;31m2[m, Errors: 0, Skipped: 0, Time elapsed: 101.776 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLog[m
[[1;31mERROR[m] testFailedOpen[0](org.apache.hadoop.hdfs.server.namenode.TestEditLog)  Time elapsed: 0.021 s  <<< FAILURE!
java.lang.AssertionError: Did no throw exception on only having a bad dir
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestEditLog.testFailedOpen(TestEditLog.java:1068)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;31mERROR[m] testFailedOpen[1](org.apache.hadoop.hdfs.server.namenode.TestEditLog)  Time elapsed: 0.015 s  <<< FAILURE!
java.lang.AssertionError: Did no throw exception on only having a bad dir
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestEditLog.testFailedOpen(TestEditLog.java:1068)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRpcServer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.702 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRpcServer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNestedEncryptionZones[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.431 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNestedEncryptionZones[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystemMBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.725 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystemMBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLoggerWithCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m40[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.708 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLoggerWithCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestXAttrConfigFlag[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.758 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestXAttrConfigFlag[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMetadataConsistency[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.034 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMetadataConsistency[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCreateEditsLog[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.066 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCreateEditsLog[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeAcl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m66[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.713 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeConfiguration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.171 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeConfiguration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRpcServerMethods[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.58 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRpcServerMethods[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirectory[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.157 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirectory[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestXAttrFeature[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.18 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestXAttrFeature[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecureNameNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.759 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecureNameNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestLeaseManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.182 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestLeaseManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestClusterId[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.076 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestClusterId[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestProtectedDirectories[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.864 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestProtectedDirectories[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestRefreshNamenodeReplicationConfig[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.736 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestRefreshNamenodeReplicationConfig[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithAcl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 70.026 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecondaryNameNodeUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.879 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecondaryNameNodeUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestMetadataVersionOutput[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.682 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestMetadataVersionOutput[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogger[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.578 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogger[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestMalformedURLs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.608 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestMalformedURLs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStoragePolicySummary[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.129 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStoragePolicySummary[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m32[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.689 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCommitBlockSynchronization[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.349 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCommitBlockSynchronization[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestGetImageServlet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.609 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestGetImageServlet[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStripedINodeFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.614 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStripedINodeFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFsLimits[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.384 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFsLimits[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestReconstructStripedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.533 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestReconstructStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestINodeFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m28[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.675 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestINodeFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystem[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.137 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystem[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRespectsBindHostKeys[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.703 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRespectsBindHostKeys[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestHostsFiles[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.228 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestHostsFiles[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestBlockUnderConstruction[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.916 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestBlockUnderConstruction[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSnapshotPathINodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.493 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSnapshotPathINodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeRetryCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.215 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeRetryCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestReencryptionHandler[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.939 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestReencryptionHandler[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCheckPointForSecurityTokens[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.932 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCheckPointForSecurityTokens[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCommitBlockWithInvalidGenStamp[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.73 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCommitBlockWithInvalidGenStamp[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMetricsLogger[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.591 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMetricsLogger[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCheckpoint[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m38[m, [1;31mFailures: [0;1;31m2[m, Errors: 0, Skipped: 0, Time elapsed: 62.325 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestCheckpoint[m
[[1;31mERROR[m] testNameDirError(org.apache.hadoop.hdfs.server.namenode.TestCheckpoint)  Time elapsed: 3.484 s  <<< FAILURE!
java.lang.AssertionError: NN should have failed to start with /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 set unreadable
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testNameDirError(TestCheckpoint.java:180)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;31mERROR[m] testCheckpointWithSeparateDirsAfterNameFails(org.apache.hadoop.hdfs.server.namenode.TestCheckpoint)  Time elapsed: 0.338 s  <<< FAILURE!
java.lang.AssertionError: Did not fail to checkpoint when there are no valid storage dirs
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpointWithSeparateDirsAfterNameFails(TestCheckpoint.java:2143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestGetBlockLocations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.436 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestGetBlockLocations[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestParallelImageWrite[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.095 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestParallelImageWrite[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStoragePolicySatisfierWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.789 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStoragePolicySatisfierWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogFileInputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.766 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogFileInputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMXBean[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m12[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 34.192 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMXBean[m
[[1;31mERROR[m] testNameNodeMXBeanInfo(org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean)  Time elapsed: 1.426 s  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNameNodeMXBeanInfo(TestNameNodeMXBean.java:257)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m17[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 130.871 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestLargeDirectoryDelete[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.031 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestLargeDirectoryDelete[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEnabledECPolicies[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.434 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEnabledECPolicies[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSaveNamespace[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m16[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 16.46 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestSaveNamespace[m
[[1;31mERROR[m] testReinsertnamedirsInSavenamespace(org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace)  Time elapsed: 0.245 s  <<< FAILURE!
java.lang.AssertionError: Savenamespace should have marked one directory as bad. But found 0 bad directories.
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testReinsertnamedirsInSavenamespace(TestSaveNamespace.java:292)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileContextXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.935 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileContextXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestGenericJournalConf[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.42 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestGenericJournalConf[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDeadDatanode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.413 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDeadDatanode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestClientNameNodeAddress[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.364 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestClientNameNodeAddress[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestNNMetricFilesInGetListingOps[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.395 s - in org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestNNMetricFilesInGetListingOps[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestTopMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.438 s - in org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestTopMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestNameNodeMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m19[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 62.271 s - in org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestNameNodeMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestINodeAttributeProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.14 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestINodeAttributeProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.148 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeResourcePolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.195 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeResourcePolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNNStorageRetentionFunctional[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m1[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 3.403 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestNNStorageRetentionFunctional[m
[[1;31mERROR[m] testPurgingWithNameEditsDirAfterFailure(org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionFunctional)  Time elapsed: 3.249 s  <<< FAILURE!
org.junit.ComparisonFailure: Bad files matching fsimage_\d* in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/nn0/current expected:<...e_000000000000000000[2,fsimage_0000000000000000004]> but was:<...e_000000000000000000[4,fsimage_0000000000000000006]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.apache.hadoop.test.GenericTestUtils.assertGlobEquals(GenericTestUtils.java:309)
	at org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionFunctional.testPurgingWithNameEditsDirAfterFailure(TestNNStorageRetentionFunctional.java:117)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeResourceChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.872 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeResourceChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditsDoubleBuffer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.246 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditsDoubleBuffer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestListCorruptFileBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 108.9 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestListCorruptFileBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestBackupNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.672 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestBackupNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeCapacityReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.673 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeCapacityReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogJournalFailures[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.986 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogJournalFailures[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestHDFSConcat[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.123 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestHDFSConcat[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeStatusMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.584 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeStatusMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddStripedBlockInFBR[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.017 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddStripedBlockInFBR[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.85 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDiskspaceQuotaUpdate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 46.073 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDiskspaceQuotaUpdate[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFavoredNodesEndToEnd[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.052 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFavoredNodesEndToEnd[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.76 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeStorageDirectives[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.076 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeStorageDirectives[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDecommissioningStatus[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.751 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDecommissioningStatus[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStartupProgressServlet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.396 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStartupProgressServlet[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEncryptionZoneManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.456 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEncryptionZoneManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystemLock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.529 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystemLock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestGetContentSummaryWithPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.058 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestGetContentSummaryWithPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddBlockRetry[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.299 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddBlockRetry[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileContextAcl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m66[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.87 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileContextAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.web.resources.[1mTestWebHdfsDataLocality[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.769 s - in org.apache.hadoop.hdfs.server.namenode.web.resources.[1mTestWebHdfsDataLocality[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.web.resources.[1mTestWebHdfsCreatePermissions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.935 s - in org.apache.hadoop.hdfs.server.namenode.web.resources.[1mTestWebHdfsCreatePermissions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaWithStripedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.668 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaWithStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDeduplicationMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.06 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDeduplicationMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestReencryption[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m32[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 348.789 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestReencryption[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecureNameNodeWithExternalKdc[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m1[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.067 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecureNameNodeWithExternalKdc[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddOverReplicatedStripedBlocks[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m4[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 26.315 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddOverReplicatedStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestTransferFsImage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.868 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestTransferFsImage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAclTransformation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m55[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.279 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAclTransformation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecurityTokenEditLog[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.464 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecurityTokenEditLog[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogRace[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 122.414 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogRace[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileLimit[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.66 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileLimit[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.command.[1mTestDiskBalancerCommand[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m30[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 58.454 s - in org.apache.hadoop.hdfs.server.diskbalancer.command.[1mTestDiskBalancerCommand[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancerRPC[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.166 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancerRPC[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestPlanner[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.67 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestPlanner[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDataModels[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.491 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDataModels[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestConnectors[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.174 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestConnectors[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancerWithMockMover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.02 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancerWithMockMover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancer[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m6[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 31.019 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancer[m
[[1;31mERROR[m] testDiskBalancerWithFedClusterWithOneNameServiceEmpty(org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancer)  Time elapsed: 6.909 s  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancer.testDiskBalancerWithFedClusterWithOneNameServiceEmpty(TestDiskBalancer.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.aliasmap.[1mTestInMemoryAliasMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.254 s - in org.apache.hadoop.hdfs.server.aliasmap.[1mTestInMemoryAliasMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSequentialBlockGroupId[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.537 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSequentialBlockGroupId[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockInfoStriped[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m30[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 63.818 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockInfoStriped[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockReportLease[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.035 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockReportLease[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestLowRedundancyBlockQueues[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.213 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestLowRedundancyBlockQueues[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingDataNodeMessages[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.865 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingDataNodeMessages[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m68[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.58 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestDatanodeManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.365 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestDatanodeManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockManagerSafeMode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m20[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.404 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockManagerSafeMode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockUnderConstructionFeature[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.239 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockUnderConstructionFeature[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlocksWithNotEnoughRacks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.566 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlocksWithNotEnoughRacks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockPlacementStatusWithUpgradeDomain[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.157 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockPlacementStatusWithUpgradeDomain[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockStatsMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.419 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockStatsMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestCachedBlocksList[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.199 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestCachedBlocksList[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHeartbeatHandling[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.852 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHeartbeatHandling[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestNodeCount[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.575 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestNodeCount[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyWithNodeGroup[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m18[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.443 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyWithNodeGroup[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingReconstruction[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.57 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingReconstruction[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestProvidedStorageMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.512 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestProvidedStorageMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestNameNodePrunesMissingStorages[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.355 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestNameNodePrunesMissingStorages[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockTokenWithDFSStriped[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 42.956 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockTokenWithDFSStriped[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReconstructStripedBlocksWithRackAwareness[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.729 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReconstructStripedBlocksWithRackAwareness[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingRecoveryBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.335 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingRecoveryBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestOverReplicatedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.72 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestOverReplicatedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyWithUpgradeDomain[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.227 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyWithUpgradeDomain[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockTokenWithDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.942 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockTokenWithDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSortLocatedStripedBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.997 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSortLocatedStripedBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSequentialBlockId[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.374 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSequentialBlockId[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingInvalidateBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.369 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingInvalidateBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockInfo[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.274 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockInfo[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSlowDiskTracker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.516 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSlowDiskTracker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestDatanodeDescriptor[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.181 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestDatanodeDescriptor[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSlowPeerTracker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.681 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSlowPeerTracker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestCorruptReplicaInfo[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.551 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestCorruptReplicaInfo[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHost2NodesMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.195 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHost2NodesMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m27[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.598 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestUnderReplicatedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.58 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestUnderReplicatedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockReportRateLimiting[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.259 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockReportRateLimiting[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyConsiderLoad[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.894 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyConsiderLoad[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHostFileManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.888 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHostFileManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestAvailableSpaceBlockPlacementPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.508 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestAvailableSpaceBlockPlacementPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestRBWBlockInvalidation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.037 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestRBWBlockInvalidation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestComputeInvalidateWork[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.06 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestComputeInvalidateWork[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeInitStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.414 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeInitStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeTransferSocketSize[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.915 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeTransferSocketSize[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailureToleration[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m4[m, [1;31mFailures: [0;1;31m2[m, [1;31mErrors: [0;1;31m1[m, Skipped: 0, Time elapsed: 61.645 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailureToleration[m
[[1;31mERROR[m] testValidVolumesAtStartup(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration)  Time elapsed: 15.595 s  <<< FAILURE!
java.lang.AssertionError: The DN shouldn't have a bad directory.
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertFalse(Assert.java:64)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testValidVolumesAtStartup(TestDataNodeVolumeFailureToleration.java:131)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testFailedVolumeOnStartupIsCounted(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration)  Time elapsed: 30.964 s  <<< ERROR!
java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 1 Expected = 1 Dead = 0 Expected = 0 Total capacity = 898358673408 Expected = 449179336704 Vol Fails = 0 Expected = 1
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testFailedVolumeOnStartupIsCounted(TestDataNodeVolumeFailureToleration.java:299)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testVolumeAndTolerableConfiguration(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration)  Time elapsed: 1.541 s  <<< FAILURE!
java.lang.AssertionError: expected:<false> but was:<true>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testVolumeConfig(TestDataNodeVolumeFailureToleration.java:259)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testVolumeAndTolerableConfiguration(TestDataNodeVolumeFailureToleration.java:208)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDiskError[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBPOfferService[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 41.827 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBPOfferService[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodePeerMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.248 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodePeerMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeFaultInjector[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.86 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeFaultInjector[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDeleteBlockPool[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.787 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDeleteBlockPool[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestReadOnlySharedStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.91 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestReadOnlySharedStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataXceiverLazyPersistHint[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.968 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataXceiverLazyPersistHint[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBpServiceActorScheduler[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.356 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBpServiceActorScheduler[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeProtocolRetryPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.173 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeProtocolRetryPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataXceiverBackwardsCompat[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.958 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataXceiverBackwardsCompat[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestStartSecureDataNode[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m3[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.35 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestStartSecureDataNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockHasMultipleReplicasOnSameDN[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.224 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockHasMultipleReplicasOnSameDN[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeUUID[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.963 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeUUID[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestTriggerBlockReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.713 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestTriggerBlockReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestRefreshNamenodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.754 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestRefreshNamenodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeRegister[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.459 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeRegister[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestTransferRbw[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.623 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestTransferRbw[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.extdataset.[1mTestExternalDataset[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.092 s - in org.apache.hadoop.hdfs.server.datanode.extdataset.[1mTestExternalDataset[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeRollingUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 121.036 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeRollingUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeStartupOptions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.297 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeStartupOptions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestFsDatasetCacheRevocation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.766 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestFsDatasetCacheRevocation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.89 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailureReporting[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.957 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailureReporting[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeCheckerFailures[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.559 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeCheckerFailures[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestStorageLocationChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.715 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestStorageLocationChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestThrottledAsyncCheckerTimeout[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.32 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestThrottledAsyncCheckerTimeout[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeCheckerTimeout[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.54 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeCheckerTimeout[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.642 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestThrottledAsyncChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.782 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestThrottledAsyncChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeReconfiguration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.781 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeReconfiguration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBatchIbr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.917 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBatchIbr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.022 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDirectoryScanner[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m10[m, Failures: 0, [1;31mErrors: [0;1;31m1[m, Skipped: 0, Time elapsed: 733.144 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.datanode.[1mTestDirectoryScanner[m
[[1;31mERROR[m] testScanDirectoryStructureWarn(org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner)  Time elapsed: 600.02 s  <<< ERROR!
java.lang.Exception: test timed out after 600000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2704)
	at org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2744)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1735)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:911)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477)
	at org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.testScanDirectoryStructureWarn(TestDirectoryScanner.java:426)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestLargeBlockReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 182.427 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestLargeBlockReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestIncrementalBrVariations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.211 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestIncrementalBrVariations[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailure[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m11[m, [1;31mFailures: [0;1;31m2[m, [1;31mErrors: [0;1;31m1[m, Skipped: 0, Time elapsed: 78.778 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailure[m
[[1;31mERROR[m] testDataNodeFailToStartWithVolumeFailure(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure)  Time elapsed: 1.236 s  <<< FAILURE!
java.lang.AssertionError: Failed to get expected IOException
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.startNewDataNodeWithDiskFailure(TestDataNodeVolumeFailure.java:572)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testDataNodeFailToStartWithVolumeFailure(TestDataNodeVolumeFailure.java:503)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testDNFailToStartWithDataDirNonWritable(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure)  Time elapsed: 1.286 s  <<< FAILURE!
java.lang.AssertionError: Failed to get expected IOException
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.startNewDataNodeWithDiskFailure(TestDataNodeVolumeFailure.java:572)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testDNFailToStartWithDataDirNonWritable(TestDataNodeVolumeFailure.java:535)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testVolumeFailure(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure)  Time elapsed: 31.097 s  <<< ERROR!
java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2020-04-08 10:08:26,022

"qtp857726694-6628-acceptor-0@6c4544d2-ServerConnector@279c4dbd{HTTP/1.1,[http/1.1]}{localhost:42963}" daemon prio=3 tid=6628 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"qtp1850761058-6578" daemon prio=5 tid=6578 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"VolumeCheck ResultHandler thread 1" daemon prio=5 tid=6558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Readahead Thread #0" daemon prio=5 tid=4912 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"LeaseRenewer:root@localhost:42300" daemon prio=5 tid=7038 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"pool-383-thread-1"  prio=5 tid=6801 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-374-thread-1"  prio=5 tid=6574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 42300" daemon prio=5 tid=6612 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"StorageLocationChecker thread 0" daemon prio=5 tid=6814 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-3-worker-29" daemon prio=5 tid=504 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=22 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-379-thread-1" daemon prio=5 tid=7006 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"BP-1525518249-172.17.0.5-1586340475207 heartbeating to localhost/127.0.0.1:42300" daemon prio=5 tid=6994 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager.waitTillNextIBR(IncrementalBlockReportManager.java:158)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:718)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
        at java.lang.Thread.run(Thread.java:748)
"BP-1525518249-172.17.0.5-1586340475207 heartbeating to localhost/127.0.0.1:42300" daemon prio=5 tid=6800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager.waitTillNextIBR(IncrementalBlockReportManager.java:158)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:718)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=6797 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"qtp1850761058-6587" daemon prio=5 tid=6587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"qtp1850761058-6577" daemon prio=5 tid=6577 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 36791" daemon prio=5 tid=6806 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"datanode DomainSocketWatcher" daemon prio=5 tid=6818 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 36371" daemon prio=5 tid=7000 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 2 on default port 36371" daemon prio=5 tid=6999 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp2037693399-6822" daemon prio=5 tid=6822 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@2c3df6d6Timer" daemon prio=5 tid=6825 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 36791" daemon prio=5 tid=6804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"DatanodeAdminMonitor-0" daemon prio=5 tid=6602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-391-thread-1"  prio=5 tid=6819 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=7023 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"main"  prio=5 tid=1 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.lang.Thread.join(Thread.java:1260)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluateStatement(FailOnTimeout.java:26)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluate(FailOnTimeout.java:17)
        at org.junit.rules.RunRules.evaluate(RunRules.java:20)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)" daemon prio=5 tid=6995 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"IPC Server idle connection scanner for port 42300" daemon prio=5 tid=6597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ForkJoinPool-3-worker-50" daemon prio=5 tid=501 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"pool-382-thread-1"  prio=5 tid=6626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp2037693399-6820" daemon prio=5 tid=6820 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=4897 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 42300" daemon prio=5 tid=6608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1525518249-172.17.0.5-1586340475207" daemon prio=5 tid=7015 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=6990 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"IPC Server handler 7 on default port 36791" daemon prio=5 tid=6811 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Listener at localhost/36371"  prio=5 tid=6564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.lang.Thread.join(Thread.java:1260)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluateStatement(FailOnTimeout.java:26)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluate(FailOnTimeout.java:17)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
"CacheReplicationMonitor(638690345)"  prio=5 tid=6620 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run(CacheReplicationMonitor.java:181)
"org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@2292fcad" daemon prio=5 tid=6601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@4bade1dTimer" daemon prio=5 tid=6630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"RedundancyMonitor" daemon prio=5 tid=6588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:340)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4684)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@772f3244Timer" daemon prio=5 tid=6632 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor@5ff9f2aa" daemon prio=5 tid=6617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor.run(FSNamesystem.java:4063)
        at java.lang.Thread.run(Thread.java:748)
"Timer for 'NameNode' metrics system" daemon prio=5 tid=6572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ForkJoinPool-3-worker-1" daemon prio=5 tid=508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"Readahead Thread #1" daemon prio=5 tid=4913 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@27f5d1db" daemon prio=5 tid=6986 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 36791" daemon prio=5 tid=6805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp857726694-6627" daemon prio=5 tid=6627 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 42300" daemon prio=5 tid=6604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Client (1881503984) connection to localhost/127.0.0.1:42300 from root" daemon prio=5 tid=7194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1034)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1078)
"process reaper" daemon prio=10 tid=487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=6809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@5f0572a1Timer" daemon prio=5 tid=6584 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=6795 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"IPC Server handler 3 on default port 42300" daemon prio=5 tid=6607 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.eclipse.jetty.server.session.HashSessionManager@343dc72fTimer" daemon prio=5 tid=6631 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=6557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
"IPC Server handler 5 on default port 36791" daemon prio=5 tid=6808 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.eclipse.jetty.server.session.HashSessionManager@434769a9Timer" daemon prio=5 tid=6824 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1525518249-172.17.0.5-1586340475207" daemon prio=5 tid=7029 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 36791" daemon prio=5 tid=6810 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"StorageLocationChecker thread 1" daemon prio=5 tid=6815 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@34a7bed7" daemon prio=5 tid=6573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"StorageLocationChecker thread 0" daemon prio=5 tid=6621 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=6794 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@334025d5" daemon prio=5 tid=6619 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber.run(FSNamesystem.java:4196)
        at java.lang.Thread.run(Thread.java:748)
"qtp1850761058-6575" daemon prio=5 tid=6575 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"pool-394-thread-1"  prio=5 tid=6996 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 36791" daemon prio=5 tid=6812 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"VolumeCheck ResultHandler thread 1" daemon prio=5 tid=5402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-3-worker-8" daemon prio=5 tid=507 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"IPC Server handler 9 on default port 36371" daemon prio=5 tid=7008 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server idle connection scanner for port 36791" daemon prio=5 tid=6796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ForkJoinPool-3-worker-22" daemon prio=5 tid=505 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"process reaper" daemon prio=10 tid=484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1c1fc7f" daemon prio=5 tid=6817 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:113)
        at org.apache.hadoop.hdfs.net.TcpPeerServer.accept(TcpPeerServer.java:85)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:145)
        at java.lang.Thread.run(Thread.java:748)
"qtp2037693399-6821-acceptor-0@1295c89-ServerConnector@161830d6{HTTP/1.1,[http/1.1]}{localhost:34037}" daemon prio=3 tid=6821 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"qtp857726694-6629" daemon prio=5 tid=6629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 42300" daemon prio=5 tid=6610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server listener on 0" daemon prio=5 tid=6595 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"IPC Server handler 7 on default port 42300" daemon prio=5 tid=6611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)" daemon prio=5 tid=7017 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"IPC Server handler 1 on default port 36371" daemon prio=5 tid=6998 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.eclipse.jetty.server.session.HashSessionManager@4165b5ecTimer" daemon prio=5 tid=6823 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-388-thread-1" daemon prio=5 tid=7024 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 36371" daemon prio=5 tid=7005 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.eclipse.jetty.server.session.HashSessionManager@1fc70942Timer" daemon prio=5 tid=6583 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"client DomainSocketWatcher" daemon prio=5 tid=483 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 42300" daemon prio=5 tid=6613 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 8 on default port 36371" daemon prio=5 tid=7007 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)" daemon prio=5 tid=6991 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"qtp1850761058-6582-acceptor-3@4637eef-ServerConnector@497580c2{HTTP/1.1,[http/1.1]}{localhost:35504}" daemon prio=3 tid=6582 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:230)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"qtp1850761058-6580-acceptor-1@7df807ed-ServerConnector@497580c2{HTTP/1.1,[http/1.1]}{localhost:35504}" daemon prio=3 tid=6580 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"AsyncAppender-Dispatcher-Thread-42" daemon prio=5 tid=77 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@78f5f9ab" daemon prio=5 tid=6590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run(HeartbeatManager.java:456)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 42300" daemon prio=5 tid=6605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bd4b2d2" daemon prio=5 tid=6793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"process reaper" daemon prio=10 tid=485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Async disk worker #0 for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3" daemon prio=5 tid=7192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1850761058-6579-acceptor-0@3af4b1c0-ServerConnector@497580c2{HTTP/1.1,[http/1.1]}{localhost:35504}" daemon prio=3 tid=6579 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:230)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-3-worker-57" daemon prio=5 tid=500 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"Block report processor" daemon prio=5 tid=6592 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:5043)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:5032)
"AsyncAppender-Dispatcher-Thread-61" daemon prio=5 tid=266 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=21 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:748)
"StorageInfoMonitor" daemon prio=5 tid=6589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StorageInfoDefragmenter.run(BlockManager.java:4719)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@13d753b2Timer" daemon prio=5 tid=6585 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 36791" daemon prio=5 tid=6813 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1525518249-172.17.0.5-1586340475207" daemon prio=5 tid=7014 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@25c56de6" daemon prio=5 tid=6618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller.run(FSNamesystem.java:4105)
        at java.lang.Thread.run(Thread.java:748)
"LeaseRenewer:root@localhost:35865" daemon prio=5 tid=5390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@13f176cc" daemon prio=5 tid=6616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
        at java.lang.Thread.run(Thread.java:748)
"FSEditLogAsync"  prio=5 tid=6594 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.dequeueEdit(FSEditLogAsync.java:221)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.run(FSEditLogAsync.java:229)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 36371" daemon prio=5 tid=6989 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 5 on default port 42300" daemon prio=5 tid=6609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)" daemon prio=5 tid=7021 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"ForkJoinPool-3-worker-43" daemon prio=5 tid=502 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"qtp1850761058-6576" daemon prio=5 tid=6576 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"qtp1850761058-6581-acceptor-2@5144686-ServerConnector@497580c2{HTTP/1.1,[http/1.1]}{localhost:35504}" daemon prio=3 tid=6581 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:230)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 36371" daemon prio=5 tid=7002 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ForkJoinPool-3-worker-15" daemon prio=5 tid=506 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"IPC Server handler 6 on default port 36371" daemon prio=5 tid=7004 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server listener on 0" daemon prio=5 tid=6987 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=4893 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 36371" daemon prio=5 tid=6997 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1525518249-172.17.0.5-1586340475207" daemon prio=5 tid=7030 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 36791" daemon prio=5 tid=6803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Socket Reader #1 for port 0"  prio=5 tid=6596 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"pool-376-thread-1"  prio=5 tid=6614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 42300" daemon prio=5 tid=6606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"java.util.concurrent.ThreadPoolExecutor$Worker@2cd2f86f[State = -1, empty queue]" daemon prio=5 tid=7035 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner" daemon prio=5 tid=85 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:3762)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=6988 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"nioEventLoopGroup-56-1"  prio=10 tid=6826 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=7191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=7003 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeCheck ResultHandler thread 2" daemon prio=5 tid=6563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4890c397" daemon prio=5 tid=6624 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:113)
        at org.apache.hadoop.hdfs.net.TcpPeerServer.accept(TcpPeerServer.java:85)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:145)
        at java.lang.Thread.run(Thread.java:748)
"java.util.concurrent.ThreadPoolExecutor$Worker@1eed4ae4[State = -1, empty queue]" daemon prio=5 tid=7022 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=5401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 36791" daemon prio=5 tid=6807 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"StorageLocationChecker thread 1" daemon prio=5 tid=6622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 36371" daemon prio=5 tid=7001 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-54-1"  prio=10 tid=6633 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=6625 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=6598 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"Thread-1956"  prio=5 tid=7036 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1610)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:87)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)
        at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:389)
        at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testVolumeFailure(TestDataNodeVolumeFailure.java:195)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
"ForkJoinPool-3-worker-36" daemon prio=5 tid=503 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)


	at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:389)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testVolumeFailure(TestDataNodeVolumeFailure.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockPoolManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.65 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockPoolManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDnRespectsBlockReportSplitThreshold[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.564 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDnRespectsBlockReportSplitThreshold[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestStorageReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.907 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestStorageReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeLifeline[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.125 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeLifeline[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.489 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMultipleRegistrations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.978 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMultipleRegistrations[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeExit[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.725 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeExit[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeErasureCodingMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.645 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeErasureCodingMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestCachingStrategy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.731 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestCachingStrategy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.metrics.[1mTestSlowNodeDetector[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.19 s - in org.apache.hadoop.hdfs.server.datanode.metrics.[1mTestSlowNodeDetector[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.metrics.[1mTestDataNodeOutlierDetectionViaMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.467 s - in org.apache.hadoop.hdfs.server.datanode.metrics.[1mTestDataNodeOutlierDetectionViaMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.064 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeHotSwapVolumes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 55.945 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeHotSwapVolumes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestNNHandlesCombinedBlockReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 52.101 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestNNHandlesCombinedBlockReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m21[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 106.227 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeECN[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.644 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeECN[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestHdfsServerConstants[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.057 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestHdfsServerConstants[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDNUsageReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.066 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDNUsageReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestWriteToReplica[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.496 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestWriteToReplica[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.714 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestProvidedImpl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.905 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestProvidedImpl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestFsDatasetImpl[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m15[m, Failures: 0, [1;31mErrors: [0;1;31m1[m, Skipped: 0, Time elapsed: 25.602 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestFsDatasetImpl[m
[[1;31mERROR[m] testCleanShutdownOfVolume(org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl)  Time elapsed: 2.492 s  <<< ERROR!
java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2020-04-08 10:16:02,873

"nioEventLoopGroup-11-38"  prio=10 tid=1444 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-45"  prio=10 tid=1371 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-71"  prio=10 tid=1397 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=37 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1565-acceptor-2@7fdc6e57-ServerConnector@3cdf2c61{HTTP/1.1,[http/1.1]}{localhost:44323}" daemon prio=3 tid=1565 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:231)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 44852" daemon prio=5 tid=1787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-20"  prio=10 tid=1426 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"DataXceiver for client DFSClient_NONMAPREDUCE_1610447008_1 at /127.0.0.1:41598 [Receiving block BP-1438896877-172.17.0.5-1586340961216:blk_1073741825_1001]" daemon prio=5 tid=1816 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at java.io.DataInputStream.read(DataInputStream.java:149)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 39977" daemon prio=5 tid=1592 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-35"  prio=10 tid=1441 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RLLeDjtWjj/data/data1)" daemon prio=5 tid=1799 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"qtp402695541-1571" daemon prio=5 tid=1571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1562" daemon prio=5 tid=1562 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-72"  prio=10 tid=1398 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-46"  prio=10 tid=1372 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"pool-123-thread-1"  prio=5 tid=1598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-28"  prio=10 tid=1354 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-28"  prio=10 tid=1434 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=1255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"BP-1438896877-172.17.0.5-1586340961216 heartbeating to localhost/127.0.0.1:39977" daemon prio=5 tid=1784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager.waitTillNextIBR(IncrementalBlockReportManager.java:158)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:718)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-19"  prio=10 tid=1345 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-51"  prio=10 tid=1377 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-62"  prio=10 tid=1388 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-21"  prio=10 tid=1427 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=856 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"IPC Client (1322907235) connection to localhost/127.0.0.1:39977 from root" daemon prio=5 tid=1786 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1034)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1078)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-11-52"  prio=10 tid=1458 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RLLeDjtWjj/data/data1/current/BP-1438896877-172.17.0.5-1586340961216" daemon prio=5 tid=1807 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1566-acceptor-3@7ee752cc-ServerConnector@3cdf2c61{HTTP/1.1,[http/1.1]}{localhost:44323}" daemon prio=3 tid=1566 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:231)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"CacheReplicationMonitor(1340649897)"  prio=5 tid=1604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run(CacheReplicationMonitor.java:181)
"nioEventLoopGroup-11-49"  prio=10 tid=1455 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-24"  prio=10 tid=1350 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=1241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-7"  prio=10 tid=1333 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 1" daemon prio=5 tid=1824 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-9"  prio=10 tid=1335 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=362 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-41"  prio=10 tid=1367 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-22" daemon prio=5 tid=395 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"nioEventLoopGroup-11-12"  prio=10 tid=1418 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@63fbfaeb" daemon prio=5 tid=1600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-1" daemon prio=5 tid=1229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-11"  prio=10 tid=1337 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-6"  prio=10 tid=1332 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"LeaseRenewer:root@localhost:39977" daemon prio=5 tid=1815 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0)" daemon prio=5 tid=922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-67"  prio=10 tid=1393 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-0" daemon prio=5 tid=864 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-59"  prio=10 tid=1465 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-55"  prio=10 tid=1381 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@9ebe38bTimer" daemon prio=5 tid=1568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-68"  prio=10 tid=1474 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-4"  prio=10 tid=1410 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 39977" daemon prio=5 tid=1581 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=883 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=21 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-58"  prio=10 tid=1384 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-23"  prio=10 tid=1349 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=1579 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"nioEventLoopGroup-11-62"  prio=10 tid=1468 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=22 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-32"  prio=10 tid=1438 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-41"  prio=10 tid=1447 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-0" daemon prio=5 tid=361 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@5ce8d869Timer" daemon prio=5 tid=1614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7749bf93" daemon prio=5 tid=1777 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-69"  prio=10 tid=1475 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-77"  prio=10 tid=1403 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=1216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-11-6"  prio=10 tid=1412 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-60"  prio=10 tid=1386 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-55"  prio=10 tid=1461 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-61"  prio=10 tid=1467 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-48"  prio=10 tid=1374 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-13"  prio=10 tid=1339 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-0" daemon prio=5 tid=383 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-1" daemon prio=5 tid=1545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-42"  prio=10 tid=1448 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-1" daemon prio=5 tid=370 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=1214 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-12-1"  prio=10 tid=1617 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@66c92293Timer" daemon prio=5 tid=1569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-50"  prio=10 tid=1456 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-54"  prio=10 tid=1380 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-16"  prio=10 tid=1342 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@24ba9639Timer" daemon prio=5 tid=1616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-67"  prio=10 tid=1473 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-12"  prio=10 tid=1338 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-0" daemon prio=5 tid=1247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0)" daemon prio=5 tid=377 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"IPC Server handler 8 on default port 44852" daemon prio=5 tid=1796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-10-27"  prio=10 tid=1353 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=1239 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0)" daemon prio=5 tid=355 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0)" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"DatanodeAdminMonitor-0" daemon prio=5 tid=1586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-5"  prio=10 tid=1411 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-18"  prio=10 tid=1424 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 39977" daemon prio=5 tid=1589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server listener on 0" daemon prio=5 tid=1778 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"nioEventLoopGroup-11-27"  prio=10 tid=1433 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"pool-126-thread-1" daemon prio=5 tid=1802 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0)" daemon prio=5 tid=1215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"IPC Server handler 9 on default port 39977" daemon prio=5 tid=1597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-80"  prio=10 tid=1406 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"LeaseRenewer:root@localhost:35681" daemon prio=5 tid=342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-34"  prio=10 tid=1440 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=1781 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@5bf0fe62" daemon prio=5 tid=1574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run(HeartbeatManager.java:456)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-29"  prio=10 tid=1435 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-4"  prio=10 tid=1330 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-26"  prio=10 tid=1432 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=1582 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"ForkJoinPool-2-worker-43" daemon prio=5 tid=42 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"nioEventLoopGroup-11-80"  prio=10 tid=1486 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-52"  prio=10 tid=1378 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.PeerCache@6ccd16b2" daemon prio=5 tid=347 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:253)
        at org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:46)
        at org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:124)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-46"  prio=10 tid=1452 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-29"  prio=10 tid=1355 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-77"  prio=10 tid=1483 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"qtp693267461-1613" daemon prio=5 tid=1613 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 39977" daemon prio=5 tid=1594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=384 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 44852" daemon prio=5 tid=1789 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-10-68"  prio=10 tid=1394 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=858 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@764faa6" daemon prio=5 tid=1585 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/newData0/current/bpid-0" daemon prio=5 tid=374 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-66"  prio=10 tid=1472 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-29" daemon prio=5 tid=365 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-0" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0)" daemon prio=5 tid=1240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/newData0)" daemon prio=5 tid=375 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-11-33"  prio=10 tid=1439 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RLLeDjtWjj/data/data2)" daemon prio=5 tid=1800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=871 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=378 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"datanode DomainSocketWatcher" daemon prio=5 tid=354 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-1" daemon prio=5 tid=67 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=1538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-3"  prio=10 tid=1409 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-50" daemon prio=5 tid=40 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"IPC Server handler 6 on default port 44852" daemon prio=5 tid=1793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"datanode DomainSocketWatcher" daemon prio=5 tid=1609 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0)" daemon prio=5 tid=1531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-38"  prio=10 tid=1364 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"qtp693267461-1611" daemon prio=5 tid=1611 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-9"  prio=10 tid=1415 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"PacketResponder: BP-1438896877-172.17.0.5-1586340961216:blk_1073741825_1001, type=LAST_IN_PIPELINE" daemon prio=5 tid=1818 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.waitForAckHead(BlockReceiver.java:1330)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1402)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=52 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-56"  prio=10 tid=1462 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"process reaper" daemon prio=10 tid=34 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-2"  prio=10 tid=1408 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 39977" daemon prio=5 tid=1588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-22"  prio=10 tid=1428 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-8"  prio=10 tid=1414 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-10"  prio=10 tid=1336 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@31c7528fTimer" daemon prio=5 tid=1615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-19"  prio=10 tid=1425 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-17"  prio=10 tid=1343 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-47"  prio=10 tid=1373 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Block report processor" daemon prio=5 tid=1576 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:5043)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:5032)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=936 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"AsyncAppender-Dispatcher-Thread-73" daemon prio=5 tid=121 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-79"  prio=10 tid=1485 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-56"  prio=10 tid=1382 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=1530 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-17"  prio=10 tid=1423 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"process reaper" daemon prio=10 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/RLLeDjtWjj/data/data2/current/BP-1438896877-172.17.0.5-1586340961216" daemon prio=5 tid=1808 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-24"  prio=10 tid=1430 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-70"  prio=10 tid=1476 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-76"  prio=10 tid=1402 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-57"  prio=10 tid=1383 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 44852" daemon prio=5 tid=1790 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 3 on default port 39977" daemon prio=5 tid=1591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-10-33"  prio=10 tid=1359 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-59"  prio=10 tid=1385 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=909 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-57" daemon prio=5 tid=41 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"nioEventLoopGroup-10-15"  prio=10 tid=1341 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 39977" daemon prio=5 tid=1595 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=1532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=903 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=356 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2c07545f" daemon prio=5 tid=1602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller.run(FSNamesystem.java:4105)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=1546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-1" daemon prio=5 tid=391 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-31"  prio=10 tid=1437 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 39977" daemon prio=5 tid=1596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-0" daemon prio=5 tid=1537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"qtp693267461-1612-acceptor-0@5da644b1-ServerConnector@6bffbc6d{HTTP/1.1,[http/1.1]}{localhost:35019}" daemon prio=3 tid=1612 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-39"  prio=10 tid=1365 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"pool-129-thread-1"  prio=5 tid=1610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@632ceb35" daemon prio=5 tid=1557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1560" daemon prio=5 tid=1560 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-2"  prio=10 tid=1328 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-7"  prio=10 tid=1413 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-22"  prio=10 tid=1348 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-0" daemon prio=5 tid=1221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-31"  prio=10 tid=1357 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-44"  prio=10 tid=1450 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=1779 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"nioEventLoopGroup-11-76"  prio=10 tid=1482 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-30"  prio=10 tid=1356 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-74"  prio=10 tid=1400 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-5"  prio=10 tid=1331 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 44852" daemon prio=5 tid=1797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-75"  prio=10 tid=1481 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor@602e0143" daemon prio=5 tid=1601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor.run(FSNamesystem.java:4063)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-1" daemon prio=5 tid=937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-35"  prio=10 tid=1361 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-37"  prio=10 tid=1443 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-63"  prio=10 tid=1469 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Listener at localhost/44852"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1610)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:87)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)
        at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:389)
        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testCleanShutdownOfVolume(TestFsDatasetImpl.java:700)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"IPC Server handler 5 on default port 39977" daemon prio=5 tid=1593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@524f3b3a" daemon prio=5 tid=1608 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:113)
        at org.apache.hadoop.hdfs.net.TcpPeerServer.accept(TcpPeerServer.java:85)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:145)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-57"  prio=10 tid=1463 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-49"  prio=10 tid=1375 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=863 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-64"  prio=10 tid=1390 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-48"  prio=10 tid=1454 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-73"  prio=10 tid=1399 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-26"  prio=10 tid=1352 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-72"  prio=10 tid=1478 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-43"  prio=10 tid=1449 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-20"  prio=10 tid=1346 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=890 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-25"  prio=10 tid=1351 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-78"  prio=10 tid=1484 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-40"  prio=10 tid=1366 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-44"  prio=10 tid=1370 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=28 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"qtp402695541-1564-acceptor-1@c5cc18a-ServerConnector@3cdf2c61{HTTP/1.1,[http/1.1]}{localhost:44323}" daemon prio=3 tid=1564 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:231)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=1801 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-11"  prio=10 tid=1417 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=1794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"DataStreamer for file /user/root/test.dat block BP-1438896877-172.17.0.5-1586340961216:blk_1073741825_1001" daemon prio=5 tid=1814 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:681)
"nioEventLoopGroup-11-74"  prio=10 tid=1480 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=26 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=921 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=376 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"ResponseProcessor for block BP-1438896877-172.17.0.5-1586340961216:blk_1073741825_1001" daemon prio=5 tid=1819 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
        at java.io.FilterInputStream.read(FilterInputStream.java:83)
        at java.io.FilterInputStream.read(FilterInputStream.java:83)
        at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:548)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)
        at org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1086)
"ForkJoinPool-2-worker-36" daemon prio=5 tid=43 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"nioEventLoopGroup-11-71"  prio=10 tid=1477 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-3"  prio=10 tid=1329 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-18"  prio=10 tid=1344 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
"nioEventLoopGroup-10-78"  prio=10 tid=1404 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 44852" daemon prio=5 tid=1788 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-23"  prio=10 tid=1429 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"StorageInfoMonitor" daemon prio=5 tid=1573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StorageInfoDefragmenter.run(BlockManager.java:4719)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-42"  prio=10 tid=1368 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-32"  prio=10 tid=1358 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-50"  prio=10 tid=1376 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-43"  prio=10 tid=1369 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 44852" daemon prio=5 tid=1795 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-58"  prio=10 tid=1464 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Client (1322907235) connection to localhost/127.0.0.1:39977 from root" daemon prio=5 tid=1798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1034)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1078)
"FSEditLogAsync"  prio=5 tid=1578 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.dequeueEdit(FSEditLogAsync.java:221)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.run(FSEditLogAsync.java:229)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=901 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-66"  prio=10 tid=1392 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=1222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-40"  prio=10 tid=1446 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-15"  prio=10 tid=1421 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-37"  prio=10 tid=1363 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-14"  prio=10 tid=1420 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-36"  prio=10 tid=1442 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Timer for 'NameNode' metrics system" daemon prio=5 tid=1556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"nioEventLoopGroup-10-1"  prio=10 tid=1327 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-65"  prio=10 tid=1471 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-10"  prio=10 tid=1416 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-51"  prio=10 tid=1457 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=875 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@56928307Timer" daemon prio=5 tid=1567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"AsyncAppender-Dispatcher-Thread-91" daemon prio=5 tid=309 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-34"  prio=10 tid=1360 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 44852" daemon prio=5 tid=1792 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-47"  prio=10 tid=1453 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1561" daemon prio=5 tid=1561 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-61"  prio=10 tid=1387 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-0" daemon prio=5 tid=1246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-0" daemon prio=5 tid=928 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0)" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"qtp402695541-1563-acceptor-0@7c0da313-ServerConnector@3cdf2c61{HTTP/1.1,[http/1.1]}{localhost:44323}" daemon prio=3 tid=1563 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-21"  prio=10 tid=1347 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"DataXceiver for client DFSClient_NONMAPREDUCE_1610447008_1 at /127.0.0.1:41602 [Waiting for operation #2]" daemon prio=5 tid=1822 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readShort(DataInputStream.java:312)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:71)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:271)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-30"  prio=10 tid=1436 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-75"  prio=10 tid=1401 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"StorageLocationChecker thread 1" daemon prio=5 tid=1606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=1230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 44852" daemon prio=5 tid=1791 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 2 on default port 39977" daemon prio=5 tid=1590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-60"  prio=10 tid=1466 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-14"  prio=10 tid=1340 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 44852" daemon prio=5 tid=1780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"nioEventLoopGroup-11-73"  prio=10 tid=1479 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-63"  prio=10 tid=1389 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-8"  prio=10 tid=1334 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=1580 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"nioEventLoopGroup-11-16"  prio=10 tid=1422 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"nioEventLoopGroup-11-25"  prio=10 tid=1431 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-79"  prio=10 tid=1405 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-70"  prio=10 tid=1396 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-36"  prio=10 tid=1362 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0)" daemon prio=5 tid=857 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-69"  prio=10 tid=1395 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"StorageLocationChecker thread 0" daemon prio=5 tid=1605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner" daemon prio=5 tid=29 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:3762)
        at java.lang.Thread.run(Thread.java:748)
"pool-130-thread-1"  prio=5 tid=1785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-65"  prio=10 tid=1391 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"java.util.concurrent.ThreadPoolExecutor$Worker@6a201c73[State = -1, empty queue]" daemon prio=5 tid=1813 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-1" daemon prio=5 tid=48 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-53"  prio=10 tid=1459 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-1"  prio=10 tid=1407 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"client DomainSocketWatcher" daemon prio=5 tid=338 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@e57b96d" daemon prio=5 tid=1603 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber.run(FSNamesystem.java:4196)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-13"  prio=10 tid=1419 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"LeaseRenewer:root@localhost:45327" daemon prio=5 tid=1525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-64"  prio=10 tid=1470 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1)" daemon prio=5 tid=877 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-11-39"  prio=10 tid=1445 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"RedundancyMonitor" daemon prio=5 tid=1572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:340)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4684)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-45"  prio=10 tid=1451 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=917 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-1" daemon prio=5 tid=872 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1559" daemon prio=5 tid=1559 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"pool-121-thread-1"  prio=5 tid=1558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-53"  prio=10 tid=1379 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data1/current/bpid-1" daemon prio=5 tid=392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-0" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/mR8w6TtPQ9/data0/current/bpid-1" daemon prio=5 tid=1254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-54"  prio=10 tid=1460 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)


	at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:389)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testCleanShutdownOfVolume(TestFsDatasetImpl.java:700)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestReplicaMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.132 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestReplicaMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestDatanodeRestart[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.004 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestDatanodeRestart[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestInterDatanodeProtocol[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.14 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestInterDatanodeProtocol[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestSpaceReservation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 90.167 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestSpaceReservation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyWriter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 103.46 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyWriter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestReservedSpaceCalculator[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.407 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestReservedSpaceCalculator[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistFiles[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 109.214 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistFiles[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistReplicaPlacement[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.771 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistReplicaPlacement[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistLockedMemory[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.266 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistLockedMemory[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestAddBlockPoolException[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.478 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestAddBlockPoolException[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestFsVolumeList[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.919 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestFsVolumeList[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistReplicaRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.304 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistReplicaRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestScrLazyPersistFiles[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.386 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestScrLazyPersistFiles[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.[1mTestAvailableSpaceVolumeChoosingPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.117 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.[1mTestAvailableSpaceVolumeChoosingPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.[1mTestRoundRobinVolumeChoosingPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.239 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.[1mTestRoundRobinVolumeChoosingPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestNNHandlesBlockReportPerStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 51.455 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestNNHandlesBlockReportPerStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestFsDatasetCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 96.67 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestFsDatasetCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeTcpNoDelay[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.602 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeTcpNoDelay[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestIncrementalBlockReports[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.317 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestIncrementalBlockReports[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMetricsLogger[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.792 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMetricsLogger[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestSimulatedFSDataset[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.846 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestSimulatedFSDataset[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockPoolSliceStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.309 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockPoolSliceStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestHSync[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.805 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestHSync[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockScanner[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 159.389 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockScanner[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.web.[1mTestDatanodeHttpXFrame[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.755 s - in org.apache.hadoop.hdfs.server.datanode.web.[1mTestDatanodeHttpXFrame[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.web.webhdfs.[1mTestParameterParser[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.301 s - in org.apache.hadoop.hdfs.server.datanode.web.webhdfs.[1mTestParameterParser[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.web.webhdfs.[1mTestDataNodeUGIProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.992 s - in org.apache.hadoop.hdfs.server.datanode.web.webhdfs.[1mTestDataNodeUGIProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeFSDataSetSink[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.751 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeFSDataSetSink[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestProvidedReplicaImpl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.802 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestProvidedReplicaImpl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockCountersInPendingIBR[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.865 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockCountersInPendingIBR[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockReplacement[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.469 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockReplacement[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestCorruptMetadataFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.561 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestCorruptMetadataFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataDirs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.311 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataDirs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestSimulatedFSDatasetWithMultipleStorages[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.21 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestSimulatedFSDatasetWithMultipleStorages[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.mover.[1mTestStorageMover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 160.366 s - in org.apache.hadoop.hdfs.server.mover.[1mTestStorageMover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.mover.[1mTestMover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m19[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 217.743 s - in org.apache.hadoop.hdfs.server.mover.[1mTestMover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestIsMethodSupported[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.728 s - in org.apache.hadoop.hdfs.[1mTestIsMethodSupported[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSInotifyEventInputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.61 s - in org.apache.hadoop.hdfs.[1mTestDFSInotifyEventInputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSafeModeWithStripedFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.604 s - in org.apache.hadoop.hdfs.[1mTestSafeModeWithStripedFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.shortcircuit.[1mTestShortCircuitCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.045 s - in org.apache.hadoop.hdfs.shortcircuit.[1mTestShortCircuitCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.shortcircuit.[1mTestShortCircuitLocalRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.565 s - in org.apache.hadoop.hdfs.shortcircuit.[1mTestShortCircuitLocalRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelReadUtil[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m1[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.022 s - in org.apache.hadoop.hdfs.[1mTestParallelReadUtil[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelUnixDomainRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.866 s - in org.apache.hadoop.hdfs.[1mTestParallelUnixDomainRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestGetGroups[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.259 s - in org.apache.hadoop.hdfs.tools.[1mTestGetGroups[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestWebHDFSStoragePolicyCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.823 s - in org.apache.hadoop.hdfs.tools.[1mTestWebHDFSStoragePolicyCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDelegationTokenFetcher[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.587 s - in org.apache.hadoop.hdfs.tools.[1mTestDelegationTokenFetcher[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSZKFailoverController[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.713 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSZKFailoverController[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForContentSummary[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.197 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForContentSummary[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.371 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.019 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerWithStripedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.19 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerWithStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForAcl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.851 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSAdminWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m46[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 58.898 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSAdminWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestStoragePolicySatisfyAdminCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.789 s - in org.apache.hadoop.hdfs.tools.[1mTestStoragePolicySatisfyAdminCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineEditsViewer.[1mTestOfflineEditsViewer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 41.911 s - in org.apache.hadoop.hdfs.tools.offlineEditsViewer.[1mTestOfflineEditsViewer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSAdmin[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.596 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSAdmin[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestViewFSStoragePolicyCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.119 s - in org.apache.hadoop.hdfs.tools.[1mTestViewFSStoragePolicyCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDebugAdmin[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.395 s - in org.apache.hadoop.hdfs.tools.[1mTestDebugAdmin[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSHAAdminMiniCluster[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.968 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSHAAdminMiniCluster[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestStoragePolicyCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.198 s - in org.apache.hadoop.hdfs.tools.[1mTestStoragePolicyCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestAdminHelper[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.044 s - in org.apache.hadoop.hdfs.tools.[1mTestAdminHelper[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestGetConf[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.838 s - in org.apache.hadoop.hdfs.tools.[1mTestGetConf[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSHAAdmin[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.074 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSHAAdmin[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithMissingBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 143.291 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithMissingBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeRespectsBindHostKeys[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.143 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeRespectsBindHostKeys[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournal[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.32 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournal[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.003 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.94 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournaledEditsCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.616 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournaledEditsCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeSync[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 55.621 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeSync[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.[1mTestMiniJournalCluster[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.092 s - in org.apache.hadoop.hdfs.qjournal.[1mTestMiniJournalCluster[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumCall[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.205 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumCall[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestSegmentRecoveryComparator[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.2 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestSegmentRecoveryComparator[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestEpochsAreUnique[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.089 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestEpochsAreUnique[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestIPCLoggerChannel[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.641 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestIPCLoggerChannel[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestQJMWithFaults[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 144.845 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestQJMWithFaults[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumJournalManagerUnit[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.292 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumJournalManagerUnit[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumJournalManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m28[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.064 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumJournalManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.[1mTestSecureNNWithQJM[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.923 s - in org.apache.hadoop.hdfs.qjournal.[1mTestSecureNNWithQJM[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.[1mTestNNWithQJM[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.062 s - in org.apache.hadoop.hdfs.qjournal.[1mTestNNWithQJM[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestCrcCorruption[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.787 s - in org.apache.hadoop.hdfs.[1mTestCrcCorruption[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRollingUpgradeRollback[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.801 s - in org.apache.hadoop.hdfs.[1mTestRollingUpgradeRollback[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestKeyProviderCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.249 s - in org.apache.hadoop.hdfs.[1mTestKeyProviderCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.crypto.[1mTestHdfsCryptoStreams[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.305 s - in org.apache.hadoop.hdfs.crypto.[1mTestHdfsCryptoStreams[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStorageStateRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 51.423 s - in org.apache.hadoop.hdfs.[1mTestDFSStorageStateRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingPolicyWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.948 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingPolicyWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.995 s - in org.apache.hadoop.hdfs.[1mTestDFSUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFsShellPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.423 s - in org.apache.hadoop.hdfs.[1mTestFsShellPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSmallBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.747 s - in org.apache.hadoop.hdfs.[1mTestSmallBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingPolicyWithSnapshotWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.025 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingPolicyWithSnapshotWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDNFailure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 175.96 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDNFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestPipelines[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.92 s - in org.apache.hadoop.hdfs.[1mTestPipelines[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecodingDeletedData[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 305.296 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecodingDeletedData[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.net.[1mTestDFSNetworkTopology[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.435 s - in org.apache.hadoop.hdfs.net.[1mTestDFSNetworkTopology[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.net.[1mTestDFSNetworkTopologyPerformance[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m1[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.022 s - in org.apache.hadoop.hdfs.net.[1mTestDFSNetworkTopologyPerformance[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDistributedFileSystem[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m34[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 51.357 s - in org.apache.hadoop.hdfs.[1mTestDistributedFileSystem[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMiniDFSCluster[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.341 s - in org.apache.hadoop.hdfs.[1mTestMiniDFSCluster[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSafeMode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.542 s - in org.apache.hadoop.hdfs.[1mTestSafeMode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestStateAlignmentContextWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 75.132 s - in org.apache.hadoop.hdfs.[1mTestStateAlignmentContextWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedInputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 51.884 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedInputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeLayoutUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.844 s - in org.apache.hadoop.hdfs.[1mTestDatanodeLayoutUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeStartupFixesLegacyStorageIDs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.26 s - in org.apache.hadoop.hdfs.[1mTestDatanodeStartupFixesLegacyStorageIDs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSAddressConfig[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.363 s - in org.apache.hadoop.hdfs.[1mTestDFSAddressConfig[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppendRestart[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.374 s - in org.apache.hadoop.hdfs.[1mTestFileAppendRestart[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocolPB.[1mTestPBHelper[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m40[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.643 s - in org.apache.hadoop.hdfs.protocolPB.[1mTestPBHelper[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLocalDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.747 s - in org.apache.hadoop.hdfs.[1mTestLocalDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadWhileWriting[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.447 s - in org.apache.hadoop.hdfs.[1mTestReadWhileWriting[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSnapshotCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.974 s - in org.apache.hadoop.hdfs.[1mTestSnapshotCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.785 s - in org.apache.hadoop.hdfs.[1mTestParallelRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelShortCircuitReadNoChecksum[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.685 s - in org.apache.hadoop.hdfs.[1mTestParallelShortCircuitReadNoChecksum[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMaintenanceState[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m25[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 413.096 s - in org.apache.hadoop.hdfs.[1mTestMaintenanceState[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestExternalBlockReader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.015 s - in org.apache.hadoop.hdfs.[1mTestExternalBlockReader[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReplaceDatanodeOnFailure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.46 s - in org.apache.hadoop.hdfs.[1mTestReplaceDatanodeOnFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingExerciseAPIs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.606 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingExerciseAPIs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestClientReportBadBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.183 s - in org.apache.hadoop.hdfs.[1mTestClientReportBadBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodeBenchmarkThroughput[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.245 s - in org.apache.hadoop.hdfs.[1mTestErasureCodeBenchmarkThroughput[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestClose[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.178 s - in org.apache.hadoop.hdfs.[1mTestClose[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReplaceDatanodeFailureReplication[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 71.233 s - in org.apache.hadoop.hdfs.[1mTestReplaceDatanodeFailureReplication[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.741 s - in org.apache.hadoop.hdfs.[1mTestDatanodeReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingMultipleRacks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.89 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingMultipleRacks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCreation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m25[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 80.406 s - in org.apache.hadoop.hdfs.[1mTestFileCreation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMissingBlocksAlert[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.56 s - in org.apache.hadoop.hdfs.[1mTestMissingBlocksAlert[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSUpgradeFromImage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.479 s - in org.apache.hadoop.hdfs.[1mTestDFSUpgradeFromImage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestModTime[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.085 s - in org.apache.hadoop.hdfs.[1mTestModTime[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteConfigurationToDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.12 s - in org.apache.hadoop.hdfs.[1mTestWriteConfigurationToDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileStatusSerialization[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.309 s - in org.apache.hadoop.hdfs.[1mTestFileStatusSerialization[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRestartDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.622 s - in org.apache.hadoop.hdfs.[1mTestRestartDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLargeBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.94 s - in org.apache.hadoop.hdfs.[1mTestLargeBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.security.[1mTestDelegationToken[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.61 s - in org.apache.hadoop.hdfs.security.[1mTestDelegationToken[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.security.token.block.[1mTestBlockToken[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m20[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.922 s - in org.apache.hadoop.hdfs.security.token.block.[1mTestBlockToken[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.security.[1mTestDelegationTokenForProxyUser[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.116 s - in org.apache.hadoop.hdfs.security.[1mTestDelegationTokenForProxyUser[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppend[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.169 s - in org.apache.hadoop.hdfs.[1mTestFileAppend[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCreationDelete[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.138 s - in org.apache.hadoop.hdfs.[1mTestFileCreationDelete[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCorruption[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.237 s - in org.apache.hadoop.hdfs.[1mTestFileCorruption[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestGetFileChecksum[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.773 s - in org.apache.hadoop.hdfs.[1mTestGetFileChecksum[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestQuota[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m21[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.777 s - in org.apache.hadoop.hdfs.[1mTestQuota[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDataTransferProtocol[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.146 s - in org.apache.hadoop.hdfs.[1mTestDataTransferProtocol[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestListFilesInDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.462 s - in org.apache.hadoop.hdfs.[1mTestListFilesInDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestGetBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 52.409 s - in org.apache.hadoop.hdfs.[1mTestGetBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDeprecatedKeys[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.251 s - in org.apache.hadoop.hdfs.[1mTestDeprecatedKeys[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLeaseRecoveryStriped[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 46.21 s - in org.apache.hadoop.hdfs.[1mTestLeaseRecoveryStriped[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFSOutputSummer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.342 s - in org.apache.hadoop.hdfs.[1mTestFSOutputSummer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppend2[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.523 s - in org.apache.hadoop.hdfs.[1mTestFileAppend2[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedInputStreamWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.441 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedInputStreamWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestPread[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 120.346 s - in org.apache.hadoop.hdfs.[1mTestPread[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingPolicies[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m21[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 58.874 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingPolicies[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFetchImage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.023 s - in org.apache.hadoop.hdfs.[1mTestFetchImage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSUtil[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m33[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.582 s - in org.apache.hadoop.hdfs.[1mTestDFSUtil[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestAppendDifferentChecksum[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m3[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 9.811 s - in org.apache.hadoop.hdfs.[1mTestAppendDifferentChecksum[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStartupVersions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.584 s - in org.apache.hadoop.hdfs.[1mTestDFSStartupVersions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHDFSPolicyProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.143 s - in org.apache.hadoop.hdfs.[1mTestHDFSPolicyProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileLengthOnClusterRestart[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.738 s - in org.apache.hadoop.hdfs.[1mTestFileLengthOnClusterRestart[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBalancerBandwidth[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.554 s - in org.apache.hadoop.hdfs.[1mTestBalancerBandwidth[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDecommission[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m25[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 183.615 s - in org.apache.hadoop.hdfs.[1mTestDecommission[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelShortCircuitLegacyRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.997 s - in org.apache.hadoop.hdfs.[1mTestParallelShortCircuitLegacyRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRenameWhileOpen[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 47 s - in org.apache.hadoop.hdfs.[1mTestRenameWhileOpen[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppend3[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.371 s - in org.apache.hadoop.hdfs.[1mTestFileAppend3[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSOutputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.182 s - in org.apache.hadoop.hdfs.[1mTestDFSOutputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHttpPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.244 s - in org.apache.hadoop.hdfs.[1mTestHttpPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestApplyingStoragePolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.682 s - in org.apache.hadoop.hdfs.[1mTestApplyingStoragePolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestClientProtocolForPipelineRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 72.941 s - in org.apache.hadoop.hdfs.[1mTestClientProtocolForPipelineRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSetrepDecreasing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.351 s - in org.apache.hadoop.hdfs.[1mTestSetrepDecreasing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestEncryptedTransfer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m30[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 131.426 s - in org.apache.hadoop.hdfs.[1mTestEncryptedTransfer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestPersistBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.397 s - in org.apache.hadoop.hdfs.[1mTestPersistBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLease[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.244 s - in org.apache.hadoop.hdfs.[1mTestLease[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelShortCircuitRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.841 s - in org.apache.hadoop.hdfs.[1mTestParallelShortCircuitRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSConfigKeys[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.07 s - in org.apache.hadoop.hdfs.[1mTestDFSConfigKeys[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHDFSServerPorts[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.65 s - in org.apache.hadoop.hdfs.[1mTestHDFSServerPorts[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecoding[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.986 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecoding[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSFinalize[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.396 s - in org.apache.hadoop.hdfs.[1mTestDFSFinalize[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDistributedFileSystemWithECFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.817 s - in org.apache.hadoop.hdfs.[1mTestDistributedFileSystemWithECFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSRename[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.391 s - in org.apache.hadoop.hdfs.[1mTestDFSRename[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestInjectionForSimulatedStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.955 s - in org.apache.hadoop.hdfs.[1mTestInjectionForSimulatedStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHAAuxiliaryPort[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.093 s - in org.apache.hadoop.hdfs.[1mTestHAAuxiliaryPort[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHdfsAdmin[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.78 s - in org.apache.hadoop.hdfs.[1mTestHdfsAdmin[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReservedRawPaths[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.696 s - in org.apache.hadoop.hdfs.[1mTestReservedRawPaths[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHFlush[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.715 s - in org.apache.hadoop.hdfs.[1mTestHFlush[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRollingUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 100.371 s - in org.apache.hadoop.hdfs.[1mTestRollingUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLeaseRecovery2[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m8[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 85.177 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestLeaseRecovery2[m
[[1;31mERROR[m] testCloseWhileRecoverLease(org.apache.hadoop.hdfs.TestLeaseRecovery2)  Time elapsed: 16.259 s  <<< FAILURE!
java.lang.AssertionError: 
 Expected to find 'whereas it is under recovery' but got unexpected exception: java.io.IOException: Unable to close file because the last blockBP-412746799-172.17.0.5-1586346321552:blk_1073741826_1002 does not have enough number of replicas.
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:963)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:907)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:890)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestLeaseRecovery2.testCloseWhileRecoverLease(TestLeaseRecovery2.java:210)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:350)
	at org.apache.hadoop.test.GenericTestUtils.assertExceptionContains(GenericTestUtils.java:327)
	at org.apache.hadoop.hdfs.TestLeaseRecovery2.testCloseWhileRecoverLease(TestLeaseRecovery2.java:213)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: java.io.IOException: Unable to close file because the last blockBP-412746799-172.17.0.5-1586346321552:blk_1073741826_1002 does not have enough number of replicas.
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:963)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:907)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:890)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestLeaseRecovery2.testCloseWhileRecoverLease(TestLeaseRecovery2.java:210)
	... 27 more

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 77.186 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.004 s - in org.apache.hadoop.hdfs.[1mTestRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestConnCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.138 s - in org.apache.hadoop.hdfs.[1mTestConnCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBlockStoragePolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.597 s - in org.apache.hadoop.hdfs.[1mTestBlockStoragePolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteStripedFileWithFailure[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m1[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.054 s - in org.apache.hadoop.hdfs.[1mTestWriteStripedFileWithFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSInputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.1 s - in org.apache.hadoop.hdfs.[1mTestDFSInputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReplication[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 47.024 s - in org.apache.hadoop.hdfs.[1mTestReplication[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestExtendedAcls[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.148 s - in org.apache.hadoop.hdfs.[1mTestExtendedAcls[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCreationEmpty[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.946 s - in org.apache.hadoop.hdfs.[1mTestFileCreationEmpty[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCreationClient[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.166 s - in org.apache.hadoop.hdfs.[1mTestFileCreationClient[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLeaseRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.279 s - in org.apache.hadoop.hdfs.[1mTestLeaseRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecodingCorruptData[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 306.263 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecodingCorruptData[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDisableConnCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.459 s - in org.apache.hadoop.hdfs.[1mTestDisableConnCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSafeModeWithStripedFileWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.561 s - in org.apache.hadoop.hdfs.[1mTestSafeModeWithStripedFileWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeRegistration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.597 s - in org.apache.hadoop.hdfs.[1mTestDatanodeRegistration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDistributedFileSystemWithECFileWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.714 s - in org.apache.hadoop.hdfs.[1mTestDistributedFileSystemWithECFileWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocalMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.513 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocalMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderRemote[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.382 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderRemote[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestClientBlockVerification[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.598 s - in org.apache.hadoop.hdfs.client.impl.[1mTestClientBlockVerification[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderIoProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.415 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderIoProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocal[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m38[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.391 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocal[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderFactory[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.31 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderFactory[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocalLegacy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.836 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocalLegacy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSClientFailover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.959 s - in org.apache.hadoop.hdfs.[1mTestDFSClientFailover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.713 s - in org.apache.hadoop.hdfs.[1mTestDFSPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMultiThreadedHflush[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.999 s - in org.apache.hadoop.hdfs.[1mTestMultiThreadedHflush[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileStatusWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.937 s - in org.apache.hadoop.hdfs.[1mTestFileStatusWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestUnsetAndChangeDirectoryEcPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.177 s - in org.apache.hadoop.hdfs.[1mTestUnsetAndChangeDirectoryEcPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileChecksumCompositeCrc[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m32[m, Failures: 0, [1;31mErrors: [0;1;31m8[m, Skipped: 0, Time elapsed: 194.816 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestFileChecksumCompositeCrc[m
[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery12(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 6.192 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977604099-172.17.0.5-1586347227789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36495,DS-c26081d2-8a5c-46ee-85fb-8f4677127afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-b954d50a-2c70-432a-80d8-13899231f95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-6ce85ef3-311f-496a-a2ad-c580bc763b65,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-5058db69-bc57-47c2-aa4b-3b6e52ca1394,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-a5b11b48-5c70-41bf-8664-542c4c5959ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-35426866-d42e-49d3-9af2-efaf29db422e,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-f14704d9-0633-4deb-9616-8852a7a62775,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-f54f7a15-29a2-438c-912f-fe2a74ddd365,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12(TestFileChecksum.java:432)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.822 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502297807-172.17.0.5-1586347233979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35489,DS-0c414337-2ea6-4d8a-9b4e-63356726cb36,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-764b69b0-bce7-42e3-8f34-66b04bd252f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-36826b84-959a-4706-a35f-c1ffd6e39d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-ae1a7509-ba65-4b5c-b21c-df9c78901ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-5c48a5e0-91b8-40f1-8a63-36ef558688b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-dd9c3fe5-8947-4644-bac3-abb897d3f09a,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-9449ef75-5373-4da3-ae2c-7e5cf31301ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-1d3f09f9-9f80-4ca2-8d5b-e46e6d7a0cb5,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 6.12 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935334167-172.17.0.5-1586347239810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37898,DS-7fbc2e50-c355-4779-bfd0-ea2b3dcbe1de,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-abe8b2c0-6119-4b68-b6fd-1be5974311a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-ef46c774-a4e9-4217-b98e-aa446142763a,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-b94e895f-e3ad-4838-b051-0fa16553b634,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-dc018156-e43c-4744-82f6-8ffd847601d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-9b4c90ab-f5d5-4be0-a0da-bc0982b761e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-41ba904a-9b20-4dfa-a04a-f698050cfa13,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-2de454e4-05b9-4171-abfe-88267a32e933,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.606 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728452268-172.17.0.5-1586347245925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-9aa6ac0f-ab4f-46b2-ade6-9f4f213cfac7,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-0d7b28f2-c29a-4f5a-8a62-7d2a48770e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-a6c5deff-e499-42c0-8c1e-387244a851a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-de89ac97-e4f5-41e8-af8e-3002cf6208a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-c7c66e09-8d3a-4950-981b-9f45811a87b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-f0316fc3-583d-4f07-9a09-150b61ecbdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-6f5b9f14-dfa9-4d20-8c10-0e8771d42ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-b0819824-1f01-469d-812f-3355ab7f8853,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery17(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.604 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483111808-172.17.0.5-1586347256625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46373,DS-6c3b0076-c2c8-4745-85cb-7b485571597a,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-2bcf1647-f645-4ebb-b110-5c2f59636767,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-eb1cf5b3-87e3-4a46-be6e-c97773359d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-ccca1803-ab70-42af-a55c-60cc655688df,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-f4c119d9-d8e3-4974-b3b6-cc76c44304bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-70177b75-64b1-4644-9d56-a63219ba8547,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-6629b554-dd09-4bdc-a2ea-076546cba6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-509b8cd1-a235-478c-aaf7-9095c5737426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.793 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112555566-172.17.0.5-1586347287494:blk_-9223372036854775760_1003; getBlockSize()=37748736; corrupt=false; offset=75497472; locs=[DatanodeInfoWithStorage[127.0.0.1:37925,DS-f949b4ad-b3e9-4b80-84aa-252ba2cdeb27,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-dd727ba5-e727-46b8-90d6-a80798c0cbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-669a1913-9e43-4fa0-97c9-26870c6a136a,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-87b92b23-af5b-47eb-b324-13c5df9b9ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-cf4a0742-0268-4546-9b28-060fb2853ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-105f827e-9888-420f-8ff6-23d9488ddb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-cfe0703d-cd96-48a9-997f-f707ff27bb58,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-db437a72-113b-4c02-979c-931aaeceac06,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 7.215 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1040411281-172.17.0.5-1586347293296:blk_-9223372036854775632_1011; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33095,DS-0b65174a-5893-47f9-a1c4-0c4e669e2ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-46af0f73-3d7c-45d7-b111-1ee11f55bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-ac67d746-44f4-4ce4-805e-a0f57cdc0061,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-eb72b650-14d9-4e26-a5a9-a06a19e7d249,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-b7cf7777-1094-4187-9782-1c3d8b2a234c,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-10770109-9b7a-4ca2-9984-73e4ed815ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-24cf28f3-fe19-46b6-96c2-696b24976963,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-9dbd00f6-48e3-4894-824d-672f07c00610,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery8(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.657 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463095502-172.17.0.5-1586347396521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43488,DS-56cb9c52-cc8a-46b4-b282-2ad7673cf777,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-017f8aa0-09fe-4c2d-9d3d-772cf8dc254c,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-fe191a1b-90cf-42c2-895e-f1a64e2c88d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-8f1333c4-b8fa-4543-8885-c4c375610257,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-daf746c6-57b1-4ad3-a8d7-e49d782d7055,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-1e7a4f19-dfaa-40f2-939f-500377b8c61e,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-7d18fc18-f8cb-492e-902e-abbd25301ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-670a12e4-b1ff-413b-b286-9dde623f5320,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8(TestFileChecksum.java:388)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileStatus[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.057 s - in org.apache.hadoop.hdfs.[1mTestFileStatus[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteBlockGetsBlockLengthHint[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.178 s - in org.apache.hadoop.hdfs.[1mTestWriteBlockGetsBlockLengthHint[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMultipleNNPortQOP[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.299 s - in org.apache.hadoop.hdfs.[1mTestMultipleNNPortQOP[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestEncryptionZonesWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.783 s - in org.apache.hadoop.hdfs.[1mTestEncryptionZonesWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestTrashWithSecureEncryptionZones[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.548 s - in org.apache.hadoop.hdfs.[1mTestTrashWithSecureEncryptionZones[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestCombinedHostsFileReader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.372 s - in org.apache.hadoop.hdfs.util.[1mTestCombinedHostsFileReader[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestLightWeightHashSet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.146 s - in org.apache.hadoop.hdfs.util.[1mTestLightWeightHashSet[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestCyclicIteration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.048 s - in org.apache.hadoop.hdfs.util.[1mTestCyclicIteration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestMD5FileUtils[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.222 s - in org.apache.hadoop.hdfs.util.[1mTestMD5FileUtils[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestLightWeightLinkedSet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m17[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.152 s - in org.apache.hadoop.hdfs.util.[1mTestLightWeightLinkedSet[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestStripedBlockUtil[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.843 s - in org.apache.hadoop.hdfs.util.[1mTestStripedBlockUtil[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestBestEffortLongFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.172 s - in org.apache.hadoop.hdfs.util.[1mTestBestEffortLongFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestXMLUtils[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.049 s - in org.apache.hadoop.hdfs.util.[1mTestXMLUtils[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestDiff[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.61 s - in org.apache.hadoop.hdfs.util.[1mTestDiff[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestAtomicFileOutputStream[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m4[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.153 s - in org.apache.hadoop.hdfs.util.[1mTestAtomicFileOutputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileStatusWithDefaultECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.82 s - in org.apache.hadoop.hdfs.[1mTestFileStatusWithDefaultECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppend4[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.21 s - in org.apache.hadoop.hdfs.[1mTestFileAppend4[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelShortCircuitReadUnCached[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.678 s - in org.apache.hadoop.hdfs.[1mTestParallelShortCircuitReadUnCached[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBlockMissingException[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.555 s - in org.apache.hadoop.hdfs.[1mTestBlockMissingException[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestAppendSnapshotTruncate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.583 s - in org.apache.hadoop.hdfs.[1mTestAppendSnapshotTruncate[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSMkdirs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.962 s - in org.apache.hadoop.hdfs.[1mTestDFSMkdirs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRollingUpgradeDowngrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.598 s - in org.apache.hadoop.hdfs.[1mTestRollingUpgradeDowngrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSShellGenericOptions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.79 s - in org.apache.hadoop.hdfs.[1mTestDFSShellGenericOptions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBlocksScheduledCounter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.588 s - in org.apache.hadoop.hdfs.[1mTestBlocksScheduledCounter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSInotifyEventInputStreamKerberized[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m1[m, Failures: 0, [1;31mErrors: [0;1;31m1[m, Skipped: 0, Time elapsed: 17.498 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestDFSInotifyEventInputStreamKerberized[m
[[1;31mERROR[m] testWithKerberizedCluster(org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized)  Time elapsed: 17.378 s  <<< ERROR!
java.io.IOException: DestHost:destPort localhost:13716 , LocalHost:localPort 4dcd8edd9737/172.17.0.5:0. Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:808)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy26.getEditsFromTxid(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getEditsFromTxid(ClientNamenodeProtocolTranslatorPB.java:1788)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy27.getEditsFromTxid(Unknown Source)
	at org.apache.hadoop.hdfs.DFSInotifyEventInputStream.poll(DFSInotifyEventInputStream.java:105)
	at org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized$1.run(TestDFSInotifyEventInputStreamKerberized.java:142)
	at org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized$1.run(TestDFSInotifyEventInputStreamKerberized.java:113)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.hdfs.TestDFSInotifyEventInputStreamKerberized.testWithKerberizedCluster(TestDFSInotifyEventInputStreamKerberized.java:113)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:770)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:733)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:827)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:421)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1606)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	... 33 more
Caused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:211)
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:408)
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:627)
	at org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:421)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:814)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:810)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:810)
	... 36 more
Caused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
	at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:162)
	at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:122)
	at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:189)
	at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:224)
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:212)
	at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179)
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:192)
	... 45 more

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileChecksum[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m32[m, Failures: 0, [1;31mErrors: [0;1;31m9[m, Skipped: 0, Time elapsed: 191.74 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestFileChecksum[m
[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery11(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 7.474 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380859365-172.17.0.5-1586347650007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-af0d3ee2-d4b6-4e79-b6c0-2eb250c44119,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-922ca03a-8123-4cf2-8b25-57bc5bf1d557,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-c5f1ad01-66f3-451e-9d69-98734061a53c,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-5f6bac8a-1082-445b-ab81-9d15f99bd37f,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-6d2aa0d9-0d8b-4fe3-afce-e924d4b87f23,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-212fa375-1e3a-4e12-b32b-1e5275d244df,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-63b4879c-2008-4586-9969-0799d08cc332,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-7117f456-4f1a-4a78-b669-09e982056ce0,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery11(TestFileChecksum.java:421)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 6.189 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272923111-172.17.0.5-1586347663443:blk_-9223372036854775728_1005; getBlockSize()=37748736; corrupt=false; offset=150994944; locs=[DatanodeInfoWithStorage[127.0.0.1:44220,DS-c529b5a6-1f87-4529-a595-2c65b0fdc4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-a2fa67a5-7231-44c7-9034-25c7314e1837,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-7c9ad8df-d2d6-49f0-a807-a1b1497338ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-b6998efe-b215-4b21-9eff-573722c5c5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-3d544792-9c22-4c43-974b-c6660d16872c,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-889dc818-9355-4c5a-88e4-ce9ffceba56d,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-810e74e5-0686-4636-8655-8c60ecd3f533,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-95298b64-298d-463e-ba32-1e4fa5251ceb,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 6.334 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1779394068-172.17.0.5-1586347669625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37746,DS-ae9f5f06-af5a-43c4-90b0-178040824fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-fb5259b3-de95-4b70-966e-2396b5dfd6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-365633dc-8397-440d-8427-0a421db82475,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-10fed18b-ac54-426f-aceb-cf879f7138bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-7c9efdc7-234b-4ac6-ae39-57a4f2a8676c,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-78dcb4bf-1a48-42f4-b9a7-a49099616440,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-0e807d57-8fde-4212-a0a6-c42ed2a324f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-e4e4c970-f685-4e3d-b712-a6344ac15ac6,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.498 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-480259232-172.17.0.5-1586347675955:blk_-9223372036854775760_1003; getBlockSize()=37748736; corrupt=false; offset=75497472; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-4510a4b8-94dd-4712-b7b2-099f550b7e43,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-c2f9fc0d-ac92-4cf2-943d-b3e85daff807,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-31a61758-e08a-407e-ab60-5618a19f64f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-c8f409e9-502e-4976-8a73-532676f9d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-2884cd81-1f5f-48dc-83cb-a3a122d11662,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-513b7cb0-b14c-4e7b-b8e4-e79c4b9bb5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-c0076cdf-7bb0-4a59-a215-2f040fbbb583,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-237de3c9-396a-4d1c-ba8f-2d3daa0e6cc5,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery20(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.56 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100547599-172.17.0.5-1586347704117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44358,DS-6109392d-9063-487b-8548-0c0cf3358246,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-80050d26-5b1e-4789-8b54-a4961555d13c,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-c20e56d7-99f0-4d26-a3fa-8554ed59ea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-d7b73ec3-8c6c-4cab-a606-1d6566298f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-e5b63cd3-7c4f-4822-9ecd-3e19120789b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-57e14bad-f26d-4914-950d-699c2f66ff21,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-901e530b-958c-45f4-91a5-3b607ebc4a24,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-a6ab406f-61de-42ad-b46e-676626583107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.316 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83206433-172.17.0.5-1586347719019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:39021,DS-8128fd8a-e0b5-4b6c-aea4-14b1b0df0b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-dc1bad20-d4b3-4dfb-9ada-cee75b52240d,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-c9e0bc41-68e6-4c0c-8584-140ed02b7c05,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-62c57336-1a09-4992-b52e-bf527454c3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-1014d5f6-6bc6-4779-ba27-bc27278dad71,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-b8e25b9b-5ac5-4ade-aa80-edc82a012744,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-d78f45ea-f0f9-4485-b040-f9b50c2edf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-fcc0fe5a-c4c9-412d-8fe2-36466ee1f6eb,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 6.809 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-854381297-172.17.0.5-1586347724343:blk_-9223372036854775616_1012; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:40966,DS-2636555d-fbe6-4128-8123-b4c394e093f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-22590be6-5e98-4b98-93b0-e90b0afa5153,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-1906aed7-c57b-4a17-8e04-73e02e08e461,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-e922891b-d58b-453c-8736-e693cda73bed,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-075efdd9-02eb-4484-b164-adf38232fd70,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-b763255f-6111-42c9-a982-c6b55bd40c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-b8a61259-03b1-4c2a-9f0b-2b18c23f3aac,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-7c453fc1-ef9e-4854-ba1f-7f22dd6ef233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery2(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.277 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-888160396-172.17.0.5-1586347790257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42094,DS-7995fb11-4d23-4999-8dfc-863f12cf5837,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-1c121fee-8f8f-4f43-bd0d-4ee7c63154aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-f531e64d-4721-44cb-a55f-f0eb6f83da4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-acb3d04b-bd5f-4181-88ee-9bcdbbddc894,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-d2dc6c66-8d2c-45a2-b841-cc1f5ddceec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-60892219-b7b5-47f2-a346-1c5fe0e68fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-16f4ddbf-23f8-4add-8095-4f22f8366a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-0223e220-0296-4748-84bf-015cf83869fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery8(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.476 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880435823-172.17.0.5-1586347822299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44489,DS-a9cfd057-f034-4b37-9d99-e959f468ca52,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-549a5506-b02e-4a20-adf5-af138eff5e66,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-45b4e7a4-315e-4c95-b542-396c0cff1dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-5d16dcdf-fec9-4bc5-bf27-5b8fac961f89,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-dd9805ed-8a41-4465-87dd-cd6a4ae6ee65,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-86c96b5d-a616-4e2e-b06b-d529fdbd6ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-60dc8b20-9ec0-4040-8f43-36d6bd36bbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-f9fba309-8dc6-4cf3-9f99-c7c45ee6e1e0,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8(TestFileChecksum.java:388)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestEncryptionZonesWithKMS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m45[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 117.285 s - in org.apache.hadoop.hdfs.[1mTestEncryptionZonesWithKMS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSClientExcludedNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.766 s - in org.apache.hadoop.hdfs.[1mTestDFSClientExcludedNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSRemove[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.022 s - in org.apache.hadoop.hdfs.[1mTestDFSRemove[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSShell[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m49[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 22.177 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestDFSShell[m
[[1;31mERROR[m] testCopyFromLocalWithPermissionDenied(org.apache.hadoop.hdfs.TestDFSShell)  Time elapsed: 0.093 s  <<< FAILURE!
java.lang.AssertionError: put is working expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.apache.hadoop.hdfs.TestDFSShell.testCopyFromLocalWithPermissionDenied(TestDFSShell.java:2765)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeDeath[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 61.71 s - in org.apache.hadoop.hdfs.[1mTestDatanodeDeath[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSClientSocketSize[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.815 s - in org.apache.hadoop.hdfs.[1mTestDFSClientSocketSize[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSRollback[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.628 s - in org.apache.hadoop.hdfs.[1mTestDFSRollback[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSeekBug[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.178 s - in org.apache.hadoop.hdfs.[1mTestSeekBug[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFSInputChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.011 s - in org.apache.hadoop.hdfs.[1mTestFSInputChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithFailure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 110.969 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBlockTokenWrappingQOP[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 55.227 s - in org.apache.hadoop.hdfs.[1mTestBlockTokenWrappingQOP[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDecommissionWithStriped[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 87.52 s - in org.apache.hadoop.hdfs.[1mTestDecommissionWithStriped[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSecureEncryptionZoneWithKMS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.129 s - in org.apache.hadoop.hdfs.[1mTestSecureEncryptionZoneWithKMS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestAbandonBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.136 s - in org.apache.hadoop.hdfs.[1mTestAbandonBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingPoliciesWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m21[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 46.258 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingPoliciesWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHDFSFileSystemContract[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m44[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.335 s - in org.apache.hadoop.hdfs.[1mTestHDFSFileSystemContract[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSetTimes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.151 s - in org.apache.hadoop.hdfs.[1mTestSetTimes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m35[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 137.187 s - in org.apache.hadoop.hdfs.web.[1mTestWebHDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsUrl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.148 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsUrl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithAuthenticationFilter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.689 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithAuthenticationFilter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.resources.[1mTestParam[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m34[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.301 s - in org.apache.hadoop.hdfs.web.resources.[1mTestParam[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestJsonUtil[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.466 s - in org.apache.hadoop.hdfs.web.[1mTestJsonUtil[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHDFSXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.898 s - in org.apache.hadoop.hdfs.web.[1mTestWebHDFSXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHDFSForHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.192 s - in org.apache.hadoop.hdfs.web.[1mTestWebHDFSForHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithMultipleNameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.778 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithMultipleNameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithRestCsrfPreventionFilter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m32[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.084 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithRestCsrfPreventionFilter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestAuthFilter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.339 s - in org.apache.hadoop.hdfs.web.[1mTestAuthFilter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsTimeouts[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.425 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsTimeouts[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestFSMainOperationsWebHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m53[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.208 s - in org.apache.hadoop.hdfs.web.[1mTestFSMainOperationsWebHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHDFSAcl[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m66[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 26.849 s - in org.apache.hadoop.hdfs.web.[1mTestWebHDFSAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestHttpsFileSystem[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.79 s - in org.apache.hadoop.hdfs.web.[1mTestHttpsFileSystem[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsFileSystemContract[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m53[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.743 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsFileSystemContract[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsTokens[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.893 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsTokens[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestTrashWithEncryptionZones[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.084 s - in org.apache.hadoop.hdfs.[1mTestTrashWithEncryptionZones[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHDFSTrash[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.963 s - in org.apache.hadoop.hdfs.[1mTestHDFSTrash[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 58.35 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestListFilesInFileContext[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.369 s - in org.apache.hadoop.hdfs.[1mTestListFilesInFileContext[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDataStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.76 s - in org.apache.hadoop.hdfs.[1mTestDataStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithFailureWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 105.331 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithFailureWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileConcurrentReader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.533 s - in org.apache.hadoop.hdfs.[1mTestFileConcurrentReader[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSClientRetries[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 144.706 s - in org.apache.hadoop.hdfs.[1mTestDFSClientRetries[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDataTransferKeepalive[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.536 s - in org.apache.hadoop.hdfs.[1mTestDataTransferKeepalive[m
[[1;34mINFO[m] Running org.apache.hadoop.security.[1mTestPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.029 s - in org.apache.hadoop.security.[1mTestPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.security.[1mTestRefreshUserMappings[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.451 s - in org.apache.hadoop.security.[1mTestRefreshUserMappings[m
[[1;34mINFO[m] Running org.apache.hadoop.security.[1mTestPermissionSymlinks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.375 s - in org.apache.hadoop.security.[1mTestPermissionSymlinks[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.shell.[1mTestHdfsTextCommand[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.528 s - in org.apache.hadoop.fs.shell.[1mTestHdfsTextCommand[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestHDFSFileContextMainOperations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m77[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.719 s - in org.apache.hadoop.fs.[1mTestHDFSFileContextMainOperations[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestSymlinkHdfsFileSystem[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m74[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m2[m, Time elapsed: 15.91 s - in org.apache.hadoop.fs.[1mTestSymlinkHdfsFileSystem[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestEnhancedByteBufferAccess[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m10[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 15.836 s - in org.apache.hadoop.fs.[1mTestEnhancedByteBufferAccess[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestSymlinkHdfsDisable[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.103 s - in org.apache.hadoop.fs.[1mTestSymlinkHdfsDisable[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestGlobPaths[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m37[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m6[m, Time elapsed: 4.765 s - in org.apache.hadoop.fs.[1mTestGlobPaths[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestHdfsNativeCodeLoader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.113 s - in org.apache.hadoop.fs.[1mTestHdfsNativeCodeLoader[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestUrlStreamHandler[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.384 s - in org.apache.hadoop.fs.[1mTestUrlStreamHandler[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestResolveHdfsSymlink[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.822 s - in org.apache.hadoop.fs.[1mTestResolveHdfsSymlink[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.permission.[1mTestStickyBit[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.856 s - in org.apache.hadoop.fs.permission.[1mTestStickyBit[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestSymlinkHdfsFileContext[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m71[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.163 s - in org.apache.hadoop.fs.[1mTestSymlinkHdfsFileContext[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractSeek[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m18[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.395 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractSeek[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractSetTimes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.822 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractSetTimes[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractRename[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.874 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractRename[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractDelete[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.722 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractDelete[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractCreate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.419 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractCreate[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractRootDirectory[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.085 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractRootDirectory[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractMultipartUploader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.898 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractMultipartUploader[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractPathHandle[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m32[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.718 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractPathHandle[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractGetFileStatus[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m18[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.661 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractGetFileStatus[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractAppend[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.475 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractAppend[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractOpen[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.735 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractOpen[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractConcat[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.831 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractConcat[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractMkdir[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.96 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractMkdir[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestFcHdfsCreateMkdir[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.627 s - in org.apache.hadoop.fs.[1mTestFcHdfsCreateMkdir[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.loadGenerator.[1mTestLoadGenerator[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.586 s - in org.apache.hadoop.fs.loadGenerator.[1mTestLoadGenerator[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestUnbuffer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.943 s - in org.apache.hadoop.fs.[1mTestUnbuffer[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestFcHdfsPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.551 s - in org.apache.hadoop.fs.[1mTestFcHdfsPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemLinkFallback[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m75[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.075 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemLinkFallback[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsAtHdfsRoot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m65[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.849 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsAtHdfsRoot[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithTruncate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.935 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithTruncate[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithAcls[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.175 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithAcls[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsDefaultValue[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.898 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsDefaultValue[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemAtHdfsRoot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m72[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.428 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemAtHdfsRoot[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsFileStatusHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.806 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsFileStatusHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m78[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.906 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemLinkMergeSlash[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m76[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.624 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemLinkMergeSlash[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsWithXAttrs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.083 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsWithXAttrs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsWithAcls[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.093 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsWithAcls[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m65[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.851 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithXAttrs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.168 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithXAttrs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestWebHdfsFileContextMainOperations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m68[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.668 s - in org.apache.hadoop.fs.[1mTestWebHdfsFileContextMainOperations[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestSWebHdfsFileContextMainOperations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m68[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.012 s - in org.apache.hadoop.fs.[1mTestSWebHdfsFileContextMainOperations[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestFcHdfsSetUMask[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.652 s - in org.apache.hadoop.fs.[1mTestFcHdfsSetUMask[m
[[1;34mINFO[m] Running org.apache.hadoop.[1mTestGenericRefresh[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.875 s - in org.apache.hadoop.[1mTestGenericRefresh[m
[[1;34mINFO[m] Running org.apache.hadoop.metrics2.sink.[1mTestRollingFileSystemSinkWithHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.865 s - in org.apache.hadoop.metrics2.sink.[1mTestRollingFileSystemSinkWithHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.metrics2.sink.[1mTestRollingFileSystemSinkWithSecureHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.266 s - in org.apache.hadoop.metrics2.sink.[1mTestRollingFileSystemSinkWithSecureHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.[1mTestRefreshCallQueue[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.577 s - in org.apache.hadoop.[1mTestRefreshCallQueue[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestAclCLIWithPosixAclInheritance[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.375 s - in org.apache.hadoop.cli.[1mTestAclCLIWithPosixAclInheritance[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestErasureCodingCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.096 s - in org.apache.hadoop.cli.[1mTestErasureCodingCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestHDFSCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 93.446 s - in org.apache.hadoop.cli.[1mTestHDFSCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestCacheAdminCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.235 s - in org.apache.hadoop.cli.[1mTestCacheAdminCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestXAttrCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.482 s - in org.apache.hadoop.cli.[1mTestXAttrCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestDeleteCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.809 s - in org.apache.hadoop.cli.[1mTestDeleteCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestCryptoAdminCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.976 s - in org.apache.hadoop.cli.[1mTestCryptoAdminCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestAclCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.246 s - in org.apache.hadoop.cli.[1mTestAclCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.tracing.[1mTestTracing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.041 s - in org.apache.hadoop.tracing.[1mTestTracing[m
[[1;34mINFO[m] Running org.apache.hadoop.tracing.[1mTestTracingShortCircuitLocalRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.438 s - in org.apache.hadoop.tracing.[1mTestTracingShortCircuitLocalRead[m
[[1;34mINFO[m] Running org.apache.hadoop.tracing.[1mTestTraceAdmin[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.971 s - in org.apache.hadoop.tracing.[1mTestTraceAdmin[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;31mERROR[m] [1;31mFailures: [m
[[1;31mERROR[m] [1;31m  TestDFSShell.testCopyFromLocalWithPermissionDenied:2765 put is working expected:<1> but was:<0>[m
[[1;31mERROR[m] [1;31m  TestLeaseRecovery2.testCloseWhileRecoverLease:213  Expected to find 'whereas it is under recovery' but got unexpected exception: java.io.IOException: Unable to close file because the last blockBP-412746799-172.17.0.5-1586346321552:blk_1073741826_1002 does not have enough number of replicas.
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:963)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:907)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:890)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:845)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:101)
	at org.apache.hadoop.hdfs.TestLeaseRecovery2.testCloseWhileRecoverLease(TestLeaseRecovery2.java:210)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[m
[[1;31mERROR[m] [1;31m  TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverAllParityBlocks:180->TestReconstructStripedFile.assertFileBlocksReconstruction:399 arrays first differed at element [0]; expected:<1> but was:<0>[m
[[1;31mERROR[m] [1;31m  TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverAnyBlocks1:229->TestReconstructStripedFile.assertFileBlocksReconstruction:399 arrays first differed at element [1048064]; expected:<1> but was:<0>[m
[[1;31mERROR[m] [1;31m  TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverOneDataBlock1:208->TestReconstructStripedFile.assertFileBlocksReconstruction:399 arrays first differed at element [0]; expected:<1> but was:<0>[m
[[1;31mERROR[m] [1;31m  TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverOneDataBlock2:215->TestReconstructStripedFile.assertFileBlocksReconstruction:399 arrays first differed at element [0]; expected:<1> but was:<0>[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailure.testDNFailToStartWithDataDirNonWritable:535->startNewDataNodeWithDiskFailure:572 Failed to get expected IOException[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailure.testDataNodeFailToStartWithVolumeFailure:503->startNewDataNodeWithDiskFailure:572 Failed to get expected IOException[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailureToleration.testValidVolumesAtStartup:131 The DN shouldn't have a bad directory.[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailureToleration.testVolumeAndTolerableConfiguration:208->testVolumeConfig:259 expected:<false> but was:<true>[m
[[1;31mERROR[m] [1;31m  TestDiskBalancer.testDiskBalancerWithFedClusterWithOneNameServiceEmpty:278[m
[[1;31mERROR[m] [1;31m  TestCheckpoint.testCheckpointWithSeparateDirsAfterNameFails:2143 Did not fail to checkpoint when there are no valid storage dirs[m
[[1;31mERROR[m] [1;31m  TestCheckpoint.testNameDirError:180 NN should have failed to start with /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 set unreadable[m
[[1;31mERROR[m] [1;31m  TestEditLog.testFailedOpen:1068 Did no throw exception on only having a bad dir[m
[[1;31mERROR[m] [1;31m  TestEditLog.testFailedOpen:1068 Did no throw exception on only having a bad dir[m
[[1;31mERROR[m] [1;31m  TestFileJournalManager.testDoPreUpgradeIOError Expected test to throw (an instance of java.io.IOException and exception with message a string containing "failure in native rename")[m
[[1;31mERROR[m] [1;31m  TestNNStorageRetentionFunctional.testPurgingWithNameEditsDirAfterFailure:117 Bad files matching fsimage_\d* in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/nn0/current expected:<...e_000000000000000000[2,fsimage_0000000000000000004]> but was:<...e_000000000000000000[4,fsimage_0000000000000000006]>[m
[[1;31mERROR[m] [1;31m  TestNameNodeMXBean.testNameNodeMXBeanInfo:257[m
[[1;31mERROR[m] [1;31m  TestSaveNamespace.testReinsertnamedirsInSavenamespace:292 Savenamespace should have marked one directory as bad. But found 0 bad directories.[m
[[1;31mERROR[m] [1;31m  TestStartup.testNNFailToStartOnReadOnlyNNDir:744 Restarting NN should fail on read only NN dir.[m
[[1;31mERROR[m] [1;31m  TestStorageRestore.testStorageRestoreFailure:416[m
[[1;31mERROR[m] [1;31m  TestFailureOfSharedDir.testFailureOfSharedDir:169 Succeeded in rolling edit log despite shared dir being deleted[m
[[1;31mERROR[m] [1;31mErrors: [m
[[1;31mERROR[m] [1;31m  TestDFSInotifyEventInputStreamKerberized.testWithKerberizedCluster:113 ? IO De...[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->getFileChecksum:586 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery11:421->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2:322->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20:533->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8:388->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->TestFileChecksum.getFileChecksum:586 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12:432->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17:493->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8:388->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailure.testVolumeFailure:195 ? Timeout Timed out waiting fo...[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailureToleration.testFailedVolumeOnStartupIsCounted:299 ? Timeout[m
[[1;31mERROR[m] [1;31m  TestDirectoryScanner.testScanDirectoryStructureWarn:426 ?  test timed out afte...[m
[[1;31mERROR[m] [1;31m  TestFsDatasetImpl.testCleanShutdownOfVolume:700 ? Timeout Timed out waiting fo...[m
[[1;34mINFO[m] 
[[1;31mERROR[m] [1;31mTests run: 5835, Failures: 22, Errors: 22, Skipped: 21[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;31mBUILD FAILURE[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  05:29 h
[[1;34mINFO[m] Finished at: 2020-04-08T12:44:29Z
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;31mERROR[m] Failed to execute goal [32morg.apache.maven.plugins:maven-surefire-plugin:3.0.0-M1:test[m [1m(default-test)[m on project [36mhadoop-hdfs[m: [1;31mThere was a timeout or other error in the fork[m -> [1m[Help 1][m
[[1;31mERROR[m] 
[[1;31mERROR[m] To see the full stack trace of the errors, re-run Maven with the [1m-e[m switch.
[[1;31mERROR[m] Re-run Maven using the [1m-X[m switch to enable full debug logging.
[[1;31mERROR[m] 
[[1;31mERROR[m] For more information about the errors and possible solutions, please read the following articles:
[[1;31mERROR[m] [1m[Help 1][m http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
