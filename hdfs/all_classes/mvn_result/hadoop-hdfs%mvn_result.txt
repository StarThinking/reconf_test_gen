[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-------------------< [0;36morg.apache.hadoop:hadoop-hdfs[0;1m >--------------------[m
[[1;34mINFO[m] [1mBuilding Apache Hadoop HDFS 3.2.1[m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.pom
Downloading from repository.jboss.org: https://repository.jboss.org/nexus/content/groups/public/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.pom
Downloading from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.pom
Progress (1): 2.2 kB                    Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.pom (2.2 kB at 12 kB/s)
Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.pom
Downloading from repository.jboss.org: https://repository.jboss.org/nexus/content/groups/public/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.pom
Downloading from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.pom
Progress (1): 2.2/9.2 kBProgress (1): 5.0/9.2 kBProgress (1): 7.8/9.2 kBProgress (1): 9.2 kB                        Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.pom (9.2 kB at 141 kB/s)
Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.jar
Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.jar
Downloading from apache.snapshots.https: https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1-tests.jar
Downloading from repository.jboss.org: https://repository.jboss.org/nexus/content/groups/public/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.jar
Downloading from repository.jboss.org: https://repository.jboss.org/nexus/content/groups/public/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.jar
Downloading from repository.jboss.org: https://repository.jboss.org/nexus/content/groups/public/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1-tests.jar
Downloading from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.jar
Downloading from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.jar
Downloading from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1-tests.jar
Progress (1): 2.2/53 kBProgress (1): 5.0/53 kBProgress (1): 7.7/53 kBProgress (1): 10/53 kB Progress (1): 13/53 kBProgress (1): 16/53 kBProgress (1): 19/53 kBProgress (1): 21/53 kBProgress (1): 24/53 kBProgress (1): 27/53 kBProgress (1): 30/53 kBProgress (1): 32/53 kBProgress (1): 36/53 kBProgress (1): 40/53 kBProgress (1): 45/53 kBProgress (1): 49/53 kBProgress (1): 53/53 kBProgress (1): 53 kB   Progress (2): 53 kB | 2.2/131 kBProgress (3): 53 kB | 2.2/131 kB | 2.2/208 kBProgress (3): 53 kB | 5.0/131 kB | 2.2/208 kBProgress (3): 53 kB | 5.0/131 kB | 5.0/208 kBProgress (3): 53 kB | 7.7/131 kB | 5.0/208 kBProgress (3): 53 kB | 7.7/131 kB | 7.7/208 kBProgress (3): 53 kB | 7.7/131 kB | 10/208 kB                                             Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-minikdc/3.2.1/hadoop-minikdc-3.2.1.jar (53 kB at 669 kB/s)
Progress (2): 10/131 kB | 10/208 kBProgress (2): 10/131 kB | 13/208 kBProgress (2): 13/131 kB | 13/208 kBProgress (2): 13/131 kB | 16/208 kBProgress (2): 16/131 kB | 16/208 kBProgress (2): 16/131 kB | 19/208 kBProgress (2): 19/131 kB | 19/208 kBProgress (2): 19/131 kB | 21/208 kBProgress (2): 21/131 kB | 21/208 kBProgress (2): 21/131 kB | 24/208 kBProgress (2): 24/131 kB | 24/208 kBProgress (2): 24/131 kB | 27/208 kBProgress (2): 27/131 kB | 27/208 kBProgress (2): 27/131 kB | 30/208 kBProgress (2): 30/131 kB | 30/208 kBProgress (2): 30/131 kB | 32/208 kBProgress (2): 32/131 kB | 32/208 kBProgress (2): 36/131 kB | 32/208 kBProgress (2): 40/131 kB | 32/208 kBProgress (2): 45/131 kB | 32/208 kBProgress (2): 49/131 kB | 32/208 kBProgress (2): 49/131 kB | 36/208 kBProgress (2): 49/131 kB | 40/208 kBProgress (2): 53/131 kB | 40/208 kBProgress (2): 53/131 kB | 45/208 kBProgress (2): 57/131 kB | 45/208 kBProgress (2): 57/131 kB | 49/208 kBProgress (2): 61/131 kB | 49/208 kBProgress (2): 65/131 kB | 49/208 kBProgress (2): 65/131 kB | 53/208 kBProgress (2): 65/131 kB | 57/208 kBProgress (2): 69/131 kB | 57/208 kBProgress (2): 69/131 kB | 61/208 kBProgress (2): 73/131 kB | 61/208 kBProgress (2): 73/131 kB | 65/208 kBProgress (2): 77/131 kB | 65/208 kBProgress (2): 81/131 kB | 65/208 kBProgress (2): 81/131 kB | 69/208 kBProgress (2): 81/131 kB | 73/208 kBProgress (2): 81/131 kB | 77/208 kBProgress (2): 81/131 kB | 81/208 kBProgress (2): 85/131 kB | 81/208 kBProgress (2): 90/131 kB | 81/208 kBProgress (2): 94/131 kB | 81/208 kBProgress (2): 98/131 kB | 81/208 kBProgress (2): 98/131 kB | 85/208 kBProgress (2): 98/131 kB | 90/208 kBProgress (2): 102/131 kB | 90/208 kBProgress (2): 102/131 kB | 94/208 kBProgress (2): 106/131 kB | 94/208 kBProgress (2): 106/131 kB | 98/208 kBProgress (2): 110/131 kB | 98/208 kBProgress (2): 114/131 kB | 98/208 kBProgress (2): 114/131 kB | 102/208 kBProgress (2): 118/131 kB | 102/208 kBProgress (2): 118/131 kB | 106/208 kBProgress (2): 122/131 kB | 106/208 kBProgress (2): 122/131 kB | 110/208 kBProgress (2): 126/131 kB | 110/208 kBProgress (2): 126/131 kB | 114/208 kBProgress (2): 131/131 kB | 114/208 kBProgress (2): 131 kB | 114/208 kB    Progress (2): 131 kB | 118/208 kBProgress (2): 131 kB | 122/208 kBProgress (2): 131 kB | 126/208 kBProgress (2): 131 kB | 131/208 kBProgress (2): 131 kB | 135/208 kBProgress (2): 131 kB | 139/208 kBProgress (2): 131 kB | 143/208 kBProgress (2): 131 kB | 147/208 kBProgress (2): 131 kB | 151/208 kBProgress (2): 131 kB | 155/208 kBProgress (2): 131 kB | 159/208 kBProgress (2): 131 kB | 163/208 kBProgress (2): 131 kB | 167/208 kBProgress (2): 131 kB | 171/208 kBProgress (2): 131 kB | 176/208 kBProgress (2): 131 kB | 180/208 kBProgress (2): 131 kB | 184/208 kBProgress (2): 131 kB | 188/208 kBProgress (2): 131 kB | 192/208 kBProgress (2): 131 kB | 196/208 kBProgress (2): 131 kB | 200/208 kBProgress (2): 131 kB | 204/208 kBProgress (2): 131 kB | 208 kB                                 Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1.jar (131 kB at 822 kB/s)
Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/hadoop/hadoop-kms/3.2.1/hadoop-kms-3.2.1-tests.jar (208 kB at 1.2 MB/s)
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-antrun-plugin:1.7:run[m [1m(create-testdirs)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Executing tasks

main:
[[1;34mINFO[m] Executed tasks
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mhadoop-maven-plugins:3.2.1:protoc[m [1m(compile-protoc)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] No changes detected in protoc files, skipping generation.
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mhadoop-maven-plugins:3.2.1:resource-gz[m [1m(resource-gz)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap.min.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap.min.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap-editable.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap-editable.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.min.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/css/bootstrap-theme.min.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/bootstrap-editable.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/bootstrap-editable.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/npm.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/npm.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/bootstrap.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/bootstrap.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/bootstrap-3.3.7/js/bootstrap.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/bootstrap-3.3.7/js/bootstrap.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/moment.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/moment.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dfs-dust.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dfs-dust.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/json-bignum.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/json-bignum.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/d3-v4.1.1.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/d3-v4.1.1.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-helpers-1.1.1.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dust-helpers-1.1.1.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dataTables.bootstrap.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/hadoop.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/hadoop.css.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery.dataTables.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/jquery.dataTables.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/rest-csrf.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/rest-csrf.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dust-full-2.0.0.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dust-full-2.0.0.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/jquery-3.3.1.min.js to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/jquery-3.3.1.min.js.gz
[[1;34mINFO[m] Compressing /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/dataTables.bootstrap.css to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/webapps/static/dataTables.bootstrap.css.gz
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:resources[m [1m(default-resources)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.1:compile[m [1m(default-compile)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Compiling 6 source files to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/classes
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-antrun-plugin:1.7:run[m [1m(create-web-xmls)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Executing tasks

main:
[[1;34mINFO[m] Executed tasks
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:2.6:testResources[m [1m(default-testResources)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 57 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-antrun-plugin:1.7:run[m [1m(create-log-dir)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Executing tasks

main:
   [delete] Deleting directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data
    [mkdir] Created dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data
     [copy] Copying 21 files to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps
[[1;34mINFO[m] Executed tasks
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.1:testCompile[m [1m(default-testCompile)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] Nothing to compile - all classes are up to date
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:3.0.0-M1:test[m [1m(default-test)[m @ [36mhadoop-hdfs[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] Running org.apache.hadoop.tools.[1mTestHdfsConfigFields[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.429 s - in org.apache.hadoop.tools.[1mTestHdfsConfigFields[m
[[1;34mINFO[m] Running org.apache.hadoop.tools.[1mTestJMXGet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.451 s - in org.apache.hadoop.tools.[1mTestJMXGet[m
[[1;34mINFO[m] Running org.apache.hadoop.tools.[1mTestTools[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.66 s - in org.apache.hadoop.tools.[1mTestTools[m
[[1;34mINFO[m] Running org.apache.hadoop.net.[1mTestNetworkTopology[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.228 s - in org.apache.hadoop.net.[1mTestNetworkTopology[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSetrepIncreasing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.602 s - in org.apache.hadoop.hdfs.[1mTestSetrepIncreasing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeConfig[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.503 s - in org.apache.hadoop.hdfs.[1mTestDatanodeConfig[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestAclsEndToEnd[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 61.032 s - in org.apache.hadoop.hdfs.[1mTestAclsEndToEnd[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteReadStripedFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m17[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 215.297 s - in org.apache.hadoop.hdfs.[1mTestWriteReadStripedFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.[1mTestLocatedBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.173 s - in org.apache.hadoop.hdfs.protocol.[1mTestLocatedBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.[1mTestAnnotations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.112 s - in org.apache.hadoop.hdfs.protocol.[1mTestAnnotations[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.[1mTestLayoutVersion[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.183 s - in org.apache.hadoop.hdfs.protocol.[1mTestLayoutVersion[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.datatransfer.[1mTestPacketReceiver[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.273 s - in org.apache.hadoop.hdfs.protocol.datatransfer.[1mTestPacketReceiver[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.datatransfer.sasl.[1mTestSaslDataTransfer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.806 s - in org.apache.hadoop.hdfs.protocol.datatransfer.sasl.[1mTestSaslDataTransfer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.datatransfer.sasl.[1mTestBlackListBasedTrustedChannelResolver[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.275 s - in org.apache.hadoop.hdfs.protocol.datatransfer.sasl.[1mTestBlackListBasedTrustedChannelResolver[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocol.[1mTestBlockListAsLongs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.879 s - in org.apache.hadoop.hdfs.protocol.[1mTestBlockListAsLongs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.25 s - in org.apache.hadoop.hdfs.[1mTestWriteRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReconstructStripedFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 115.556 s - in org.apache.hadoop.hdfs.[1mTestReconstructStripedFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestEncryptionZones[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m42[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 95.647 s - in org.apache.hadoop.hdfs.[1mTestEncryptionZones[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReconstructStripedFileWithRandomECPolicy[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m15[m, [1;31mFailures: [0;1;31m4[m, Errors: 0, Skipped: 0, Time elapsed: 105.827 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestReconstructStripedFileWithRandomECPolicy[m
[[1;31mERROR[m] testRecoverOneDataBlock(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 5.263 s  <<< FAILURE!
arrays first differed at element [0]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:399)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverOneDataBlock(TestReconstructStripedFile.java:201)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testRecoverAllDataBlocks(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 4.815 s  <<< FAILURE!
arrays first differed at element [314572]; expected:<1> but was:<0>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:399)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverAllDataBlocks(TestReconstructStripedFile.java:187)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testRecoverOneDataBlock2(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 4.284 s  <<< FAILURE!
arrays first differed at element [0]; expected:<1> but was:<-103>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:399)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverOneDataBlock2(TestReconstructStripedFile.java:215)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testRecoverAnyBlocks(org.apache.hadoop.hdfs.TestReconstructStripedFileWithRandomECPolicy)  Time elapsed: 4.885 s  <<< FAILURE!
arrays first differed at element [0]; expected:<1> but was:<-104>
	at org.junit.internal.ComparisonCriteria.arrayEquals(ComparisonCriteria.java:50)
	at org.junit.Assert.internalArrayEquals(Assert.java:473)
	at org.junit.Assert.assertArrayEquals(Assert.java:294)
	at org.junit.Assert.assertArrayEquals(Assert.java:305)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.assertFileBlocksReconstruction(TestReconstructStripedFile.java:399)
	at org.apache.hadoop.hdfs.TestReconstructStripedFile.testRecoverAnyBlocks(TestReconstructStripedFile.java:222)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.sps.[1mTestExternalStoragePolicySatisfier[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m28[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 376.091 s - in org.apache.hadoop.hdfs.server.sps.[1mTestExternalStoragePolicySatisfier[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestLevelDBFileRegionAliasMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.283 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestLevelDBFileRegionAliasMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestTextBlockAliasMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.275 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestTextBlockAliasMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestInMemoryLevelDBAliasMapClient[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.752 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestInMemoryLevelDBAliasMapClient[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestLevelDbMockAliasMapClient[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.193 s - in org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.[1mTestLevelDbMockAliasMapClient[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.[1mTestGetUriFromString[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.405 s - in org.apache.hadoop.hdfs.server.common.[1mTestGetUriFromString[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.common.[1mTestJspHelper[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.716 s - in org.apache.hadoop.hdfs.server.common.[1mTestJspHelper[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestKeyManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.44 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestKeyManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithNodeGroup[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.194 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithNodeGroup[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m33[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 325.437 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerRPCDelay[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.896 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerRPCDelay[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithHANameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.859 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithHANameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithEncryptedTransfer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.2 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithEncryptedTransfer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithMultipleNameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 83.132 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithMultipleNameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithSaslDataTransfer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.281 s - in org.apache.hadoop.hdfs.server.balancer.[1mTestBalancerWithSaslDataTransfer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogFileOutputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.426 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogFileOutputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeHttpServer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.904 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeHttpServer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.top.window.[1mTestRollingWindowManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.233 s - in org.apache.hadoop.hdfs.server.namenode.top.window.[1mTestRollingWindowManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.top.window.[1mTestRollingWindow[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.113 s - in org.apache.hadoop.hdfs.server.namenode.top.window.[1mTestRollingWindow[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirAttrOp[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.464 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirAttrOp[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaByStorageType[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m23[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.783 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaByStorageType[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestPersistentStoragePolicySatisfier[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 154.851 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestPersistentStoragePolicySatisfier[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestBootstrapStandby[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.021 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestBootstrapStandby[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestLossyRetryInvocationHandler[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.694 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestLossyRetryInvocationHandler[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestXAttrsWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.135 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestXAttrsWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAAppend[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.9 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAAppend[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAStateTransitions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 61.989 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAStateTransitions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestBootstrapStandbyWithQJM[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.202 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestBootstrapStandbyWithQJM[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestInitializeSharedEdits[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.034 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestInitializeSharedEdits[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.597 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyBlockManagement[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.271 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyBlockManagement[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyCheckpoints[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 186.76 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyCheckpoints[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestPendingCorruptDnMessages[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.259 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestPendingCorruptDnMessages[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHASafeMode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m19[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 80.639 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHASafeMode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestRemoteNameNodeInfo[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.358 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestRemoteNameNodeInfo[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestConsistentReadsObserver[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.568 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestConsistentReadsObserver[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestEditLogsDuringFailover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.833 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestEditLogsDuringFailover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestQuotasWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.02 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestQuotasWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHarFileSystemWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.752 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHarFileSystemWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailoverWithBlockTokensEnabled[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.768 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailoverWithBlockTokensEnabled[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestPipelinesFailover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 92.958 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestPipelinesFailover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestEditLogTailer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m18[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 55.938 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestEditLogTailer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAConfiguration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.023 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAConfiguration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestObserverNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.525 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestObserverNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDNFencing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.692 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDNFencing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDelegationTokensWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.937 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDelegationTokensWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDFSUpgradeWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.767 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDFSUpgradeWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailureToReadEdits[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 82.509 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailureToReadEdits[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailureOfSharedDir[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m4[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 8.045 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestFailureOfSharedDir[m
[[1;31mERROR[m] testFailureOfSharedDir(org.apache.hadoop.hdfs.server.namenode.ha.TestFailureOfSharedDir)  Time elapsed: 7.389 s  <<< FAILURE!
java.lang.AssertionError: Succeeded in rolling edit log despite shared dir being deleted
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.ha.TestFailureOfSharedDir.testFailureOfSharedDir(TestFailureOfSharedDir.java:169)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyIsHot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.799 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyIsHot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyInProgressTail[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.079 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStandbyInProgressTail[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestObserverReadProxyProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.726 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestObserverReadProxyProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDNFencingWithReplication[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 68.361 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestDNFencingWithReplication[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestSeveralNameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.546 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestSeveralNameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestGetGroupsWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.361 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestGetGroupsWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestMultiObserverNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.13 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestMultiObserverNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestNNHealthCheck[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.116 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestNNHealthCheck[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStateTransitionFailure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.596 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestStateTransitionFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestRetryCacheWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 126.799 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestRetryCacheWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAFsck[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.3 s - in org.apache.hadoop.hdfs.server.namenode.ha.[1mTestHAFsck[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.564 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAllowFormat[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.876 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAllowFormat[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDefaultBlockPlacementPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.11 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDefaultBlockPlacementPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaCounts[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.065 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaCounts[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileJournalManager[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m14[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 2.311 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileJournalManager[m
[[1;31mERROR[m] testDoPreUpgradeIOError(org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager)  Time elapsed: 0.071 s  <<< FAILURE!
java.lang.AssertionError: Expected test to throw (an instance of java.io.IOException and exception with message a string containing "failure in native rename")
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.rules.ExpectedException.failDueToMissingException(ExpectedException.java:184)
	at org.junit.rules.ExpectedException.access$100(ExpectedException.java:85)
	at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:170)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestPathComponents[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.119 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestPathComponents[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.sps.[1mTestBlockStorageMovementAttemptedItems[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m5[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 11.622 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.sps.[1mTestBlockStorageMovementAttemptedItems[m
[[1;31mERROR[m] testNoBlockMovementAttemptFinishedReportAdded(org.apache.hadoop.hdfs.server.namenode.sps.TestBlockStorageMovementAttemptedItems)  Time elapsed: 0.027 s  <<< FAILURE!
java.lang.AssertionError: Item doesn't exist in the attempted list expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.apache.hadoop.hdfs.server.namenode.sps.TestBlockStorageMovementAttemptedItems.testNoBlockMovementAttemptFinishedReportAdded(TestBlockStorageMovementAttemptedItems.java:131)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.sps.[1mTestStoragePolicySatisfierWithStripedFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 71.663 s - in org.apache.hadoop.hdfs.server.namenode.sps.[1mTestStoragePolicySatisfierWithStripedFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNNThroughputBenchmark[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.337 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNNThroughputBenchmark[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestListOpenFiles[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.586 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestListOpenFiles[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAclConfigFlag[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.616 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAclConfigFlag[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStorageRestore[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m4[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 12.86 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestStorageRestore[m
[[1;31mERROR[m] testStorageRestoreFailure(org.apache.hadoop.hdfs.server.namenode.TestStorageRestore)  Time elapsed: 3.774 s  <<< FAILURE!
java.lang.AssertionError
	at org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure(TestStorageRestore.java:416)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogAtDebug[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.601 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogAtDebug[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeReconfigure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.986 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeReconfigure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestProcessCorruptBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.387 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestProcessCorruptBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeOptionParsing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.245 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeOptionParsing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestTruncateQuotaUpdate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.294 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestTruncateQuotaUpdate[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogAutoroll[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.401 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogAutoroll[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCacheDirectives[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 117.896 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCacheDirectives[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.55 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileTruncate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m19[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 98.089 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileTruncate[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFsck[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m33[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 139.55 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFsck[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDeleteRace[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 67.836 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDeleteRace[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNNStorageRetentionManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.689 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNNStorageRetentionManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.112 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirWriteFileOp[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.371 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirWriteFileOp[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddStripedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.581 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestReencryptionWithKMS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m33[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 280.117 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestReencryptionWithKMS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSEditLogLoader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m26[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 101.705 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSEditLogLoader[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageStorageInspector[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.275 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageStorageInspector[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestUpgradeDomainBlockPlacementPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.17 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestUpgradeDomainBlockPlacementPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStartupOptionUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.716 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStartupOptionUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStartup[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m13[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 32.254 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestStartup[m
[[1;31mERROR[m] testNNFailToStartOnReadOnlyNNDir(org.apache.hadoop.hdfs.server.namenode.TestStartup)  Time elapsed: 6.436 s  <<< FAILURE!
java.lang.AssertionError: Restarting NN should fail on read only NN dir.
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testNNFailToStartOnReadOnlyNNDir(TestStartup.java:744)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRetryCacheMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.38 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRetryCacheMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeHttpServerXFrame[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.633 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeHttpServerXFrame[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecondaryWebUi[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.336 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecondaryWebUi[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.startupprogress.[1mTestStartupProgress[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.384 s - in org.apache.hadoop.hdfs.server.namenode.startupprogress.[1mTestStartupProgress[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.startupprogress.[1mTestStartupProgressMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.308 s - in org.apache.hadoop.hdfs.server.namenode.startupprogress.[1mTestStartupProgressMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.49 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestRandomOpsWithSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 180.589 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestRandomOpsWithSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotReplication[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.153 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotReplication[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 58.693 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapRootDescendantDiff[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m18[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m2[m, Time elapsed: 44.95 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapRootDescendantDiff[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestDiffListBySkipList[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.065 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestDiffListBySkipList[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotDiffReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m17[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 44.328 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotDiffReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotFileLength[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.666 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotFileLength[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotRename[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.765 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotRename[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotListing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.119 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotListing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestAclWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.402 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestAclWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotDeletion[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 79.778 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotDeletion[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshottableDirListing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.076 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshottableDirListing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestUpdatePipelineWithSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.31 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestUpdatePipelineWithSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotNameWithInvalidCharacters[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.189 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotNameWithInvalidCharacters[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestGetContentSummaryWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.948 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestGetContentSummaryWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.779 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotBlocksMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.603 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotBlocksMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestINodeFileUnderConstructionWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.424 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestINodeFileUnderConstructionWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestDisallowModifyROSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.022 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestDisallowModifyROSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestFileWithSnapshotFeature[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.427 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestFileWithSnapshotFeature[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestNestedSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.156 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestNestedSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestFileContextSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.9 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestFileContextSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestXAttrWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.996 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestXAttrWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestOpenFilesWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 80.341 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestOpenFilesWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestCheckpointsWithSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.173 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestCheckpointsWithSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestRenameWithSnapshots[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m36[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 97.491 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestRenameWithSnapshots[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSetQuotaWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.026 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSetQuotaWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotStatsMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.676 s - in org.apache.hadoop.hdfs.server.namenode.snapshot.[1mTestSnapshotStatsMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFsckWithMultipleNameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.834 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFsckWithMultipleNameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestBlockPlacementPolicyRackFaultTolerant[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.972 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestBlockPlacementPolicyRackFaultTolerant[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestValidateConfigurationSettings[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.469 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestValidateConfigurationSettings[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestMetaSave[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.69 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestMetaSave[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSPermissionChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.98 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSPermissionChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameEditsConfigs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.825 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameEditsConfigs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaWithStripedBlocksWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.883 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaWithStripedBlocksWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLog[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m52[m, [1;31mFailures: [0;1;31m2[m, Errors: 0, Skipped: 0, Time elapsed: 104.761 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLog[m
[[1;31mERROR[m] testFailedOpen[0](org.apache.hadoop.hdfs.server.namenode.TestEditLog)  Time elapsed: 0.018 s  <<< FAILURE!
java.lang.AssertionError: Did no throw exception on only having a bad dir
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestEditLog.testFailedOpen(TestEditLog.java:1068)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;31mERROR[m] testFailedOpen[1](org.apache.hadoop.hdfs.server.namenode.TestEditLog)  Time elapsed: 0.01 s  <<< FAILURE!
java.lang.AssertionError: Did no throw exception on only having a bad dir
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestEditLog.testFailedOpen(TestEditLog.java:1068)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRpcServer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.435 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRpcServer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNestedEncryptionZones[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.681 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNestedEncryptionZones[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystemMBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.6 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystemMBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLoggerWithCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m40[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.836 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLoggerWithCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestXAttrConfigFlag[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.417 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestXAttrConfigFlag[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMetadataConsistency[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.085 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMetadataConsistency[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCreateEditsLog[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.274 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCreateEditsLog[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeAcl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m66[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.55 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeConfiguration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.178 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeConfiguration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRpcServerMethods[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.773 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRpcServerMethods[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirectory[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.583 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSDirectory[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestXAttrFeature[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.176 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestXAttrFeature[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecureNameNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.804 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecureNameNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestLeaseManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.731 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestLeaseManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestClusterId[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.003 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestClusterId[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestProtectedDirectories[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.397 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestProtectedDirectories[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestRefreshNamenodeReplicationConfig[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.73 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestRefreshNamenodeReplicationConfig[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithAcl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 69.977 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecondaryNameNodeUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.975 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecondaryNameNodeUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestMetadataVersionOutput[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.811 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestMetadataVersionOutput[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogger[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.408 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogger[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestMalformedURLs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.619 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestMalformedURLs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStoragePolicySummary[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.13 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStoragePolicySummary[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m32[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.936 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAuditLogs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCommitBlockSynchronization[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.344 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCommitBlockSynchronization[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestGetImageServlet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.576 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestGetImageServlet[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStripedINodeFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.284 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStripedINodeFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFsLimits[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.425 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFsLimits[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestReconstructStripedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.17 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestReconstructStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestINodeFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m28[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.932 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestINodeFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystem[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.069 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystem[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRespectsBindHostKeys[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.642 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRespectsBindHostKeys[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestHostsFiles[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.31 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestHostsFiles[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestBlockUnderConstruction[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.786 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestBlockUnderConstruction[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSnapshotPathINodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.398 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSnapshotPathINodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeRetryCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.497 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeRetryCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestReencryptionHandler[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.94 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestReencryptionHandler[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCheckPointForSecurityTokens[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.8 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCheckPointForSecurityTokens[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCommitBlockWithInvalidGenStamp[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.954 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestCommitBlockWithInvalidGenStamp[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMetricsLogger[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.611 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMetricsLogger[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestCheckpoint[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m38[m, [1;31mFailures: [0;1;31m2[m, Errors: 0, Skipped: 0, Time elapsed: 60.615 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestCheckpoint[m
[[1;31mERROR[m] testNameDirError(org.apache.hadoop.hdfs.server.namenode.TestCheckpoint)  Time elapsed: 3.505 s  <<< FAILURE!
java.lang.AssertionError: NN should have failed to start with /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 set unreadable
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testNameDirError(TestCheckpoint.java:180)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;31mERROR[m] testCheckpointWithSeparateDirsAfterNameFails(org.apache.hadoop.hdfs.server.namenode.TestCheckpoint)  Time elapsed: 0.346 s  <<< FAILURE!
java.lang.AssertionError: Did not fail to checkpoint when there are no valid storage dirs
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpointWithSeparateDirsAfterNameFails(TestCheckpoint.java:2143)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestGetBlockLocations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.407 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestGetBlockLocations[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestParallelImageWrite[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.03 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestParallelImageWrite[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStoragePolicySatisfierWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.779 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStoragePolicySatisfierWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogFileInputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.818 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogFileInputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMXBean[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m12[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 34.596 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeMXBean[m
[[1;31mERROR[m] testNameNodeMXBeanInfo(org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean)  Time elapsed: 1.546 s  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNameNodeMXBeanInfo(TestNameNodeMXBean.java:257)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m17[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 128.882 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestLargeDirectoryDelete[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.879 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestLargeDirectoryDelete[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEnabledECPolicies[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.431 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEnabledECPolicies[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSaveNamespace[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m16[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 16.626 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestSaveNamespace[m
[[1;31mERROR[m] testReinsertnamedirsInSavenamespace(org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace)  Time elapsed: 0.228 s  <<< FAILURE!
java.lang.AssertionError: Savenamespace should have marked one directory as bad. But found 0 bad directories.
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testReinsertnamedirsInSavenamespace(TestSaveNamespace.java:292)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileContextXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.044 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileContextXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestGenericJournalConf[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.555 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestGenericJournalConf[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDeadDatanode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.168 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDeadDatanode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestClientNameNodeAddress[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.375 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestClientNameNodeAddress[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestNNMetricFilesInGetListingOps[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.837 s - in org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestNNMetricFilesInGetListingOps[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestTopMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.449 s - in org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestTopMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestNameNodeMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m19[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 64.573 s - in org.apache.hadoop.hdfs.server.namenode.metrics.[1mTestNameNodeMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestINodeAttributeProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.298 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestINodeAttributeProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.194 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSImageWithXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeResourcePolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.196 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeResourcePolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNNStorageRetentionFunctional[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m1[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 3.292 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.namenode.[1mTestNNStorageRetentionFunctional[m
[[1;31mERROR[m] testPurgingWithNameEditsDirAfterFailure(org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionFunctional)  Time elapsed: 3.144 s  <<< FAILURE!
org.junit.ComparisonFailure: Bad files matching fsimage_\d* in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/nn0/current expected:<...e_000000000000000000[2,fsimage_0000000000000000004]> but was:<...e_000000000000000000[4,fsimage_0000000000000000006]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.apache.hadoop.test.GenericTestUtils.assertGlobEquals(GenericTestUtils.java:309)
	at org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionFunctional.testPurgingWithNameEditsDirAfterFailure(TestNNStorageRetentionFunctional.java:117)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeResourceChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.97 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeResourceChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditsDoubleBuffer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.234 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditsDoubleBuffer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestListCorruptFileBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 118.914 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestListCorruptFileBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestBackupNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.36 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestBackupNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeCapacityReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.545 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeCapacityReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogJournalFailures[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.842 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogJournalFailures[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestHDFSConcat[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.091 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestHDFSConcat[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeStatusMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.601 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeStatusMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddStripedBlockInFBR[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.162 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddStripedBlockInFBR[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.178 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDiskspaceQuotaUpdate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 59.284 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDiskspaceQuotaUpdate[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFavoredNodesEndToEnd[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.474 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFavoredNodesEndToEnd[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.941 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNameNodeRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeStorageDirectives[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.76 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestNamenodeStorageDirectives[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDecommissioningStatus[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.797 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDecommissioningStatus[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestStartupProgressServlet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.413 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestStartupProgressServlet[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEncryptionZoneManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.519 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEncryptionZoneManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystemLock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.547 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFSNamesystemLock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestGetContentSummaryWithPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.111 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestGetContentSummaryWithPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddBlockRetry[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.577 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddBlockRetry[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileContextAcl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m66[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.733 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileContextAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.web.resources.[1mTestWebHdfsDataLocality[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.763 s - in org.apache.hadoop.hdfs.server.namenode.web.resources.[1mTestWebHdfsDataLocality[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.web.resources.[1mTestWebHdfsCreatePermissions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.09 s - in org.apache.hadoop.hdfs.server.namenode.web.resources.[1mTestWebHdfsCreatePermissions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaWithStripedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.741 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestQuotaWithStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestDeduplicationMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.06 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestDeduplicationMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestReencryption[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m32[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 346.536 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestReencryption[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecureNameNodeWithExternalKdc[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m1[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.081 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecureNameNodeWithExternalKdc[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAddOverReplicatedStripedBlocks[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m4[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 26.383 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAddOverReplicatedStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestTransferFsImage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.983 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestTransferFsImage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestAclTransformation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m55[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.234 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestAclTransformation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestSecurityTokenEditLog[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.374 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestSecurityTokenEditLog[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogRace[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 107.631 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestEditLogRace[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.namenode.[1mTestFileLimit[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.094 s - in org.apache.hadoop.hdfs.server.namenode.[1mTestFileLimit[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.command.[1mTestDiskBalancerCommand[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m30[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 59.162 s - in org.apache.hadoop.hdfs.server.diskbalancer.command.[1mTestDiskBalancerCommand[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancerRPC[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.943 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancerRPC[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestPlanner[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.65 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestPlanner[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDataModels[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.501 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDataModels[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestConnectors[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.246 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestConnectors[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancerWithMockMover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.529 s - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancerWithMockMover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancer[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m6[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 31.175 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.diskbalancer.[1mTestDiskBalancer[m
[[1;31mERROR[m] testDiskBalancerWithFedClusterWithOneNameServiceEmpty(org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancer)  Time elapsed: 6.878 s  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.hdfs.server.diskbalancer.TestDiskBalancer.testDiskBalancerWithFedClusterWithOneNameServiceEmpty(TestDiskBalancer.java:278)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.aliasmap.[1mTestInMemoryAliasMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.283 s - in org.apache.hadoop.hdfs.server.aliasmap.[1mTestInMemoryAliasMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSequentialBlockGroupId[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.736 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSequentialBlockGroupId[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockInfoStriped[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m30[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 58.008 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockInfoStriped[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockReportLease[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.821 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockReportLease[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestLowRedundancyBlockQueues[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.21 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestLowRedundancyBlockQueues[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingDataNodeMessages[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.832 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingDataNodeMessages[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m68[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.545 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestDatanodeManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.466 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestDatanodeManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockManagerSafeMode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m20[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.434 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockManagerSafeMode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockUnderConstructionFeature[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.25 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockUnderConstructionFeature[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlocksWithNotEnoughRacks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.982 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlocksWithNotEnoughRacks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockPlacementStatusWithUpgradeDomain[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.165 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockPlacementStatusWithUpgradeDomain[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockStatsMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.246 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockStatsMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestCachedBlocksList[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.199 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestCachedBlocksList[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHeartbeatHandling[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.031 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHeartbeatHandling[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestNodeCount[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.654 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestNodeCount[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyWithNodeGroup[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m18[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.304 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyWithNodeGroup[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingReconstruction[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.619 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingReconstruction[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestProvidedStorageMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.514 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestProvidedStorageMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestNameNodePrunesMissingStorages[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.797 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestNameNodePrunesMissingStorages[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockTokenWithDFSStriped[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.009 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockTokenWithDFSStriped[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReconstructStripedBlocksWithRackAwareness[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.406 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReconstructStripedBlocksWithRackAwareness[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingRecoveryBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.33 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingRecoveryBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestOverReplicatedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.674 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestOverReplicatedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyWithUpgradeDomain[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.15 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyWithUpgradeDomain[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockTokenWithDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.163 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockTokenWithDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSortLocatedStripedBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.983 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSortLocatedStripedBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSequentialBlockId[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.234 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSequentialBlockId[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingInvalidateBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.339 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestPendingInvalidateBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockInfo[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.286 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockInfo[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSlowDiskTracker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.003 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSlowDiskTracker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestDatanodeDescriptor[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.197 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestDatanodeDescriptor[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSlowPeerTracker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.69 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestSlowPeerTracker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestCorruptReplicaInfo[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.53 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestCorruptReplicaInfo[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHost2NodesMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.175 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHost2NodesMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m27[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.357 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestUnderReplicatedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.552 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestUnderReplicatedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockReportRateLimiting[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.29 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestBlockReportRateLimiting[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyConsiderLoad[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.813 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestReplicationPolicyConsiderLoad[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHostFileManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.982 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestHostFileManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestAvailableSpaceBlockPlacementPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.527 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestAvailableSpaceBlockPlacementPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestRBWBlockInvalidation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.103 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestRBWBlockInvalidation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.blockmanagement.[1mTestComputeInvalidateWork[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.331 s - in org.apache.hadoop.hdfs.server.blockmanagement.[1mTestComputeInvalidateWork[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeInitStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.578 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeInitStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeTransferSocketSize[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.204 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeTransferSocketSize[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailureToleration[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m4[m, [1;31mFailures: [0;1;31m2[m, [1;31mErrors: [0;1;31m1[m, Skipped: 0, Time elapsed: 61.805 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailureToleration[m
[[1;31mERROR[m] testValidVolumesAtStartup(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration)  Time elapsed: 15.577 s  <<< FAILURE!
java.lang.AssertionError: The DN shouldn't have a bad directory.
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertFalse(Assert.java:64)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testValidVolumesAtStartup(TestDataNodeVolumeFailureToleration.java:131)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testFailedVolumeOnStartupIsCounted(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration)  Time elapsed: 31.07 s  <<< ERROR!
java.util.concurrent.TimeoutException: Timed out waiting for capacity. Live = 1 Expected = 1 Dead = 0 Expected = 0 Total capacity = 898358673408 Expected = 449179336704 Vol Fails = 0 Expected = 1
	at org.apache.hadoop.hdfs.DFSTestUtil.waitForDatanodeStatus(DFSTestUtil.java:732)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testFailedVolumeOnStartupIsCounted(TestDataNodeVolumeFailureToleration.java:299)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testVolumeAndTolerableConfiguration(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration)  Time elapsed: 1.507 s  <<< FAILURE!
java.lang.AssertionError: expected:<false> but was:<true>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testVolumeConfig(TestDataNodeVolumeFailureToleration.java:259)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testVolumeAndTolerableConfiguration(TestDataNodeVolumeFailureToleration.java:208)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDiskError[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBPOfferService[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 41.5 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBPOfferService[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodePeerMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.246 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodePeerMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeFaultInjector[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.984 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeFaultInjector[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDeleteBlockPool[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.651 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDeleteBlockPool[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestReadOnlySharedStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.942 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestReadOnlySharedStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataXceiverLazyPersistHint[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.941 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataXceiverLazyPersistHint[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBpServiceActorScheduler[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.368 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBpServiceActorScheduler[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeProtocolRetryPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.126 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeProtocolRetryPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataXceiverBackwardsCompat[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.988 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataXceiverBackwardsCompat[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestStartSecureDataNode[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m3[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.379 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestStartSecureDataNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockHasMultipleReplicasOnSameDN[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.139 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockHasMultipleReplicasOnSameDN[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeUUID[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.09 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeUUID[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestTriggerBlockReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.653 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestTriggerBlockReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestRefreshNamenodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.836 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestRefreshNamenodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeRegister[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.464 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeRegister[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestTransferRbw[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.835 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestTransferRbw[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.extdataset.[1mTestExternalDataset[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.08 s - in org.apache.hadoop.hdfs.server.datanode.extdataset.[1mTestExternalDataset[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeRollingUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 119.724 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeRollingUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeStartupOptions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.305 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDatanodeStartupOptions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestFsDatasetCacheRevocation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.911 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestFsDatasetCacheRevocation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.653 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailureReporting[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.61 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailureReporting[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeCheckerFailures[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.589 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeCheckerFailures[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestStorageLocationChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.702 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestStorageLocationChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestThrottledAsyncCheckerTimeout[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.332 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestThrottledAsyncCheckerTimeout[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeCheckerTimeout[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.547 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeCheckerTimeout[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.663 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestDatasetVolumeChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.checker.[1mTestThrottledAsyncChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.772 s - in org.apache.hadoop.hdfs.server.datanode.checker.[1mTestThrottledAsyncChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeReconfiguration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.676 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeReconfiguration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBatchIbr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.766 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBatchIbr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.987 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDirectoryScanner[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m10[m, Failures: 0, [1;31mErrors: [0;1;31m1[m, Skipped: 0, Time elapsed: 737.677 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.datanode.[1mTestDirectoryScanner[m
[[1;31mERROR[m] testScanDirectoryStructureWarn(org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner)  Time elapsed: 600.019 s  <<< ERROR!
java.lang.Exception: test timed out after 600000 milliseconds
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2704)
	at org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2744)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1735)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:911)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477)
	at org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.testScanDirectoryStructureWarn(TestDirectoryScanner.java:426)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestLargeBlockReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 179.191 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestLargeBlockReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestIncrementalBrVariations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.104 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestIncrementalBrVariations[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailure[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m11[m, [1;31mFailures: [0;1;31m2[m, [1;31mErrors: [0;1;31m1[m, Skipped: 0, Time elapsed: 79.073 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeFailure[m
[[1;31mERROR[m] testDataNodeFailToStartWithVolumeFailure(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure)  Time elapsed: 1.232 s  <<< FAILURE!
java.lang.AssertionError: Failed to get expected IOException
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.startNewDataNodeWithDiskFailure(TestDataNodeVolumeFailure.java:572)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testDataNodeFailToStartWithVolumeFailure(TestDataNodeVolumeFailure.java:503)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testDNFailToStartWithDataDirNonWritable(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure)  Time elapsed: 1.219 s  <<< FAILURE!
java.lang.AssertionError: Failed to get expected IOException
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.startNewDataNodeWithDiskFailure(TestDataNodeVolumeFailure.java:572)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testDNFailToStartWithDataDirNonWritable(TestDataNodeVolumeFailure.java:535)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testVolumeFailure(org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure)  Time elapsed: 31.297 s  <<< ERROR!
java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2020-04-09 01:15:39,857

"IPC Server handler 4 on default port 34156" daemon prio=5 tid=6804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server listener on 0" daemon prio=5 tid=6990 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"IPC Server handler 6 on default port 45664" daemon prio=5 tid=7008 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 1 on default port 34699" daemon prio=5 tid=6602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"VolumeCheck ResultHandler thread 2" daemon prio=5 tid=6560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=21 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 34156" daemon prio=5 tid=6810 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"DataNode DiskChecker thread 0" daemon prio=5 tid=6985 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 34156" daemon prio=5 tid=6805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
"IPC Server handler 5 on default port 34699" daemon prio=5 tid=6606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.eclipse.jetty.server.session.HashSessionManager@4ae7133cTimer" daemon prio=5 tid=6820 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1791177909-6625-acceptor-0@9c7758d-ServerConnector@48e82987{HTTP/1.1,[http/1.1]}{localhost:41652}" daemon prio=3 tid=6625 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@72cd9aa8" daemon prio=5 tid=6814 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:113)
        at org.apache.hadoop.hdfs.net.TcpPeerServer.accept(TcpPeerServer.java:85)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:145)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-56-1"  prio=10 tid=6823 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 34699" daemon prio=5 tid=6603 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.eclipse.jetty.server.session.HashSessionManager@530d251Timer" daemon prio=5 tid=6628 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@2a3cf6fb" daemon prio=5 tid=6587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run(HeartbeatManager.java:456)
        at java.lang.Thread.run(Thread.java:748)
"AsyncAppender-Dispatcher-Thread-61" daemon prio=5 tid=266 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1806961428-172.17.0.5-1586394908892" daemon prio=5 tid=7028 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=6991 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"IPC Server handler 2 on default port 34156" daemon prio=5 tid=6802 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ForkJoinPool-2-worker-15" daemon prio=5 tid=506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"IPC Server handler 6 on default port 34699" daemon prio=5 tid=6607 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 7 on default port 34156" daemon prio=5 tid=6807 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"ForkJoinPool-2-worker-36" daemon prio=5 tid=503 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=7188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Readahead Thread #1" daemon prio=5 tid=4910 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1782177965-6818-acceptor-0@357c83b0-ServerConnector@415acb20{HTTP/1.1,[http/1.1]}{localhost:42684}" daemon prio=3 tid=6818 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 34156" daemon prio=5 tid=6806 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1791177909-6624" daemon prio=5 tid=6624 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceExecuteConsume(ExecuteProduceConsume.java:169)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:145)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"Timer for 'NameNode' metrics system" daemon prio=5 tid=6569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1791177909-6626" daemon prio=5 tid=6626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 45664" daemon prio=5 tid=7011 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"process reaper" daemon prio=10 tid=484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1806961428-172.17.0.5-1586394908892" daemon prio=5 tid=6997 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeCheck ResultHandler thread 1" daemon prio=5 tid=6554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"java.util.concurrent.ThreadPoolExecutor$Worker@3dcc7b4b[State = -1, empty queue]" daemon prio=5 tid=7017 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-376-thread-1"  prio=5 tid=6611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-395-thread-1"  prio=5 tid=7001 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)" daemon prio=5 tid=7019 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"Block report processor" daemon prio=5 tid=6589 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:5043)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:5032)
"LeaseRenewer:root@localhost:36431" daemon prio=5 tid=5387 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"Listener at localhost/45664"  prio=5 tid=6561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.lang.Thread.join(Thread.java:1260)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluateStatement(FailOnTimeout.java:26)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluate(FailOnTimeout.java:17)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1806961428-172.17.0.5-1586394908892" daemon prio=5 tid=7027 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"qtp1875711202-6584" daemon prio=5 tid=6584 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"StorageLocationChecker thread 1" daemon prio=5 tid=6812 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1875711202-6579-acceptor-3@4380b1a7-ServerConnector@27e4a179{HTTP/1.1,[http/1.1]}{localhost:42140}" daemon prio=3 tid=6579 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:230)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-50" daemon prio=5 tid=500 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"IPC Server listener on 0" daemon prio=5 tid=6592 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"qtp1875711202-6575" daemon prio=5 tid=6575 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@383aae8a" daemon prio=5 tid=6613 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=6622 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=22 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 34156" daemon prio=5 tid=6808 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-54-1"  prio=10 tid=6630 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=6593 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"qtp1875711202-6578-acceptor-2@5139b19c-ServerConnector@27e4a179{HTTP/1.1,[http/1.1]}{localhost:42140}" daemon prio=3 tid=6578 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=6809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=6553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 34699" daemon prio=5 tid=6608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@524c9113" daemon prio=5 tid=6570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 34699" daemon prio=5 tid=6604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"StorageInfoMonitor" daemon prio=5 tid=6586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StorageInfoDefragmenter.run(BlockManager.java:4719)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@7669432bTimer" daemon prio=5 tid=6581 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 34699" daemon prio=5 tid=6609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1875711202-6572" daemon prio=5 tid=6572 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)" daemon prio=5 tid=6974 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"IPC Server handler 5 on default port 45664" daemon prio=5 tid=7007 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"RedundancyMonitor" daemon prio=5 tid=6585 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:340)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4684)
        at java.lang.Thread.run(Thread.java:748)
"Async disk worker #0 for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3" daemon prio=5 tid=7189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"StorageLocationChecker thread 1" daemon prio=5 tid=6619 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-379-thread-1" daemon prio=5 tid=6986 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1875711202-6577-acceptor-1@62d7445c-ServerConnector@27e4a179{HTTP/1.1,[http/1.1]}{localhost:42140}" daemon prio=3 tid=6577 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:230)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"pool-388-thread-1" daemon prio=5 tid=7022 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 34156" daemon prio=5 tid=6793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Readahead Thread #0" daemon prio=5 tid=4909 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=4890 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Thread-1956"  prio=5 tid=7034 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1610)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:87)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)
        at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:389)
        at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testVolumeFailure(TestDataNodeVolumeFailure.java:195)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
"org.eclipse.jetty.server.session.HashSessionManager@8bee676Timer" daemon prio=5 tid=6821 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b675249" daemon prio=5 tid=6989 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-43" daemon prio=5 tid=502 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"StorageLocationChecker thread 0" daemon prio=5 tid=6811 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 45664" daemon prio=5 tid=7004 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"qtp1782177965-6817" daemon prio=5 tid=6817 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceExecuteConsume(ExecuteProduceConsume.java:169)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:145)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"pool-391-thread-1"  prio=5 tid=6816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=6791 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7857473f" daemon prio=5 tid=6621 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:113)
        at org.apache.hadoop.hdfs.net.TcpPeerServer.accept(TcpPeerServer.java:85)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:145)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 45664" daemon prio=5 tid=7009 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 3 on default port 45664" daemon prio=5 tid=7005 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"DatanodeAdminMonitor-0" daemon prio=5 tid=6599 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@77fdc8b9" daemon prio=5 tid=6615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller.run(FSNamesystem.java:4105)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 34699" daemon prio=5 tid=6601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 1 on default port 45664" daemon prio=5 tid=7003 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4c668aad" daemon prio=5 tid=6616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber.run(FSNamesystem.java:4196)
        at java.lang.Thread.run(Thread.java:748)
"pool-382-thread-1"  prio=5 tid=6623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@47fe91e2" daemon prio=5 tid=6598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
        at java.lang.Thread.run(Thread.java:748)
"pool-374-thread-1"  prio=5 tid=6571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1875711202-6576-acceptor-0@4cda16e2-ServerConnector@27e4a179{HTTP/1.1,[http/1.1]}{localhost:42140}" daemon prio=3 tid=6576 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:230)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"client DomainSocketWatcher" daemon prio=5 tid=494 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"java.util.concurrent.ThreadPoolExecutor$Worker@752ab0c6[State = -1, empty queue]" daemon prio=5 tid=7033 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1875711202-6574" daemon prio=5 tid=6574 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 45664" daemon prio=5 tid=7002 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=4894 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"process reaper" daemon prio=10 tid=483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=6815 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@76fca183Timer" daemon prio=5 tid=6629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Client (1662229874) connection to localhost/127.0.0.1:34699 from root" daemon prio=5 tid=7191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1034)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1078)
"IPC Server handler 0 on default port 34156" daemon prio=5 tid=6800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ca44b55" daemon prio=5 tid=6790 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"CacheReplicationMonitor(450134907)"  prio=5 tid=6617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run(CacheReplicationMonitor.java:181)
"AsyncAppender-Dispatcher-Thread-42" daemon prio=5 tid=77 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-29" daemon prio=5 tid=504 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"VolumeCheck ResultHandler thread 0" daemon prio=5 tid=5398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=6794 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"IPC Server Responder" daemon prio=5 tid=6993 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor@19817d52" daemon prio=5 tid=6614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor.run(FSNamesystem.java:4063)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@43fa7f20Timer" daemon prio=5 tid=6582 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"LeaseRenewer:root@localhost:34699" daemon prio=5 tid=7036 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 45664" daemon prio=5 tid=7006 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Socket Reader #1 for port 0"  prio=5 tid=6792 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"org.eclipse.jetty.server.session.HashSessionManager@124b50f8Timer" daemon prio=5 tid=6627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=7021 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 34699" daemon prio=5 tid=6594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-383-thread-1"  prio=5 tid=6798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)" daemon prio=5 tid=7020 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner" daemon prio=5 tid=85 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:3762)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1806961428-172.17.0.5-1586394908892" daemon prio=5 tid=6996 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"main"  prio=5 tid=1 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.lang.Thread.join(Thread.java:1260)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluateStatement(FailOnTimeout.java:26)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluate(FailOnTimeout.java:17)
        at org.junit.rules.RunRules.evaluate(RunRules.java:20)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"IPC Server handler 1 on default port 34156" daemon prio=5 tid=6801 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"org.eclipse.jetty.server.session.HashSessionManager@1be616f5Timer" daemon prio=5 tid=6580 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 34156" daemon prio=5 tid=6803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server Responder" daemon prio=5 tid=6595 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"VolumeCheck ResultHandler thread 1" daemon prio=5 tid=5399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-57" daemon prio=5 tid=499 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"IPC Server idle connection scanner for port 45664" daemon prio=5 tid=6992 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ForkJoinPool-2-worker-22" daemon prio=5 tid=505 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"org.eclipse.jetty.server.session.HashSessionManager@44636334Timer" daemon prio=5 tid=6822 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server handler 8 on default port 45664" daemon prio=5 tid=7010 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 9 on default port 34699" daemon prio=5 tid=6610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"BP-1806961428-172.17.0.5-1586394908892 heartbeating to localhost/127.0.0.1:34699" daemon prio=5 tid=6797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager.waitTillNextIBR(IncrementalBlockReportManager.java:158)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:718)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
        at java.lang.Thread.run(Thread.java:748)
"process reaper" daemon prio=10 tid=485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp1782177965-6819" daemon prio=5 tid=6819 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 34699" daemon prio=5 tid=6605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"StorageLocationChecker thread 0" daemon prio=5 tid=6618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"FSEditLogAsync"  prio=5 tid=6591 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.dequeueEdit(FSEditLogAsync.java:221)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.run(FSEditLogAsync.java:229)
        at java.lang.Thread.run(Thread.java:748)
"qtp1875711202-6573" daemon prio=5 tid=6573 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"BP-1806961428-172.17.0.5-1586394908892 heartbeating to localhost/127.0.0.1:34699" daemon prio=5 tid=7000 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager.waitTillNextIBR(IncrementalBlockReportManager.java:158)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:718)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)" daemon prio=5 tid=6964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)


	at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:389)
	at org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testVolumeFailure(TestDataNodeVolumeFailure.java:195)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockPoolManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.64 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockPoolManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDnRespectsBlockReportSplitThreshold[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.729 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDnRespectsBlockReportSplitThreshold[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestStorageReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.904 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestStorageReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeLifeline[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.157 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeLifeline[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.182 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeVolumeMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMultipleRegistrations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 22.863 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMultipleRegistrations[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeExit[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.925 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeExit[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeErasureCodingMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.661 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeErasureCodingMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestCachingStrategy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.664 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestCachingStrategy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.metrics.[1mTestSlowNodeDetector[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.189 s - in org.apache.hadoop.hdfs.server.datanode.metrics.[1mTestSlowNodeDetector[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.metrics.[1mTestDataNodeOutlierDetectionViaMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.483 s - in org.apache.hadoop.hdfs.server.datanode.metrics.[1mTestDataNodeOutlierDetectionViaMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.487 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeHotSwapVolumes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 55.765 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeHotSwapVolumes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestNNHandlesCombinedBlockReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 52.626 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestNNHandlesCombinedBlockReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m21[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 109.314 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeECN[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.678 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeECN[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestHdfsServerConstants[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.047 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestHdfsServerConstants[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDNUsageReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.073 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDNUsageReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestWriteToReplica[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.574 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestWriteToReplica[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.643 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestProvidedImpl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.735 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestProvidedImpl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestFsDatasetImpl[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m15[m, Failures: 0, [1;31mErrors: [0;1;31m1[m, Skipped: 0, Time elapsed: 25.927 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestFsDatasetImpl[m
[[1;31mERROR[m] testCleanShutdownOfVolume(org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl)  Time elapsed: 2.039 s  <<< ERROR!
java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2020-04-09 01:23:16,679

"nioEventLoopGroup-11-39"  prio=10 tid=1446 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-46"  prio=10 tid=1373 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-72"  prio=10 tid=1399 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-57" daemon prio=5 tid=40 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"qtp402695541-1567-acceptor-2@1f6e2c48-ServerConnector@3cdf2c61{HTTP/1.1,[http/1.1]}{localhost:39774}" daemon prio=3 tid=1567 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 44005" daemon prio=5 tid=1790 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-21"  prio=10 tid=1428 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1573" daemon prio=5 tid=1573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"PacketResponder: BP-771064488-172.17.0.5-1586395395053:blk_1073741825_1001, type=LAST_IN_PIPELINE" daemon prio=5 tid=1819 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.waitForAckHead(BlockReceiver.java:1330)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1402)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 41307" daemon prio=5 tid=1595 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-36"  prio=10 tid=1443 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/4QeRbvkdGN/data/data2)" daemon prio=5 tid=1802 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"qtp402695541-1564" daemon prio=5 tid=1564 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-73"  prio=10 tid=1400 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-47"  prio=10 tid=1374 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@602e0143" daemon prio=5 tid=1602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-29"  prio=10 tid=1356 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-29"  prio=10 tid=1436 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-1"  prio=10 tid=1328 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"pool-130-thread-1"  prio=5 tid=1787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-20"  prio=10 tid=1347 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-52"  prio=10 tid=1379 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-63"  prio=10 tid=1390 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-22"  prio=10 tid=1429 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=864 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 6 on default port 44005" daemon prio=5 tid=1795 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-53"  prio=10 tid=1460 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/4QeRbvkdGN/data/data2/current/BP-771064488-172.17.0.5-1586395395053" daemon prio=5 tid=1810 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1568-acceptor-3@5627ba3-ServerConnector@3cdf2c61{HTTP/1.1,[http/1.1]}{localhost:39774}" daemon prio=3 tid=1568 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:231)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-50"  prio=10 tid=1457 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-25"  prio=10 tid=1352 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-8"  prio=10 tid=1335 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0)" daemon prio=5 tid=1216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-10"  prio=10 tid=1337 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-0" daemon prio=5 tid=364 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-42"  prio=10 tid=1369 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=857 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-13"  prio=10 tid=1420 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor@2c07545f" daemon prio=5 tid=1603 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor.run(FSNamesystem.java:4063)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=1231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-12"  prio=10 tid=1339 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-7"  prio=10 tid=1334 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0)" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"DataXceiver for client DFSClient_NONMAPREDUCE_1077917655_1 at /127.0.0.1:44854 [Receiving block BP-771064488-172.17.0.5-1586395395053:blk_1073741825_1001]" daemon prio=5 tid=1818 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at java.io.DataInputStream.read(DataInputStream.java:149)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0)" daemon prio=5 tid=923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-68"  prio=10 tid=1395 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=872 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-60"  prio=10 tid=1467 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-56"  prio=10 tid=1383 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@66c92293Timer" daemon prio=5 tid=1571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-69"  prio=10 tid=1476 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-5"  prio=10 tid=1412 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@764faa6" daemon prio=5 tid=1587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=891 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=22 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-59"  prio=10 tid=1386 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-24"  prio=10 tid=1351 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 0 on default port 41307" daemon prio=5 tid=1590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-63"  prio=10 tid=1470 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"process reaper" daemon prio=10 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-33"  prio=10 tid=1440 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-42"  prio=10 tid=1449 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=357 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@2b76ff4eTimer" daemon prio=5 tid=1617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"Socket Reader #1 for port 0"  prio=5 tid=1781 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"nioEventLoopGroup-11-70"  prio=10 tid=1477 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-78"  prio=10 tid=1405 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-7"  prio=10 tid=1414 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-61"  prio=10 tid=1388 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-56"  prio=10 tid=1463 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-62"  prio=10 tid=1469 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-49"  prio=10 tid=1376 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-14"  prio=10 tid=1341 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-0" daemon prio=5 tid=385 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=1548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-43"  prio=10 tid=1450 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-1" daemon prio=5 tid=373 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"qtp49222910-1615" daemon prio=5 tid=1615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=1222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@13330ac6" daemon prio=5 tid=1779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"FSEditLogAsync"  prio=5 tid=1580 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.dequeueEdit(FSEditLogAsync.java:221)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.run(FSEditLogAsync.java:229)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-51"  prio=10 tid=1458 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-55"  prio=10 tid=1382 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-17"  prio=10 tid=1344 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-12-1"  prio=10 tid=1619 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-68"  prio=10 tid=1475 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-13"  prio=10 tid=1340 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-1" daemon prio=5 tid=1255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0)" daemon prio=5 tid=379 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=1799 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-28"  prio=10 tid=1355 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-0" daemon prio=5 tid=1247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0)" daemon prio=5 tid=358 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@5bf0fe62" daemon prio=5 tid=1576 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run(HeartbeatManager.java:456)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-6"  prio=10 tid=1413 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-19"  prio=10 tid=1426 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 41307" daemon prio=5 tid=1592 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 0 on default port 44005" daemon prio=5 tid=1789 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-28"  prio=10 tid=1435 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/4QeRbvkdGN/data/data1/current/BP-771064488-172.17.0.5-1586395395053" daemon prio=5 tid=1809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"pool-123-thread-1"  prio=5 tid=1600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=924 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-11-1"  prio=10 tid=1408 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"client DomainSocketWatcher" daemon prio=5 tid=339 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=50 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-35"  prio=10 tid=1442 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=1780 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"RedundancyMonitor" daemon prio=5 tid=1574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:340)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4684)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-30"  prio=10 tid=1437 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-5"  prio=10 tid=1332 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-27"  prio=10 tid=1434 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server listener on 0" daemon prio=5 tid=1581 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1304)
"ForkJoinPool-2-worker-36" daemon prio=5 tid=43 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"datanode DomainSocketWatcher" daemon prio=5 tid=1532 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-53"  prio=10 tid=1380 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"LeaseRenewer:root@localhost:33761" daemon prio=5 tid=344 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-47"  prio=10 tid=1454 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-30"  prio=10 tid=1357 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-78"  prio=10 tid=1485 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"qtp49222910-1614-acceptor-0@540af559-ServerConnector@1b84f475{HTTP/1.1,[http/1.1]}{localhost:36247}" daemon prio=3 tid=1614 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 41307" daemon prio=5 tid=1597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=386 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 3 on default port 44005" daemon prio=5 tid=1792 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-10-69"  prio=10 tid=1396 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=859 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"DatanodeAdminMonitor-0" daemon prio=5 tid=1588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/newData0/current/bpid-0" daemon prio=5 tid=376 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-67"  prio=10 tid=1474 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=365 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-0" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/newData0)" daemon prio=5 tid=377 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-11-34"  prio=10 tid=1441 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 0" daemon prio=5 tid=1803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-1" daemon prio=5 tid=873 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=380 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"org.apache.hadoop.hdfs.PeerCache@4e8d5658" daemon prio=5 tid=349 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:253)
        at org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:46)
        at org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:124)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-1" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-1" daemon prio=5 tid=1547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-4"  prio=10 tid=1411 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-50" daemon prio=5 tid=41 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"IPC Server handler 8 on default port 44005" daemon prio=5 tid=1797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"pool-129-thread-1"  prio=5 tid=1612 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0)" daemon prio=5 tid=1533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-39"  prio=10 tid=1366 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
"nioEventLoopGroup-11-10"  prio=10 tid=1417 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"ResponseProcessor for block BP-771064488-172.17.0.5-1586395395053:blk_1073741825_1001" daemon prio=5 tid=1820 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
        at java.io.FilterInputStream.read(FilterInputStream.java:83)
        at java.io.FilterInputStream.read(FilterInputStream.java:83)
        at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:548)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)
        at org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1086)
"datanode DomainSocketWatcher" daemon prio=5 tid=53 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-57"  prio=10 tid=1464 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-3"  prio=10 tid=1410 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 1 on default port 41307" daemon prio=5 tid=1591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-23"  prio=10 tid=1430 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-9"  prio=10 tid=1416 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-11"  prio=10 tid=1338 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@38aa816fTimer" daemon prio=5 tid=1618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"CacheReplicationMonitor(419967999)"  prio=5 tid=1606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run(CacheReplicationMonitor.java:181)
"nioEventLoopGroup-11-20"  prio=10 tid=1427 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-18"  prio=10 tid=1345 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Listener at localhost/44005"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1610)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:87)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)
        at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:389)
        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testCleanShutdownOfVolume(TestFsDatasetImpl.java:700)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"nioEventLoopGroup-10-48"  prio=10 tid=1375 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server Responder" daemon prio=5 tid=1584 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=938 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=1242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"AsyncAppender-Dispatcher-Thread-73" daemon prio=5 tid=122 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-80"  prio=10 tid=1487 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-57"  prio=10 tid=1384 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-0" daemon prio=5 tid=1539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-18"  prio=10 tid=1425 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=1217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"datanode DomainSocketWatcher" daemon prio=5 tid=26 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"java.util.concurrent.ThreadPoolExecutor$Worker@6455a330[State = -1, empty queue]" daemon prio=5 tid=1815 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-25"  prio=10 tid=1432 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-71"  prio=10 tid=1478 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-77"  prio=10 tid=1404 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-58"  prio=10 tid=1385 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 4 on default port 44005" daemon prio=5 tid=1793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 4 on default port 41307" daemon prio=5 tid=1594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-10-34"  prio=10 tid=1361 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-60"  prio=10 tid=1387 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=918 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-43" daemon prio=5 tid=42 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"nioEventLoopGroup-10-16"  prio=10 tid=1343 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 8 on default port 41307" daemon prio=5 tid=1598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=1534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=904 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=359 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@32c726ee" daemon prio=5 tid=1605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber.run(FSNamesystem.java:4196)
        at java.lang.Thread.run(Thread.java:748)
"Timer for 'NameNode' metrics system" daemon prio=5 tid=1558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=393 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-32"  prio=10 tid=1439 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 41307" daemon prio=5 tid=1599 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=1540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"qtp49222910-1613" daemon prio=5 tid=1613 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceExecuteConsume(ExecuteProduceConsume.java:169)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:145)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-40"  prio=10 tid=1367 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@27eedb64Timer" daemon prio=5 tid=1616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"pool-121-thread-1"  prio=5 tid=1560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1562" daemon prio=5 tid=1562 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-3"  prio=10 tid=1330 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-8"  prio=10 tid=1415 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-23"  prio=10 tid=1350 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-0" daemon prio=5 tid=1223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-32"  prio=10 tid=1359 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-45"  prio=10 tid=1452 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 44005" daemon prio=5 tid=1782 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"nioEventLoopGroup-11-77"  prio=10 tid=1484 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-31"  prio=10 tid=1358 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-75"  prio=10 tid=1402 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-6"  prio=10 tid=1333 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Client (1670630889) connection to localhost/127.0.0.1:41307 from root" daemon prio=5 tid=1800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1034)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1078)
"nioEventLoopGroup-11-76"  prio=10 tid=1483 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@e57b96d" daemon prio=5 tid=1604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller.run(FSNamesystem.java:4105)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=1215 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-36"  prio=10 tid=1363 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-38"  prio=10 tid=1445 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-64"  prio=10 tid=1471 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server handler 6 on default port 41307" daemon prio=5 tid=1596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server Responder" daemon prio=5 tid=1783 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1480)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1463)
"nioEventLoopGroup-11-58"  prio=10 tid=1465 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-50"  prio=10 tid=1377 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-0" daemon prio=5 tid=865 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-65"  prio=10 tid=1392 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-49"  prio=10 tid=1456 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-74"  prio=10 tid=1401 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-27"  prio=10 tid=1354 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-73"  prio=10 tid=1480 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-44"  prio=10 tid=1451 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-21"  prio=10 tid=1348 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=902 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-26"  prio=10 tid=1353 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-79"  prio=10 tid=1486 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-41"  prio=10 tid=1368 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=28 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-45"  prio=10 tid=1372 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1566-acceptor-1@6a981af8-ServerConnector@3cdf2c61{HTTP/1.1,[http/1.1]}{localhost:39774}" daemon prio=3 tid=1566 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:231)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"pool-126-thread-1" daemon prio=5 tid=1804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-12"  prio=10 tid=1419 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 9 on default port 44005" daemon prio=5 tid=1798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"LeaseRenewer:root@localhost:41307" daemon prio=5 tid=1817 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-75"  prio=10 tid=1482 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0)" daemon prio=5 tid=1241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner" daemon prio=5 tid=29 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:3762)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=378 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"DataXceiver for client DFSClient_NONMAPREDUCE_1077917655_1 at /127.0.0.1:44858 [Waiting for operation #2]" daemon prio=5 tid=1823 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readShort(DataInputStream.java:312)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp(Receiver.java:71)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:271)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-29" daemon prio=5 tid=44 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"nioEventLoopGroup-11-72"  prio=10 tid=1479 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-4"  prio=10 tid=1331 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-19"  prio=10 tid=1346 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-1" daemon prio=5 tid=937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"nioEventLoopGroup-10-79"  prio=10 tid=1406 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 2 on default port 44005" daemon prio=5 tid=1791 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-24"  prio=10 tid=1431 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"Block report processor" daemon prio=5 tid=1578 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:5043)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:5032)
"nioEventLoopGroup-10-43"  prio=10 tid=1370 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-33"  prio=10 tid=1360 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-51"  prio=10 tid=1378 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-44"  prio=10 tid=1371 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Client (1670630889) connection to localhost/127.0.0.1:41307 from root" daemon prio=5 tid=1788 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1034)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1078)
"nioEventLoopGroup-11-59"  prio=10 tid=1466 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/4QeRbvkdGN/data/data1)" daemon prio=5 tid=1801 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"Socket Reader #1 for port 0"  prio=5 tid=1582 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1242)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1221)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=910 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-67"  prio=10 tid=1394 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-1" daemon prio=5 tid=1230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-41"  prio=10 tid=1448 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-16"  prio=10 tid=1423 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-38"  prio=10 tid=1365 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-15"  prio=10 tid=1422 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-37"  prio=10 tid=1444 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@632ceb35" daemon prio=5 tid=1559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:748)
"LeaseRenewer:root@localhost:43334" daemon prio=5 tid=1527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:411)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$600(LeaseRenewer.java:76)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:307)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-66"  prio=10 tid=1473 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0)" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-11-11"  prio=10 tid=1418 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-52"  prio=10 tid=1459 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=884 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@9ebe38bTimer" daemon prio=5 tid=1570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"AsyncAppender-Dispatcher-Thread-91" daemon prio=5 tid=310 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-35"  prio=10 tid=1362 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 7 on default port 44005" daemon prio=5 tid=1796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-48"  prio=10 tid=1455 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1563" daemon prio=5 tid=1563 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-62"  prio=10 tid=1389 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-0" daemon prio=5 tid=1248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-0" daemon prio=5 tid=930 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1565-acceptor-0@108f469a-ServerConnector@3cdf2c61{HTTP/1.1,[http/1.1]}{localhost:39774}" daemon prio=3 tid=1565 blocked
java.lang.Thread.State: BLOCKED
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:231)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:397)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-22"  prio=10 tid=1349 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"DataNode DiskChecker thread 1" daemon prio=5 tid=1825 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-31"  prio=10 tid=1438 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-76"  prio=10 tid=1403 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=1611 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=1240 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server handler 5 on default port 44005" daemon prio=5 tid=1794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"IPC Server handler 3 on default port 41307" daemon prio=5 tid=1593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:295)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2881)
"nioEventLoopGroup-11-61"  prio=10 tid=1468 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-15"  prio=10 tid=1342 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"BP-771064488-172.17.0.5-1586395395053 heartbeating to localhost/127.0.0.1:41307" daemon prio=5 tid=1786 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager.waitTillNextIBR(IncrementalBlockReportManager.java:158)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:718)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-74"  prio=10 tid=1481 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-64"  prio=10 tid=1391 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-9"  prio=10 tid=1336 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"IPC Server idle connection scanner for port 41307" daemon prio=5 tid=1583 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"nioEventLoopGroup-11-17"  prio=10 tid=1424 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=21 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-26"  prio=10 tid=1433 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-80"  prio=10 tid=1407 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-71"  prio=10 tid=1398 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-37"  prio=10 tid=1364 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0)" daemon prio=5 tid=858 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-10-70"  prio=10 tid=1397 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"StorageLocationChecker thread 1" daemon prio=5 tid=1608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"process reaper" daemon prio=10 tid=34 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@41e68d87" daemon prio=5 tid=1610 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:419)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:247)
        at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:113)
        at org.apache.hadoop.hdfs.net.TcpPeerServer.accept(TcpPeerServer.java:85)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:145)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-66"  prio=10 tid=1393 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"DataStreamer for file /user/root/test.dat block BP-771064488-172.17.0.5-1586395395053:blk_1073741825_1001" daemon prio=5 tid=1816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:681)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-1" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-54"  prio=10 tid=1461 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-2"  prio=10 tid=1409 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"ForkJoinPool-2-worker-22" daemon prio=5 tid=336 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)
"StorageLocationChecker thread 0" daemon prio=5 tid=1607 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-14"  prio=10 tid=1421 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-2"  prio=10 tid=1329 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-65"  prio=10 tid=1472 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1)" daemon prio=5 tid=878 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:621)
"nioEventLoopGroup-11-40"  prio=10 tid=1447 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"StorageInfoMonitor" daemon prio=5 tid=1575 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StorageInfoDefragmenter.run(BlockManager.java:4719)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-46"  prio=10 tid=1453 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=922 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"datanode DomainSocketWatcher" daemon prio=5 tid=876 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
        at java.lang.Thread.run(Thread.java:748)
"qtp402695541-1561" daemon prio=5 tid=1561 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
        at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:748)
"org.eclipse.jetty.server.session.HashSessionManager@56928307Timer" daemon prio=5 tid=1569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-10-54"  prio=10 tid=1381 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-1" daemon prio=5 tid=394 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data0/current/bpid-0" daemon prio=5 tid=37 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/cap8kVBBcT/data1/current/bpid-1" daemon prio=5 tid=1256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:179)
        at java.lang.Thread.run(Thread.java:748)
"nioEventLoopGroup-11-55"  prio=10 tid=1462 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:62)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:754)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:410)
        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131)
        at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
        at java.lang.Thread.run(Thread.java:748)


	at org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:389)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testCleanShutdownOfVolume(TestFsDatasetImpl.java:700)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestReplicaMap[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.151 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestReplicaMap[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestDatanodeRestart[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.827 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestDatanodeRestart[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestInterDatanodeProtocol[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.048 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestInterDatanodeProtocol[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestSpaceReservation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 89.89 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestSpaceReservation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyWriter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 104.672 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyWriter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestReservedSpaceCalculator[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.403 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestReservedSpaceCalculator[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistFiles[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 109.506 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistFiles[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistReplicaPlacement[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.912 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistReplicaPlacement[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistLockedMemory[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.694 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistLockedMemory[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestAddBlockPoolException[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.462 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestAddBlockPoolException[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestFsVolumeList[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.281 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestFsVolumeList[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistReplicaRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.502 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestLazyPersistReplicaRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestScrLazyPersistFiles[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.99 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.[1mTestScrLazyPersistFiles[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.[1mTestAvailableSpaceVolumeChoosingPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.112 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.[1mTestAvailableSpaceVolumeChoosingPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.fsdataset.[1mTestRoundRobinVolumeChoosingPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.256 s - in org.apache.hadoop.hdfs.server.datanode.fsdataset.[1mTestRoundRobinVolumeChoosingPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestNNHandlesBlockReportPerStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 51.55 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestNNHandlesBlockReportPerStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestFsDatasetCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 96.989 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestFsDatasetCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeTcpNoDelay[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.697 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeTcpNoDelay[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestIncrementalBlockReports[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.347 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestIncrementalBlockReports[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMetricsLogger[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.834 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeMetricsLogger[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestSimulatedFSDataset[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.462 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestSimulatedFSDataset[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockPoolSliceStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.307 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockPoolSliceStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestHSync[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.077 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestHSync[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockScanner[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 134.629 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockScanner[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.web.[1mTestDatanodeHttpXFrame[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.78 s - in org.apache.hadoop.hdfs.server.datanode.web.[1mTestDatanodeHttpXFrame[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.web.webhdfs.[1mTestParameterParser[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.322 s - in org.apache.hadoop.hdfs.server.datanode.web.webhdfs.[1mTestParameterParser[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.web.webhdfs.[1mTestDataNodeUGIProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.981 s - in org.apache.hadoop.hdfs.server.datanode.web.webhdfs.[1mTestDataNodeUGIProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeFSDataSetSink[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.762 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataNodeFSDataSetSink[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestProvidedReplicaImpl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.855 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestProvidedReplicaImpl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockCountersInPendingIBR[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.87 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockCountersInPendingIBR[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestBlockReplacement[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.543 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestBlockReplacement[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestCorruptMetadataFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.016 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestCorruptMetadataFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestDataDirs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.326 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestDataDirs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.datanode.[1mTestSimulatedFSDatasetWithMultipleStorages[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.441 s - in org.apache.hadoop.hdfs.server.datanode.[1mTestSimulatedFSDatasetWithMultipleStorages[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.mover.[1mTestStorageMover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 161.514 s - in org.apache.hadoop.hdfs.server.mover.[1mTestStorageMover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.server.mover.[1mTestMover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m19[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 217.253 s - in org.apache.hadoop.hdfs.server.mover.[1mTestMover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestIsMethodSupported[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.847 s - in org.apache.hadoop.hdfs.[1mTestIsMethodSupported[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSInotifyEventInputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.52 s - in org.apache.hadoop.hdfs.[1mTestDFSInotifyEventInputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSafeModeWithStripedFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.71 s - in org.apache.hadoop.hdfs.[1mTestSafeModeWithStripedFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.shortcircuit.[1mTestShortCircuitCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.302 s - in org.apache.hadoop.hdfs.shortcircuit.[1mTestShortCircuitCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.shortcircuit.[1mTestShortCircuitLocalRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.986 s - in org.apache.hadoop.hdfs.shortcircuit.[1mTestShortCircuitLocalRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelReadUtil[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m1[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.025 s - in org.apache.hadoop.hdfs.[1mTestParallelReadUtil[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelUnixDomainRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 40.074 s - in org.apache.hadoop.hdfs.[1mTestParallelUnixDomainRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestGetGroups[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.401 s - in org.apache.hadoop.hdfs.tools.[1mTestGetGroups[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestWebHDFSStoragePolicyCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.787 s - in org.apache.hadoop.hdfs.tools.[1mTestWebHDFSStoragePolicyCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDelegationTokenFetcher[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.573 s - in org.apache.hadoop.hdfs.tools.[1mTestDelegationTokenFetcher[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSZKFailoverController[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.759 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSZKFailoverController[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForContentSummary[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.165 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForContentSummary[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.357 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.935 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerWithStripedBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.076 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerWithStripedBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForAcl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.717 s - in org.apache.hadoop.hdfs.tools.offlineImageViewer.[1mTestOfflineImageViewerForAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSAdminWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m46[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 59.44 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSAdminWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestStoragePolicySatisfyAdminCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.814 s - in org.apache.hadoop.hdfs.tools.[1mTestStoragePolicySatisfyAdminCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.offlineEditsViewer.[1mTestOfflineEditsViewer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.068 s - in org.apache.hadoop.hdfs.tools.offlineEditsViewer.[1mTestOfflineEditsViewer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSAdmin[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.676 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSAdmin[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestViewFSStoragePolicyCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.049 s - in org.apache.hadoop.hdfs.tools.[1mTestViewFSStoragePolicyCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDebugAdmin[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.871 s - in org.apache.hadoop.hdfs.tools.[1mTestDebugAdmin[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSHAAdminMiniCluster[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.997 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSHAAdminMiniCluster[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestStoragePolicyCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.612 s - in org.apache.hadoop.hdfs.tools.[1mTestStoragePolicyCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestAdminHelper[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.046 s - in org.apache.hadoop.hdfs.tools.[1mTestAdminHelper[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestGetConf[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.852 s - in org.apache.hadoop.hdfs.tools.[1mTestGetConf[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.tools.[1mTestDFSHAAdmin[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.07 s - in org.apache.hadoop.hdfs.tools.[1mTestDFSHAAdmin[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithMissingBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 142.832 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithMissingBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeRespectsBindHostKeys[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.218 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeRespectsBindHostKeys[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournal[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.4 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournal[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeMXBean[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.943 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeMXBean[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.827 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournaledEditsCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.585 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournaledEditsCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeSync[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 56.275 s - in org.apache.hadoop.hdfs.qjournal.server.[1mTestJournalNodeSync[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.[1mTestMiniJournalCluster[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.087 s - in org.apache.hadoop.hdfs.qjournal.[1mTestMiniJournalCluster[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumCall[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.203 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumCall[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestSegmentRecoveryComparator[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.194 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestSegmentRecoveryComparator[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestEpochsAreUnique[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.098 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestEpochsAreUnique[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestIPCLoggerChannel[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.59 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestIPCLoggerChannel[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestQJMWithFaults[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 143.065 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestQJMWithFaults[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumJournalManagerUnit[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.353 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumJournalManagerUnit[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumJournalManager[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m28[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.141 s - in org.apache.hadoop.hdfs.qjournal.client.[1mTestQuorumJournalManager[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.[1mTestSecureNNWithQJM[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.942 s - in org.apache.hadoop.hdfs.qjournal.[1mTestSecureNNWithQJM[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.qjournal.[1mTestNNWithQJM[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.092 s - in org.apache.hadoop.hdfs.qjournal.[1mTestNNWithQJM[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestCrcCorruption[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.083 s - in org.apache.hadoop.hdfs.[1mTestCrcCorruption[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRollingUpgradeRollback[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.842 s - in org.apache.hadoop.hdfs.[1mTestRollingUpgradeRollback[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestKeyProviderCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.258 s - in org.apache.hadoop.hdfs.[1mTestKeyProviderCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.crypto.[1mTestHdfsCryptoStreams[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.309 s - in org.apache.hadoop.hdfs.crypto.[1mTestHdfsCryptoStreams[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStorageStateRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.795 s - in org.apache.hadoop.hdfs.[1mTestDFSStorageStateRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingPolicyWithSnapshot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.805 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingPolicyWithSnapshot[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.629 s - in org.apache.hadoop.hdfs.[1mTestDFSUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFsShellPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.418 s - in org.apache.hadoop.hdfs.[1mTestFsShellPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSmallBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.757 s - in org.apache.hadoop.hdfs.[1mTestSmallBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingPolicyWithSnapshotWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.282 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingPolicyWithSnapshotWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDNFailure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 178.497 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDNFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestPipelines[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.887 s - in org.apache.hadoop.hdfs.[1mTestPipelines[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecodingDeletedData[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 306.341 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecodingDeletedData[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.net.[1mTestDFSNetworkTopology[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.449 s - in org.apache.hadoop.hdfs.net.[1mTestDFSNetworkTopology[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.net.[1mTestDFSNetworkTopologyPerformance[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m1[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.031 s - in org.apache.hadoop.hdfs.net.[1mTestDFSNetworkTopologyPerformance[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDistributedFileSystem[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m34[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 53.317 s - in org.apache.hadoop.hdfs.[1mTestDistributedFileSystem[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMiniDFSCluster[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.463 s - in org.apache.hadoop.hdfs.[1mTestMiniDFSCluster[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSafeMode[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.666 s - in org.apache.hadoop.hdfs.[1mTestSafeMode[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestStateAlignmentContextWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 73.773 s - in org.apache.hadoop.hdfs.[1mTestStateAlignmentContextWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedInputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 54.035 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedInputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeLayoutUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.968 s - in org.apache.hadoop.hdfs.[1mTestDatanodeLayoutUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeStartupFixesLegacyStorageIDs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.384 s - in org.apache.hadoop.hdfs.[1mTestDatanodeStartupFixesLegacyStorageIDs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSAddressConfig[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.413 s - in org.apache.hadoop.hdfs.[1mTestDFSAddressConfig[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppendRestart[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.095 s - in org.apache.hadoop.hdfs.[1mTestFileAppendRestart[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.protocolPB.[1mTestPBHelper[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m40[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.64 s - in org.apache.hadoop.hdfs.protocolPB.[1mTestPBHelper[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLocalDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.889 s - in org.apache.hadoop.hdfs.[1mTestLocalDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadWhileWriting[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.364 s - in org.apache.hadoop.hdfs.[1mTestReadWhileWriting[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSnapshotCommands[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.43 s - in org.apache.hadoop.hdfs.[1mTestSnapshotCommands[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.489 s - in org.apache.hadoop.hdfs.[1mTestParallelRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelShortCircuitReadNoChecksum[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.372 s - in org.apache.hadoop.hdfs.[1mTestParallelShortCircuitReadNoChecksum[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMaintenanceState[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m25[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 416.993 s - in org.apache.hadoop.hdfs.[1mTestMaintenanceState[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestExternalBlockReader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.287 s - in org.apache.hadoop.hdfs.[1mTestExternalBlockReader[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReplaceDatanodeOnFailure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.688 s - in org.apache.hadoop.hdfs.[1mTestReplaceDatanodeOnFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingExerciseAPIs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.086 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingExerciseAPIs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestClientReportBadBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.936 s - in org.apache.hadoop.hdfs.[1mTestClientReportBadBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodeBenchmarkThroughput[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.145 s - in org.apache.hadoop.hdfs.[1mTestErasureCodeBenchmarkThroughput[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestClose[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.181 s - in org.apache.hadoop.hdfs.[1mTestClose[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReplaceDatanodeFailureReplication[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 61.642 s - in org.apache.hadoop.hdfs.[1mTestReplaceDatanodeFailureReplication[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeReport[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.049 s - in org.apache.hadoop.hdfs.[1mTestDatanodeReport[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingMultipleRacks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.054 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingMultipleRacks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCreation[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m25[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 80.05 s - in org.apache.hadoop.hdfs.[1mTestFileCreation[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMissingBlocksAlert[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.132 s - in org.apache.hadoop.hdfs.[1mTestMissingBlocksAlert[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSUpgradeFromImage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.54 s - in org.apache.hadoop.hdfs.[1mTestDFSUpgradeFromImage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestModTime[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.935 s - in org.apache.hadoop.hdfs.[1mTestModTime[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteConfigurationToDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.431 s - in org.apache.hadoop.hdfs.[1mTestWriteConfigurationToDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileStatusSerialization[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.297 s - in org.apache.hadoop.hdfs.[1mTestFileStatusSerialization[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRestartDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.515 s - in org.apache.hadoop.hdfs.[1mTestRestartDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLargeBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.89 s - in org.apache.hadoop.hdfs.[1mTestLargeBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.security.[1mTestDelegationToken[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.538 s - in org.apache.hadoop.hdfs.security.[1mTestDelegationToken[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.security.token.block.[1mTestBlockToken[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m20[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.499 s - in org.apache.hadoop.hdfs.security.token.block.[1mTestBlockToken[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.security.[1mTestDelegationTokenForProxyUser[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.688 s - in org.apache.hadoop.hdfs.security.[1mTestDelegationTokenForProxyUser[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppend[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.215 s - in org.apache.hadoop.hdfs.[1mTestFileAppend[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCreationDelete[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.154 s - in org.apache.hadoop.hdfs.[1mTestFileCreationDelete[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCorruption[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.205 s - in org.apache.hadoop.hdfs.[1mTestFileCorruption[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestGetFileChecksum[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.856 s - in org.apache.hadoop.hdfs.[1mTestGetFileChecksum[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestQuota[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m21[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.713 s - in org.apache.hadoop.hdfs.[1mTestQuota[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDataTransferProtocol[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.091 s - in org.apache.hadoop.hdfs.[1mTestDataTransferProtocol[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestListFilesInDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.411 s - in org.apache.hadoop.hdfs.[1mTestListFilesInDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestGetBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 64.344 s - in org.apache.hadoop.hdfs.[1mTestGetBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDeprecatedKeys[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.231 s - in org.apache.hadoop.hdfs.[1mTestDeprecatedKeys[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLeaseRecoveryStriped[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 45.223 s - in org.apache.hadoop.hdfs.[1mTestLeaseRecoveryStriped[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFSOutputSummer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.208 s - in org.apache.hadoop.hdfs.[1mTestFSOutputSummer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppend2[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.055 s - in org.apache.hadoop.hdfs.[1mTestFileAppend2[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedInputStreamWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 45.692 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedInputStreamWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestPread[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 119.976 s - in org.apache.hadoop.hdfs.[1mTestPread[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingPolicies[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m21[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 55.998 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingPolicies[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFetchImage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.991 s - in org.apache.hadoop.hdfs.[1mTestFetchImage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSUtil[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m33[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.616 s - in org.apache.hadoop.hdfs.[1mTestDFSUtil[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestAppendDifferentChecksum[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m3[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 9.348 s - in org.apache.hadoop.hdfs.[1mTestAppendDifferentChecksum[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStartupVersions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.315 s - in org.apache.hadoop.hdfs.[1mTestDFSStartupVersions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHDFSPolicyProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.165 s - in org.apache.hadoop.hdfs.[1mTestHDFSPolicyProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileLengthOnClusterRestart[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.627 s - in org.apache.hadoop.hdfs.[1mTestFileLengthOnClusterRestart[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBalancerBandwidth[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.606 s - in org.apache.hadoop.hdfs.[1mTestBalancerBandwidth[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDecommission[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m25[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 182.375 s - in org.apache.hadoop.hdfs.[1mTestDecommission[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelShortCircuitLegacyRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.322 s - in org.apache.hadoop.hdfs.[1mTestParallelShortCircuitLegacyRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRenameWhileOpen[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 47.217 s - in org.apache.hadoop.hdfs.[1mTestRenameWhileOpen[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppend3[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.195 s - in org.apache.hadoop.hdfs.[1mTestFileAppend3[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSOutputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.076 s - in org.apache.hadoop.hdfs.[1mTestDFSOutputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHttpPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.241 s - in org.apache.hadoop.hdfs.[1mTestHttpPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestApplyingStoragePolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.853 s - in org.apache.hadoop.hdfs.[1mTestApplyingStoragePolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestClientProtocolForPipelineRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 72.216 s - in org.apache.hadoop.hdfs.[1mTestClientProtocolForPipelineRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSetrepDecreasing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.331 s - in org.apache.hadoop.hdfs.[1mTestSetrepDecreasing[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestEncryptedTransfer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m30[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 128.67 s - in org.apache.hadoop.hdfs.[1mTestEncryptedTransfer[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestPersistBlocks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.383 s - in org.apache.hadoop.hdfs.[1mTestPersistBlocks[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLease[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.584 s - in org.apache.hadoop.hdfs.[1mTestLease[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelShortCircuitRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.719 s - in org.apache.hadoop.hdfs.[1mTestParallelShortCircuitRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSConfigKeys[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.054 s - in org.apache.hadoop.hdfs.[1mTestDFSConfigKeys[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHDFSServerPorts[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.612 s - in org.apache.hadoop.hdfs.[1mTestHDFSServerPorts[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecoding[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.968 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecoding[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSFinalize[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.36 s - in org.apache.hadoop.hdfs.[1mTestDFSFinalize[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDistributedFileSystemWithECFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.147 s - in org.apache.hadoop.hdfs.[1mTestDistributedFileSystemWithECFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSRename[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.344 s - in org.apache.hadoop.hdfs.[1mTestDFSRename[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestInjectionForSimulatedStorage[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.992 s - in org.apache.hadoop.hdfs.[1mTestInjectionForSimulatedStorage[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHAAuxiliaryPort[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.117 s - in org.apache.hadoop.hdfs.[1mTestHAAuxiliaryPort[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHdfsAdmin[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReservedRawPaths[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.528 s - in org.apache.hadoop.hdfs.[1mTestReservedRawPaths[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHFlush[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.245 s - in org.apache.hadoop.hdfs.[1mTestHFlush[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRollingUpgrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 117.189 s - in org.apache.hadoop.hdfs.[1mTestRollingUpgrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLeaseRecovery2[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 73.581 s - in org.apache.hadoop.hdfs.[1mTestLeaseRecovery2[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 77.053 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.68 s - in org.apache.hadoop.hdfs.[1mTestRead[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestConnCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.17 s - in org.apache.hadoop.hdfs.[1mTestConnCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBlockStoragePolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m22[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.945 s - in org.apache.hadoop.hdfs.[1mTestBlockStoragePolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteStripedFileWithFailure[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m1[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.071 s - in org.apache.hadoop.hdfs.[1mTestWriteStripedFileWithFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSInputStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.796 s - in org.apache.hadoop.hdfs.[1mTestDFSInputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReplication[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 46.785 s - in org.apache.hadoop.hdfs.[1mTestReplication[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestExtendedAcls[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.009 s - in org.apache.hadoop.hdfs.[1mTestExtendedAcls[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCreationEmpty[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.91 s - in org.apache.hadoop.hdfs.[1mTestFileCreationEmpty[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileCreationClient[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.112 s - in org.apache.hadoop.hdfs.[1mTestFileCreationClient[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestLeaseRecovery[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 24.225 s - in org.apache.hadoop.hdfs.[1mTestLeaseRecovery[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecodingCorruptData[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 308.839 s - in org.apache.hadoop.hdfs.[1mTestReadStripedFileWithDecodingCorruptData[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDisableConnCache[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.271 s - in org.apache.hadoop.hdfs.[1mTestDisableConnCache[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSafeModeWithStripedFileWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.55 s - in org.apache.hadoop.hdfs.[1mTestSafeModeWithStripedFileWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeRegistration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.582 s - in org.apache.hadoop.hdfs.[1mTestDatanodeRegistration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDistributedFileSystemWithECFileWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.689 s - in org.apache.hadoop.hdfs.[1mTestDistributedFileSystemWithECFileWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocalMetrics[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.486 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocalMetrics[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderRemote[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.318 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderRemote[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestClientBlockVerification[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.618 s - in org.apache.hadoop.hdfs.client.impl.[1mTestClientBlockVerification[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderIoProvider[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.375 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderIoProvider[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocal[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m38[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.641 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocal[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderFactory[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m10[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.69 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderFactory[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocalLegacy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.251 s - in org.apache.hadoop.hdfs.client.impl.[1mTestBlockReaderLocalLegacy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSClientFailover[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.967 s - in org.apache.hadoop.hdfs.[1mTestDFSClientFailover[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.646 s - in org.apache.hadoop.hdfs.[1mTestDFSPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMultiThreadedHflush[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.127 s - in org.apache.hadoop.hdfs.[1mTestMultiThreadedHflush[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileStatusWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.905 s - in org.apache.hadoop.hdfs.[1mTestFileStatusWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestUnsetAndChangeDirectoryEcPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.862 s - in org.apache.hadoop.hdfs.[1mTestUnsetAndChangeDirectoryEcPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileChecksumCompositeCrc[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m32[m, Failures: 0, [1;31mErrors: [0;1;31m10[m, Skipped: 0, Time elapsed: 195.692 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestFileChecksumCompositeCrc[m
[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery11(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 6.961 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145333156-172.17.0.5-1586401628141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38645,DS-92d646b5-9792-4d9b-a945-eab924f94380,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-98a2612b-3199-4b29-b09f-d6003843c194,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-5c10c89a-0783-4070-97e9-5ee119daac7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-4d1a17c7-016c-447e-9ebf-7aa9695c7740,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-00fbecee-3557-4e82-b7fb-abbde2c4e3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-6da87d52-9415-4f84-8cde-1d54bd5236d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-ac604781-5935-49b5-978a-dbd3cb8698ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-a5139399-afc0-4f05-b6c0-77506316f654,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery11(TestFileChecksum.java:421)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery12(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 6.157 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119622235-172.17.0.5-1586401635115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38624,DS-a8a86338-fb10-4acd-8410-593d1d6ac013,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-2c80db66-3cb3-40de-abfb-cbcee666bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-149ed372-97a9-428f-9aac-7988019b669f,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-aad82f4f-66c2-43f2-b481-2c1eb453aa7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-f42f737c-ff46-450b-bb3e-ebe0c0f11ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-6e3bf75d-7034-4d00-bc45-b7a7da8733c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-63a24795-4dc1-442a-92e5-bb5ec450b217,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-bc5b6f38-64cb-4c28-af2e-078bc3df1a2d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12(TestFileChecksum.java:432)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 6.163 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562363026-172.17.0.5-1586401641259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34738,DS-804b2bd0-8c8d-4cae-80c1-55539d57fa70,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-0e03d719-4c18-432f-8e1f-9f4b5344aa21,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-f90d96b5-58ca-433f-8665-b419d06b83d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-1bab67f3-6a8e-4b58-9331-b1e9743945cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-7b08880d-cb4d-499e-bf86-02f16bc36897,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-35ed3592-df18-48b0-8055-d5b28ce6d06b,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-ac1c81fd-cd81-4c62-b5d6-aaf97c4c3191,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-80a73397-5237-4ce2-9238-2fa390dca35f,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 6.257 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732649706-172.17.0.5-1586401647425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46527,DS-94e61682-ce17-4623-86f1-a35d29034c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-f5819ace-8422-48be-8d6b-4b8bea13c253,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-7a210e09-af05-4c5c-b0ee-4b70a8efd431,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-c97bcba0-dcc5-4352-96ac-08918f02a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-7bd2b33f-0e1b-4ffd-bfe0-ad2ed4fa76d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-9d4d085e-2305-481a-bd9f-218ecfc65b37,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-3ce34371-617d-4e5c-9133-d968a611162e,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-efacd6d3-be26-42bd-89b9-c1f7d481c873,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.568 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018774451-172.17.0.5-1586401653681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:45061,DS-c6366749-50fa-4d1a-82ef-7e6b31e6afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-b8ec65fc-d861-41fe-97b1-d8f8ebf3bf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-0485fc2b-2774-45bf-8708-4a78ad0418eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-3fb79261-1a54-48e0-be9d-12ff4b66be05,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-da1f2674-8702-47a5-957f-605226a1556d,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-6655f1e0-c33b-48e7-bd43-f1a8acd2e34d,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-821c2784-507b-4425-ada1-301736735cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-42c27925-3549-402a-97af-23cb2ebee204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.839 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454170538-172.17.0.5-1586401697512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=37748736; locs=[DatanodeInfoWithStorage[127.0.0.1:43606,DS-75d9551c-193b-40f5-92b2-cb6c21920f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-6e765dac-fab8-46a7-a8dd-b74eb0cbc15b,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-3a8b4786-4804-4a7a-94d5-0fff1eb820ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-4c1c42db-c89b-4ca9-86f4-392892241f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-211df64b-16f2-4486-9fe7-cc08c2a40c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-7d1b42d3-0acf-4e86-aacd-75f32360fe28,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-3c88dbaa-3081-4773-82f0-d3d5086486ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-af4948c3-48d5-4c73-8ec3-05c795bdf18d,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 7.253 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-1677329273-172.17.0.5-1586401703340:blk_-9223372036854775584_1014; getBlockSize()=37748736; corrupt=false; offset=113246208; locs=[DatanodeInfoWithStorage[127.0.0.1:37450,DS-1c664409-9d51-46f1-b3e3-9ffc2be44a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-d2fb51a8-e532-4fbd-b5e7-840e476f2834,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-18be842f-56b9-4d8d-a4e8-1a28119bff26,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-d9f1926d-8000-4f78-906f-65747bec46e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-00a19dbe-1d38-4501-8418-be9ce62ac0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-5100fb64-6ed7-43d5-8c42-07545d5e963a,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-dbd90193-b03c-4111-8cef-598b63ad47a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-c7286dd7-79e3-47b2-b4ca-e9dfe1842b32,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery6(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.428 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551410682-172.17.0.5-1586401793287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45446,DS-fcc450ab-54fd-407d-a7a1-62413e5a94ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-0f57dac8-0b9d-46fe-8886-a12c0960c95c,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-4f6d9e30-0850-417e-9007-82d9ac533716,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-184e822a-9c7c-4a8c-af9b-f5a362952b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-5acd6fc7-faa1-48cb-aca1-402aea091360,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-7c0c82b5-e762-4f87-a8bc-4e577bdc73b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-e539180d-a26b-4be8-9fb4-ae35cebcdf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-4666907a-348a-4b39-aae1-f17fbe3e334d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery8(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.666 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48772698-172.17.0.5-1586401804005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41334,DS-a68497e8-eb38-453a-99d4-0657240ac705,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-10bbc908-a0d4-4dc0-bec5-a4530ddfab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-0d1ca64a-d784-4578-b2d1-9d4e5dd4d631,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-9c745432-dfd2-4cc2-8cda-0c6a3d5e0e31,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-7ecc88d5-961b-405b-aaa2-811416025b91,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-eb0ecb5a-a029-48ad-9355-a4458eb3ad63,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-8020a766-7b35-4075-a49d-2a7d898f5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-001ecd7b-c7df-4f75-bc09-9fdab72321af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8(TestFileChecksum.java:388)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery9(org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc)  Time elapsed: 5.338 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091986653-172.17.0.5-1586401809672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45360,DS-b7167d32-7c4f-47f3-9663-1befe0f6a378,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-158fec9b-f17f-4e04-8893-e0b270acc28c,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-75e5571c-1bb0-4d61-a03b-1f7dfd24911e,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c1ae1afc-7a57-4271-a162-3fd7834ee254,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-1f6f4d73-502a-497c-a4f4-ef09c97d60c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-e643e7a0-8e7e-41de-afdd-30358780f8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-84657e6b-b2ff-4f18-89f6-f3f98d1a6373,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-eb6c15e1-2590-46d0-b758-99afb38c1dfe,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery9(TestFileChecksum.java:399)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileStatus[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.075 s - in org.apache.hadoop.hdfs.[1mTestFileStatus[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestWriteBlockGetsBlockLengthHint[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.21 s - in org.apache.hadoop.hdfs.[1mTestWriteBlockGetsBlockLengthHint[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestMultipleNNPortQOP[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.343 s - in org.apache.hadoop.hdfs.[1mTestMultipleNNPortQOP[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestEncryptionZonesWithHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.709 s - in org.apache.hadoop.hdfs.[1mTestEncryptionZonesWithHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestTrashWithSecureEncryptionZones[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.864 s - in org.apache.hadoop.hdfs.[1mTestTrashWithSecureEncryptionZones[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestCombinedHostsFileReader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.397 s - in org.apache.hadoop.hdfs.util.[1mTestCombinedHostsFileReader[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestLightWeightHashSet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m14[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.144 s - in org.apache.hadoop.hdfs.util.[1mTestLightWeightHashSet[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestCyclicIteration[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.047 s - in org.apache.hadoop.hdfs.util.[1mTestCyclicIteration[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestMD5FileUtils[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.218 s - in org.apache.hadoop.hdfs.util.[1mTestMD5FileUtils[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestLightWeightLinkedSet[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m17[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.156 s - in org.apache.hadoop.hdfs.util.[1mTestLightWeightLinkedSet[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestStripedBlockUtil[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.005 s - in org.apache.hadoop.hdfs.util.[1mTestStripedBlockUtil[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestBestEffortLongFile[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.174 s - in org.apache.hadoop.hdfs.util.[1mTestBestEffortLongFile[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestXMLUtils[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.064 s - in org.apache.hadoop.hdfs.util.[1mTestXMLUtils[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestDiff[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.702 s - in org.apache.hadoop.hdfs.util.[1mTestDiff[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.util.[1mTestAtomicFileOutputStream[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m4[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 0.161 s - in org.apache.hadoop.hdfs.util.[1mTestAtomicFileOutputStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileStatusWithDefaultECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.784 s - in org.apache.hadoop.hdfs.[1mTestFileStatusWithDefaultECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileAppend4[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.384 s - in org.apache.hadoop.hdfs.[1mTestFileAppend4[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestParallelShortCircuitReadUnCached[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 28.936 s - in org.apache.hadoop.hdfs.[1mTestParallelShortCircuitReadUnCached[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBlockMissingException[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.58 s - in org.apache.hadoop.hdfs.[1mTestBlockMissingException[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestAppendSnapshotTruncate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.486 s - in org.apache.hadoop.hdfs.[1mTestAppendSnapshotTruncate[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSMkdirs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.972 s - in org.apache.hadoop.hdfs.[1mTestDFSMkdirs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestRollingUpgradeDowngrade[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.702 s - in org.apache.hadoop.hdfs.[1mTestRollingUpgradeDowngrade[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSShellGenericOptions[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.719 s - in org.apache.hadoop.hdfs.[1mTestDFSShellGenericOptions[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBlocksScheduledCounter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.222 s - in org.apache.hadoop.hdfs.[1mTestBlocksScheduledCounter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSInotifyEventInputStreamKerberized[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.864 s - in org.apache.hadoop.hdfs.[1mTestDFSInotifyEventInputStreamKerberized[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileChecksum[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m32[m, Failures: 0, [1;31mErrors: [0;1;31m9[m, Skipped: 0, Time elapsed: 191.067 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestFileChecksum[m
[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery10(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 9.01 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723159826-172.17.0.5-1586402042334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46581,DS-9669099f-99b3-415b-90d6-f824c331f4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-5804d6de-49a0-452a-be88-ca4050bbb03b,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-e7c9eca0-ec15-44dd-9e7a-404d00be8ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-697737e0-3c28-4ef3-93ef-a7c788103657,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-6a1b1fb8-47de-4e39-8592-44d5711f1d33,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-c4d1b53f-4282-49fe-b17c-0eb874b9f126,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-8240c0cf-c737-41e1-84d5-f24c815cd28b,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-4d67c1b2-f0c5-4080-ba34-9eb1eba0ecc6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10(TestFileChecksum.java:410)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery11(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.885 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375066242-172.17.0.5-1586402050690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32784,DS-9526d5b5-b6da-4370-98a2-a247d17686d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-7093dceb-046a-40a3-a772-1ced05bcfc82,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-439ff59c-e8d7-4109-870c-84b4389daf0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-0f361ed6-c2f2-44e5-ac4b-6d0b4afc8a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-cd421a74-f617-4ad2-ad85-643b06eac268,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-44df888c-ff94-45b4-b37b-325f803f26f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-680fb880-438f-4b16-8668-cd3b3950c1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-c46f8018-dfbe-4920-96a7-630407942264,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery11(TestFileChecksum.java:421)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery13(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.355 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422855891-172.17.0.5-1586402063135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45188,DS-417d626f-2331-4722-9a6e-ad0fcaba6647,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-0608b9c1-81e8-4380-b784-d649088e5134,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-fc85b1d6-31b5-4c95-b5cc-e23c91b67bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-d8f40d2b-fb5c-4c83-a1cc-4ade39f97456,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-828d4907-00ff-4791-8815-463eb60c0006,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-d43e8480-6e4d-4d49-8ab7-e944dfcea99d,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-cf05469a-6a36-4d61-b3a7-f66ff4455cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-1a0d74e5-e7c6-42d3-aeb6-94802a8a6805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13(TestFileChecksum.java:443)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery14(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 6.079 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030212430-172.17.0.5-1586402068498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-fc146500-db6e-4da7-ab37-0e16bd70b722,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-68122157-54c1-486b-9d47-36bdbed3e6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-af85fd9a-91f7-4756-afb4-184dd2588304,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-bb4e41b9-9163-40b4-ac82-a6d603f471ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-e817f806-4513-4817-b7be-595f2edc48d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-fafdc708-eda2-4c76-9c41-7e6277af159d,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-dd1b849e-e2b8-46ed-92ff-681f053770c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-c81675e7-6b4a-4d76-b51d-59c2016c3c0f,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14(TestFileChecksum.java:454)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery15(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 6.287 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902173391-172.17.0.5-1586402074571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43646,DS-ac3f1a50-4079-47d2-9ba9-d3e305f6b0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-fe9b65a0-1cbb-4f18-a59c-384320aae982,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-96f78b0c-7c1c-48e1-a8f7-237c4c7b5e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-e740954e-d911-4b87-854a-c1b12ae1408f,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-f755f447-4f8c-4ca7-8de3-09b31ddfb6da,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-f2376b15-a7ed-44b9-b0f4-96367c4a5cee,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-5a7c00fc-ef7c-4785-ba7e-dd4f88dc9881,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-50354192-968a-4ea9-a17f-a564ae7cee87,DISK]]; indices=[0, 1, 2, 3, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15(TestFileChecksum.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery18(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.458 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697460473-172.17.0.5-1586402091852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39767,DS-5dfa89f5-4ad3-4041-bb5d-4e51d77d153a,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-64cda6ca-b8ca-4c3c-86aa-37c63344f891,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-7af1b280-e3e8-4a81-9824-ba4879bef69c,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-7c8c8d18-c2b6-4a2a-909d-9b7c0189ad88,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-708cc20a-33c1-4b73-8599-e25ba263bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-65f12fe9-5ca7-48f9-9074-7b27a1466824,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-d631c41e-75a0-4df5-871f-2f0d9a38b181,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-5e78c678-3b51-4c3c-aec7-b62ecfd66114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocks1(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.417 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021747951-172.17.0.5-1586402117229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32991,DS-c2c4717b-2645-4579-9f10-a217707b51dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-cad33d38-042c-48df-89a1-a312c0f4ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-e323ce40-f5ee-4a2b-837a-1ed607b5fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-e1473ed1-419b-4fd0-a2ab-44eb3ad81758,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-42a8cfe6-4b94-4a4a-a2ac-008b9908465f,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-268942a0-bc56-48ce-9dd6-b10d19261796,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-d15dde87-45bc-4af4-ac2f-21ec65d167cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-fb81ced5-bff2-474d-a28b-06ff01b9c72c,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1(TestFileChecksum.java:256)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocks2(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 6.512 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum2': Fail to get block checksum for LocatedStripedBlock{BP-360328624-172.17.0.5-1586402122644:blk_-9223372036854775632_1011; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36563,DS-673e81ea-6a50-45f1-b966-94b7bf80a410,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-353a7207-2c5f-4a0e-a280-fe4adba9a2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-0bc8559a-5a87-443a-b007-39b56e5edcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-aa671c02-3f69-41e3-87df-edc5276dd9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-56b9e67f-37c3-4be8-9545-da34ee8be1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-a4004aaa-d01d-4394-9857-da2a5e1d66a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-fdbc36e0-b2cf-480d-ac8f-81254a96183d,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-88908857-b735-4cee-b041-f3df87d821e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1691)
	at org.apache.hadoop.hdfs.DistributedFileSystem$33.doCall(DistributedFileSystem.java:1688)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1700)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:586)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2(TestFileChecksum.java:273)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;31mERROR[m] testStripedFileChecksumWithMissedDataBlocksRangeQuery8(org.apache.hadoop.hdfs.TestFileChecksum)  Time elapsed: 5.496 s  <<< ERROR!
org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575318100-172.17.0.5-1586402221781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35809,DS-182b6a65-4d3f-409f-b20b-bd3f9961495c,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-e451dbbb-ee8b-49d1-9cc9-ec8171569308,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-09ce6d90-fd61-406c-86f4-ad7e556ff628,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-efa6f160-2e35-4385-a575-ca6d7521d4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-b2d28a52-ed8a-4dd0-9708-d8b62be9b651,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-eb295d25-04f1-4d2a-b401-75ede269c834,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-1cf79a69-f1f3-42c2-9fc3-34b464a8f43c,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-9f735651-9e81-4061-8f05-2bddf9b90526,DISK]]; indices=[0, 1, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8(TestFileChecksum.java:388)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestEncryptionZonesWithKMS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m45[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 113.658 s - in org.apache.hadoop.hdfs.[1mTestEncryptionZonesWithKMS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSClientExcludedNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.62 s - in org.apache.hadoop.hdfs.[1mTestDFSClientExcludedNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSRemove[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.538 s - in org.apache.hadoop.hdfs.[1mTestDFSRemove[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSShell[m
[[1;31mERROR[m] [1;31mTests [0;1mrun: [0;1m49[m, [1;31mFailures: [0;1;31m1[m, Errors: 0, Skipped: 0, Time elapsed: 22.294 s[1;31m <<< FAILURE![m - in org.apache.hadoop.hdfs.[1mTestDFSShell[m
[[1;31mERROR[m] testCopyFromLocalWithPermissionDenied(org.apache.hadoop.hdfs.TestDFSShell)  Time elapsed: 0.092 s  <<< FAILURE!
java.lang.AssertionError: put is working expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.apache.hadoop.hdfs.TestDFSShell.testCopyFromLocalWithPermissionDenied(TestDFSShell.java:2765)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDatanodeDeath[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 67.911 s - in org.apache.hadoop.hdfs.[1mTestDatanodeDeath[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSClientSocketSize[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.808 s - in org.apache.hadoop.hdfs.[1mTestDFSClientSocketSize[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSRollback[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.219 s - in org.apache.hadoop.hdfs.[1mTestDFSRollback[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSeekBug[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.074 s - in org.apache.hadoop.hdfs.[1mTestSeekBug[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFSInputChecker[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.933 s - in org.apache.hadoop.hdfs.[1mTestFSInputChecker[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithFailure[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 112.566 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithFailure[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestBlockTokenWrappingQOP[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 55.387 s - in org.apache.hadoop.hdfs.[1mTestBlockTokenWrappingQOP[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDecommissionWithStriped[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 88.487 s - in org.apache.hadoop.hdfs.[1mTestDecommissionWithStriped[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSecureEncryptionZoneWithKMS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.204 s - in org.apache.hadoop.hdfs.[1mTestSecureEncryptionZoneWithKMS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestAbandonBlock[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.192 s - in org.apache.hadoop.hdfs.[1mTestAbandonBlock[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestErasureCodingPoliciesWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m21[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 56.78 s - in org.apache.hadoop.hdfs.[1mTestErasureCodingPoliciesWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHDFSFileSystemContract[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m44[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 43.071 s - in org.apache.hadoop.hdfs.[1mTestHDFSFileSystemContract[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestSetTimes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.167 s - in org.apache.hadoop.hdfs.[1mTestSetTimes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHDFS[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m35[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 126.582 s - in org.apache.hadoop.hdfs.web.[1mTestWebHDFS[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsUrl[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.091 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsUrl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithAuthenticationFilter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.625 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithAuthenticationFilter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.resources.[1mTestParam[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m34[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.309 s - in org.apache.hadoop.hdfs.web.resources.[1mTestParam[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestJsonUtil[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.498 s - in org.apache.hadoop.hdfs.web.[1mTestJsonUtil[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHDFSXAttr[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.088 s - in org.apache.hadoop.hdfs.web.[1mTestWebHDFSXAttr[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHDFSForHA[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.505 s - in org.apache.hadoop.hdfs.web.[1mTestWebHDFSForHA[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithMultipleNameNodes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.902 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithMultipleNameNodes[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithRestCsrfPreventionFilter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m32[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 38.413 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsWithRestCsrfPreventionFilter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestAuthFilter[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.331 s - in org.apache.hadoop.hdfs.web.[1mTestAuthFilter[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsTimeouts[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.413 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsTimeouts[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestFSMainOperationsWebHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m53[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.526 s - in org.apache.hadoop.hdfs.web.[1mTestFSMainOperationsWebHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHDFSAcl[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m66[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 26.724 s - in org.apache.hadoop.hdfs.web.[1mTestWebHDFSAcl[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestHttpsFileSystem[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.763 s - in org.apache.hadoop.hdfs.web.[1mTestHttpsFileSystem[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsFileSystemContract[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m53[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.479 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsFileSystemContract[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.web.[1mTestWebHdfsTokens[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.991 s - in org.apache.hadoop.hdfs.web.[1mTestWebHdfsTokens[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestTrashWithEncryptionZones[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.202 s - in org.apache.hadoop.hdfs.[1mTestTrashWithEncryptionZones[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestHDFSTrash[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.508 s - in org.apache.hadoop.hdfs.[1mTestHDFSTrash[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m16[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 75.787 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestListFilesInFileContext[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.427 s - in org.apache.hadoop.hdfs.[1mTestListFilesInFileContext[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDataStream[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.909 s - in org.apache.hadoop.hdfs.[1mTestDataStream[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithFailureWithRandomECPolicy[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.381 s - in org.apache.hadoop.hdfs.[1mTestDFSStripedOutputStreamWithFailureWithRandomECPolicy[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestFileConcurrentReader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.222 s - in org.apache.hadoop.hdfs.[1mTestFileConcurrentReader[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDFSClientRetries[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m13[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 138.598 s - in org.apache.hadoop.hdfs.[1mTestDFSClientRetries[m
[[1;34mINFO[m] Running org.apache.hadoop.hdfs.[1mTestDataTransferKeepalive[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.998 s - in org.apache.hadoop.hdfs.[1mTestDataTransferKeepalive[m
[[1;34mINFO[m] Running org.apache.hadoop.security.[1mTestPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.928 s - in org.apache.hadoop.security.[1mTestPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.security.[1mTestRefreshUserMappings[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.55 s - in org.apache.hadoop.security.[1mTestRefreshUserMappings[m
[[1;34mINFO[m] Running org.apache.hadoop.security.[1mTestPermissionSymlinks[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.626 s - in org.apache.hadoop.security.[1mTestPermissionSymlinks[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.shell.[1mTestHdfsTextCommand[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.558 s - in org.apache.hadoop.fs.shell.[1mTestHdfsTextCommand[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestHDFSFileContextMainOperations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m77[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.192 s - in org.apache.hadoop.fs.[1mTestHDFSFileContextMainOperations[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestSymlinkHdfsFileSystem[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m74[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m2[m, Time elapsed: 16.854 s - in org.apache.hadoop.fs.[1mTestSymlinkHdfsFileSystem[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestEnhancedByteBufferAccess[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m10[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m1[m, Time elapsed: 15.967 s - in org.apache.hadoop.fs.[1mTestEnhancedByteBufferAccess[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestSymlinkHdfsDisable[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.114 s - in org.apache.hadoop.fs.[1mTestSymlinkHdfsDisable[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestGlobPaths[m
[[1;33mWARNING[m] [1;33mTests [0;1mrun: [0;1m37[m, Failures: 0, Errors: 0, [1;33mSkipped: [0;1;33m6[m, Time elapsed: 4.801 s - in org.apache.hadoop.fs.[1mTestGlobPaths[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestHdfsNativeCodeLoader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.125 s - in org.apache.hadoop.fs.[1mTestHdfsNativeCodeLoader[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestUrlStreamHandler[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m5[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.592 s - in org.apache.hadoop.fs.[1mTestUrlStreamHandler[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestResolveHdfsSymlink[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.79 s - in org.apache.hadoop.fs.[1mTestResolveHdfsSymlink[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.permission.[1mTestStickyBit[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.973 s - in org.apache.hadoop.fs.permission.[1mTestStickyBit[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestSymlinkHdfsFileContext[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m71[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.414 s - in org.apache.hadoop.fs.[1mTestSymlinkHdfsFileContext[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractSeek[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m18[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.417 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractSeek[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractSetTimes[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.844 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractSetTimes[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractRename[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.381 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractRename[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractDelete[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.717 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractDelete[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractCreate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.5 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractCreate[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractRootDirectory[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.147 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractRootDirectory[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractMultipartUploader[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m15[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.023 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractMultipartUploader[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractPathHandle[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m32[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.738 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractPathHandle[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractGetFileStatus[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m18[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.695 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractGetFileStatus[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractAppend[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.376 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractAppend[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractOpen[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m6[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.84 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractOpen[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractConcat[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.876 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractConcat[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractMkdir[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m8[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.02 s - in org.apache.hadoop.fs.contract.hdfs.[1mTestHDFSContractMkdir[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestFcHdfsCreateMkdir[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.646 s - in org.apache.hadoop.fs.[1mTestFcHdfsCreateMkdir[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.loadGenerator.[1mTestLoadGenerator[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.647 s - in org.apache.hadoop.fs.loadGenerator.[1mTestLoadGenerator[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestUnbuffer[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.768 s - in org.apache.hadoop.fs.[1mTestUnbuffer[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestFcHdfsPermission[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m4[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.519 s - in org.apache.hadoop.fs.[1mTestFcHdfsPermission[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemLinkFallback[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m75[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 23.232 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemLinkFallback[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsAtHdfsRoot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m65[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.297 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsAtHdfsRoot[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithTruncate[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.867 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithTruncate[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithAcls[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.158 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithAcls[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsDefaultValue[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m7[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.779 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsDefaultValue[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemAtHdfsRoot[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m72[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.756 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemAtHdfsRoot[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsFileStatusHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.767 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsFileStatusHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m78[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.155 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemLinkMergeSlash[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m76[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.631 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemLinkMergeSlash[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsWithXAttrs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.127 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsWithXAttrs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsWithAcls[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.064 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsWithAcls[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFsHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m65[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.225 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFsHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithXAttrs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.037 s - in org.apache.hadoop.fs.viewfs.[1mTestViewFileSystemWithXAttrs[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestWebHdfsFileContextMainOperations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m68[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.855 s - in org.apache.hadoop.fs.[1mTestWebHdfsFileContextMainOperations[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestSWebHdfsFileContextMainOperations[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m68[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.601 s - in org.apache.hadoop.fs.[1mTestSWebHdfsFileContextMainOperations[m
[[1;34mINFO[m] Running org.apache.hadoop.fs.[1mTestFcHdfsSetUMask[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m12[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.539 s - in org.apache.hadoop.fs.[1mTestFcHdfsSetUMask[m
[[1;34mINFO[m] Running org.apache.hadoop.[1mTestGenericRefresh[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m9[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.79 s - in org.apache.hadoop.[1mTestGenericRefresh[m
[[1;34mINFO[m] Running org.apache.hadoop.metrics2.sink.[1mTestRollingFileSystemSinkWithHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m11[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.084 s - in org.apache.hadoop.metrics2.sink.[1mTestRollingFileSystemSinkWithHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.metrics2.sink.[1mTestRollingFileSystemSinkWithSecureHdfs[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.319 s - in org.apache.hadoop.metrics2.sink.[1mTestRollingFileSystemSinkWithSecureHdfs[m
[[1;34mINFO[m] Running org.apache.hadoop.[1mTestRefreshCallQueue[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m2[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.627 s - in org.apache.hadoop.[1mTestRefreshCallQueue[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestAclCLIWithPosixAclInheritance[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.247 s - in org.apache.hadoop.cli.[1mTestAclCLIWithPosixAclInheritance[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestErasureCodingCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.135 s - in org.apache.hadoop.cli.[1mTestErasureCodingCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestHDFSCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 96.554 s - in org.apache.hadoop.cli.[1mTestHDFSCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestCacheAdminCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.277 s - in org.apache.hadoop.cli.[1mTestCacheAdminCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestXAttrCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.542 s - in org.apache.hadoop.cli.[1mTestXAttrCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestDeleteCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 7.256 s - in org.apache.hadoop.cli.[1mTestDeleteCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestCryptoAdminCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.031 s - in org.apache.hadoop.cli.[1mTestCryptoAdminCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.cli.[1mTestAclCLI[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.342 s - in org.apache.hadoop.cli.[1mTestAclCLI[m
[[1;34mINFO[m] Running org.apache.hadoop.tracing.[1mTestTracing[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.107 s - in org.apache.hadoop.tracing.[1mTestTracing[m
[[1;34mINFO[m] Running org.apache.hadoop.tracing.[1mTestTracingShortCircuitLocalRead[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.468 s - in org.apache.hadoop.tracing.[1mTestTracingShortCircuitLocalRead[m
[[1;34mINFO[m] Running org.apache.hadoop.tracing.[1mTestTraceAdmin[m
[[1;34mINFO[m] [1;32mTests run: [0;1;32m3[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.935 s - in org.apache.hadoop.tracing.[1mTestTraceAdmin[m
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;31mERROR[m] [1;31mFailures: [m
[[1;31mERROR[m] [1;31m  TestDFSShell.testCopyFromLocalWithPermissionDenied:2765 put is working expected:<1> but was:<0>[m
[[1;31mERROR[m] [1;31m  TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverAllDataBlocks:187->TestReconstructStripedFile.assertFileBlocksReconstruction:399 arrays first differed at element [314572]; expected:<1> but was:<0>[m
[[1;31mERROR[m] [1;31m  TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverAnyBlocks:222->TestReconstructStripedFile.assertFileBlocksReconstruction:399 arrays first differed at element [0]; expected:<1> but was:<-104>[m
[[1;31mERROR[m] [1;31m  TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverOneDataBlock:201->TestReconstructStripedFile.assertFileBlocksReconstruction:399 arrays first differed at element [0]; expected:<1> but was:<0>[m
[[1;31mERROR[m] [1;31m  TestReconstructStripedFileWithRandomECPolicy>TestReconstructStripedFile.testRecoverOneDataBlock2:215->TestReconstructStripedFile.assertFileBlocksReconstruction:399 arrays first differed at element [0]; expected:<1> but was:<-103>[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailure.testDNFailToStartWithDataDirNonWritable:535->startNewDataNodeWithDiskFailure:572 Failed to get expected IOException[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailure.testDataNodeFailToStartWithVolumeFailure:503->startNewDataNodeWithDiskFailure:572 Failed to get expected IOException[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailureToleration.testValidVolumesAtStartup:131 The DN shouldn't have a bad directory.[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailureToleration.testVolumeAndTolerableConfiguration:208->testVolumeConfig:259 expected:<false> but was:<true>[m
[[1;31mERROR[m] [1;31m  TestDiskBalancer.testDiskBalancerWithFedClusterWithOneNameServiceEmpty:278[m
[[1;31mERROR[m] [1;31m  TestCheckpoint.testCheckpointWithSeparateDirsAfterNameFails:2143 Did not fail to checkpoint when there are no valid storage dirs[m
[[1;31mERROR[m] [1;31m  TestCheckpoint.testNameDirError:180 NN should have failed to start with /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 set unreadable[m
[[1;31mERROR[m] [1;31m  TestEditLog.testFailedOpen:1068 Did no throw exception on only having a bad dir[m
[[1;31mERROR[m] [1;31m  TestEditLog.testFailedOpen:1068 Did no throw exception on only having a bad dir[m
[[1;31mERROR[m] [1;31m  TestFileJournalManager.testDoPreUpgradeIOError Expected test to throw (an instance of java.io.IOException and exception with message a string containing "failure in native rename")[m
[[1;31mERROR[m] [1;31m  TestNNStorageRetentionFunctional.testPurgingWithNameEditsDirAfterFailure:117 Bad files matching fsimage_\d* in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/nn0/current expected:<...e_000000000000000000[2,fsimage_0000000000000000004]> but was:<...e_000000000000000000[4,fsimage_0000000000000000006]>[m
[[1;31mERROR[m] [1;31m  TestNameNodeMXBean.testNameNodeMXBeanInfo:257[m
[[1;31mERROR[m] [1;31m  TestSaveNamespace.testReinsertnamedirsInSavenamespace:292 Savenamespace should have marked one directory as bad. But found 0 bad directories.[m
[[1;31mERROR[m] [1;31m  TestStartup.testNNFailToStartOnReadOnlyNNDir:744 Restarting NN should fail on read only NN dir.[m
[[1;31mERROR[m] [1;31m  TestStorageRestore.testStorageRestoreFailure:416[m
[[1;31mERROR[m] [1;31m  TestFailureOfSharedDir.testFailureOfSharedDir:169 Succeeded in rolling edit log despite shared dir being deleted[m
[[1;31mERROR[m] [1;31m  TestBlockStorageMovementAttemptedItems.testNoBlockMovementAttemptFinishedReportAdded:131 Item doesn't exist in the attempted list expected:<1> but was:<0>[m
[[1;31mERROR[m] [1;31mErrors: [m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->getFileChecksum:586 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery10:410->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery11:421->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18:506->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8:388->testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks1:256->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocks2:273->TestFileChecksum.getFileChecksum:586 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery11:421->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery12:432->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery13:443->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery14:454->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery15:465->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6:366->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery8:388->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestFileChecksumCompositeCrc>TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery9:399->TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery:295->TestFileChecksum.getFileChecksum:584 ? PathIO[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailure.testVolumeFailure:195 ? Timeout Timed out waiting fo...[m
[[1;31mERROR[m] [1;31m  TestDataNodeVolumeFailureToleration.testFailedVolumeOnStartupIsCounted:299 ? Timeout[m
[[1;31mERROR[m] [1;31m  TestDirectoryScanner.testScanDirectoryStructureWarn:426 ?  test timed out afte...[m
[[1;31mERROR[m] [1;31m  TestFsDatasetImpl.testCleanShutdownOfVolume:700 ? Timeout Timed out waiting fo...[m
[[1;34mINFO[m] 
[[1;31mERROR[m] [1;31mTests run: 5830, Failures: 22, Errors: 23, Skipped: 21[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;31mBUILD FAILURE[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time:  05:26 h
[[1;34mINFO[m] Finished at: 2020-04-09T03:51:11Z
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;31mERROR[m] Failed to execute goal [32morg.apache.maven.plugins:maven-surefire-plugin:3.0.0-M1:test[m [1m(default-test)[m on project [36mhadoop-hdfs[m: [1;31mThere are test failures.[m
[[1;31mERROR[m] [1;31m[m
[[1;31mERROR[m] [1;31mPlease refer to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/surefire-reports for the individual test results.[m
[[1;31mERROR[m] [1;31mPlease refer to dump files (if any exist) [date].dump, [date]-jvmRun[N].dump and [date].dumpstream.[m
[[1;31mERROR[m] [1;31mExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?[m
[[1;31mERROR[m] [1;31mCommand was /bin/sh -c cd /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -Xmx2048m -XX:+HeapDumpOnOutOfMemoryError -jar /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/surefire/surefirebooter8365640765960868023.jar /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/surefire 2020-04-08T22-24-53_721-jvmRun1 surefire6541794795103663987tmp surefire_5332308274403702678723tmp[m
[[1;31mERROR[m] [1;31mError occurred in starting fork, check output in log[m
[[1;31mERROR[m] [1;31mProcess Exit Code: 127[m
[[1;31mERROR[m] [1;31mCrashed tests:[m
[[1;31mERROR[m] [1;31morg.apache.hadoop.hdfs.TestHdfsAdmin[m
[[1;31mERROR[m] [1;31morg.apache.maven.surefire.booter.SurefireBooterForkException: ExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?[m
[[1;31mERROR[m] [1;31mCommand was /bin/sh -c cd /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -Xmx2048m -XX:+HeapDumpOnOutOfMemoryError -jar /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/surefire/surefirebooter8365640765960868023.jar /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/surefire 2020-04-08T22-24-53_721-jvmRun1 surefire6541794795103663987tmp surefire_5332308274403702678723tmp[m
[[1;31mERROR[m] [1;31mError occurred in starting fork, check output in log[m
[[1;31mERROR[m] [1;31mProcess Exit Code: 127[m
[[1;31mERROR[m] [1;31mCrashed tests:[m
[[1;31mERROR[m] [1;31morg.apache.hadoop.hdfs.TestHdfsAdmin[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.awaitResultsDone(ForkStarter.java:511)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.runSuitesForkPerTestSet(ForkStarter.java:458)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:299)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:247)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1149)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:991)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:837)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:210)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:156)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:148)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:956)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.cli.MavenCli.main(MavenCli.java:192)[m
[[1;31mERROR[m] [1;31m	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[m
[[1;31mERROR[m] [1;31m	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)[m
[[1;31mERROR[m] [1;31m	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[m
[[1;31mERROR[m] [1;31m	at java.lang.reflect.Method.invoke(Method.java:498)[m
[[1;31mERROR[m] [1;31m	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)[m
[[1;31mERROR[m] [1;31m	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)[m
[[1;31mERROR[m] [1;31m	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)[m
[[1;31mERROR[m] [1;31m	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)[m
[[1;31mERROR[m] [1;31mCaused by: org.apache.maven.surefire.booter.SurefireBooterForkException: The forked VM terminated without properly saying goodbye. VM crash or System.exit called?[m
[[1;31mERROR[m] [1;31mCommand was /bin/sh -c cd /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -Xmx2048m -XX:+HeapDumpOnOutOfMemoryError -jar /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/surefire/surefirebooter8365640765960868023.jar /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/surefire 2020-04-08T22-24-53_721-jvmRun1 surefire6541794795103663987tmp surefire_5332308274403702678723tmp[m
[[1;31mERROR[m] [1;31mError occurred in starting fork, check output in log[m
[[1;31mERROR[m] [1;31mProcess Exit Code: 127[m
[[1;31mERROR[m] [1;31mCrashed tests:[m
[[1;31mERROR[m] [1;31morg.apache.hadoop.hdfs.TestHdfsAdmin[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:670)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.booterclient.ForkStarter.access$600(ForkStarter.java:116)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.booterclient.ForkStarter$2.call(ForkStarter.java:445)[m
[[1;31mERROR[m] [1;31m	at org.apache.maven.plugin.surefire.booterclient.ForkStarter$2.call(ForkStarter.java:421)[m
[[1;31mERROR[m] [1;31m	at java.util.concurrent.FutureTask.run(FutureTask.java:266)[m
[[1;31mERROR[m] [1;31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)[m
[[1;31mERROR[m] [1;31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)[m
[[1;31mERROR[m] [1;31m	at java.lang.Thread.run(Thread.java:748)[m
[[1;31mERROR[m] [1;31m[m
[[1;31mERROR[m] -> [1m[Help 1][m
[[1;31mERROR[m] 
[[1;31mERROR[m] To see the full stack trace of the errors, re-run Maven with the [1m-e[m switch.
[[1;31mERROR[m] Re-run Maven using the [1m-X[m switch to enable full debug logging.
[[1;31mERROR[m] 
[[1;31mERROR[m] For more information about the errors and possible solutions, please read the following articles:
[[1;31mERROR[m] [1m[Help 1][m http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
